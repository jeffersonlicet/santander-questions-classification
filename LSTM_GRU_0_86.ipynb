{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "LSTM-GRU-0.86.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e2181d1314c44cc8f0759c64adeefa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0ebc8260eadb4381a825e7515cd262c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_904bd9abfaf8471a8b94ea08ec2a0649",
              "IPY_MODEL_ef37eedcf56b4b1ba11b92583284dbe5"
            ]
          }
        },
        "0ebc8260eadb4381a825e7515cd262c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "904bd9abfaf8471a8b94ea08ec2a0649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39343d332fff418b92a431c02231c539",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20108,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20108,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a337affe70a4bd6ba704dc3f29d70a6"
          }
        },
        "ef37eedcf56b4b1ba11b92583284dbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7d3664b17244d6895eb84b4748384fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20108/20108 [00:08&lt;00:00, 2340.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4361bde7e6d449f9b836cca8d814593b"
          }
        },
        "39343d332fff418b92a431c02231c539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a337affe70a4bd6ba704dc3f29d70a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7d3664b17244d6895eb84b4748384fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4361bde7e6d449f9b836cca8d814593b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2a00dcf28204bbab16434c2aa875c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff90e6e5c7d64dd3897167b0d6ca7678",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce4572c8ba4548048536f72059aab512",
              "IPY_MODEL_4d1ca7562aec40b6badfff34a4cf8612"
            ]
          }
        },
        "ff90e6e5c7d64dd3897167b0d6ca7678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce4572c8ba4548048536f72059aab512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f70dfd7672f044578d3cd7c7cc28e745",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20108,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20108,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba343c8f5b0246cb8690de867c6e0758"
          }
        },
        "4d1ca7562aec40b6badfff34a4cf8612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7babe94f23ef4ce39e829b9a6d5da948",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20108/20108 [00:00&lt;00:00, 165151.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5ed62b2952b408bb625360d91fbdaf1"
          }
        },
        "f70dfd7672f044578d3cd7c7cc28e745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba343c8f5b0246cb8690de867c6e0758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7babe94f23ef4ce39e829b9a6d5da948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5ed62b2952b408bb625360d91fbdaf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0f02a2ec490437ebc70a02bf22b770e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_025f4e67245f4c0bbc0568950cbe5da1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_89d4446c1fb14148a8051f563bc02c49",
              "IPY_MODEL_436b38c02bda478892667cb1cf6b68c1"
            ]
          }
        },
        "025f4e67245f4c0bbc0568950cbe5da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89d4446c1fb14148a8051f563bc02c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d7d091d95acd43c2bfd8d028cda8d59f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20108,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20108,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3dde0c875ed468f8f2b478189baeadc"
          }
        },
        "436b38c02bda478892667cb1cf6b68c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81318d69e830486188d49f2ab7eb7485",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20108/20108 [00:03&lt;00:00, 6533.53it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac9fad3ddd5946b8b154fae7ab85eaaf"
          }
        },
        "d7d091d95acd43c2bfd8d028cda8d59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3dde0c875ed468f8f2b478189baeadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81318d69e830486188d49f2ab7eb7485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac9fad3ddd5946b8b154fae7ab85eaaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "428390122ca64f58af8a383bb1636727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d94d5f4a8cc48bd88b3d4ad0a9155ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e8645441942461e8772342fd4611c9e",
              "IPY_MODEL_463450b0f4354f9e9a6cb2ad400efcde"
            ]
          }
        },
        "5d94d5f4a8cc48bd88b3d4ad0a9155ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e8645441942461e8772342fd4611c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c58aa08c8a264117a4598e520e3553f5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6702,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6702,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09d0c59dc4eb4dd68def1723d0948b99"
          }
        },
        "463450b0f4354f9e9a6cb2ad400efcde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3b84c332de54cee81441855b3113a4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6702/6702 [00:02&lt;00:00, 2367.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55ca1d19ab24463bb5d3ae94e74b2550"
          }
        },
        "c58aa08c8a264117a4598e520e3553f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09d0c59dc4eb4dd68def1723d0948b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3b84c332de54cee81441855b3113a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55ca1d19ab24463bb5d3ae94e74b2550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "450e5744c8a24009b2aa9b441af570c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7cb641152464b24bd10c6df9a197000",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_237f86702e9741838f164bd5e720ec87",
              "IPY_MODEL_6844208eb2de4b00abc5390c55d38a25"
            ]
          }
        },
        "d7cb641152464b24bd10c6df9a197000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "237f86702e9741838f164bd5e720ec87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63671e5a9c8f4e7ab5bead9dec96046b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6702,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6702,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cc4e3354a2642beaa913821191de90a"
          }
        },
        "6844208eb2de4b00abc5390c55d38a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf939f72f59a46288025bbe4c1711268",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6702/6702 [05:46&lt;00:00, 19.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e0305399a6e413b859ae2cf3604b681"
          }
        },
        "63671e5a9c8f4e7ab5bead9dec96046b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cc4e3354a2642beaa913821191de90a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf939f72f59a46288025bbe4c1711268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e0305399a6e413b859ae2cf3604b681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m04nSakSjzLf",
        "colab_type": "text"
      },
      "source": [
        "# Santander Questions Classification Using:\n",
        "### A Long short-term memory and Gated recurrent unit Model\n",
        "> Author: Jefferson Licet\n",
        "\n",
        "> Email: jeffersonlicet@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "atf_-x9PjzLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDINGS_DIMENSION = 120\n",
        "MAX_LEN_WORD = 30\n",
        "MIN_WORD_FQ = 1\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UBpfSgVEjzLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import random as rn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "\n",
        "SEED_NUMBER = 44 # Magic number\n",
        "\n",
        "# Seed random numbers, only words with CPU/GPU\n",
        "rn.seed(SEED_NUMBER)\n",
        "np.random.seed(SEED_NUMBER)\n",
        "tf.random.set_seed(SEED_NUMBER)\n",
        "os.environ['PYTHONHASHSEED'] = '0'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "btjstvcZjzLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import unicodedata\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "spanish_snow = SnowballStemmer('spanish')\n",
        "\n",
        "tokenizer = WordPunctTokenizer()\n",
        "remove_puntuaction = r'[^\\w\\s]' # Non words\n",
        "numbers_regex = r'(\\b)[0-9]+(\\b)' # Numbers\n",
        "\n",
        "def normailze_question(q):\n",
        "  q = q.lower()\n",
        "\n",
        "  # Remove tildes\n",
        "  q = unicodedata.normalize('NFKD', q).encode('ASCII', 'ignore').decode('utf8')\n",
        "  q = re.sub(remove_puntuaction, \" \", q)\n",
        "  q = re.sub(numbers_regex, \" DIGITO \", q)\n",
        "\n",
        "  tokens = tokenizer.tokenize(q)\n",
        "  return [spanish_snow.stem(token) for token in tokens if len(token) > 1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "vsKVU1y1jzLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Descargarmos el dataset desde el drive de la competencia\n",
        "!wget -q -O train.csv https://drive.google.com/u/0/uc?id=1SvVbsYUpKphC3NuU4y7JDYsDJxYT61Yl&export=download\n",
        "!wget -q -O test_santander.csv https://drive.google.com/u/0/uc?id=1bsV_URfRHy8LNLA1SKJ24hv0lRNVXMV4&export=download"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKawkBHqlpmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "0749c692-ff05-4d23-ee61-1f13ccaf33d9"
      },
      "source": [
        "# Load train and test data\n",
        "\n",
        "DATA_PATH = ''\n",
        "TRAIN_CSV_DIR = os.path.join(DATA_PATH, 'train.csv')\n",
        "TEST_CSV_DIR = os.path.join(DATA_PATH, 'test_santander.csv')\n",
        "\n",
        "train_data = pd.read_csv(TRAIN_CSV_DIR, sep='|')\n",
        "\n",
        "# Append samples for less populated category\n",
        "appendQuestions = [\n",
        " \"correo electrÃ³nico invÃ¡lido\",\n",
        " \"correo electrÃ³nico incorrecto\",\n",
        " \"el correo electronico es incorrecto\",\n",
        " \"el correo electronico no es correcto\",\n",
        "]\n",
        "\n",
        "appendCategories = [\"Cat_104\", \"Cat_104\", \"Cat_104\", \"Cat_104\"]\n",
        "\n",
        "df_concat = pd.DataFrame({'Pregunta': appendQuestions, 'Intencion': appendCategories })\n",
        "train_data = pd.concat([train_data, df_concat], ignore_index=True)\n",
        "\n",
        "print(train_data.tail(10))\n",
        "\n",
        "test_data = pd.read_csv(TEST_CSV_DIR)\n",
        "\n",
        "train_data['labels'], labels = pd.factorize(train_data.Intencion)\n",
        "\n",
        "# Assert prints train data\n",
        "print(train_data.head())\n",
        "\n",
        "# Assert prints test data\n",
        "print(test_data.head())\n",
        "\n",
        "assert len(labels) == len(np.unique(train_data.Intencion))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Pregunta Intencion\n",
            "20098            estoy necesitando una tarjeta de debito    Cat_39\n",
            "20099   el monto del prestamo depende de los ingresos???   Cat_251\n",
            "20100       quiero cancelar una compra puntual el cuotas   Cat_339\n",
            "20101                               necesito pagar deuda   Cat_192\n",
            "20102  teniendo otro hipotecario es posible aplicar p...   Cat_218\n",
            "20103                               comisiÃ³n descubierto    Cat_56\n",
            "20104                        correo electrÃ³nico invÃ¡lido   Cat_104\n",
            "20105                      correo electrÃ³nico incorrecto   Cat_104\n",
            "20106                el correo electronico es incorrecto   Cat_104\n",
            "20107               el correo electronico no es correcto   Cat_104\n",
            "                                            Pregunta Intencion  labels\n",
            "0               como puedo trabajar en santander rio   Cat_102       0\n",
            "1                pagar tarjeta visa querer reintegro   Cat_350       1\n",
            "2                      pagar tarjeta naranja sistema   Cat_132       2\n",
            "3  no se debitÃ³ la primera cuota del plan de bien...   Cat_129       3\n",
            "4                             abonar tarjeta credito   Cat_342       4\n",
            "   id                                           Pregunta\n",
            "0   0                    querer saber tarjeta sin limite\n",
            "1   1        Â¿cuÃ¡l es el lÃ­mite de mi tarjeta santander?\n",
            "2   2  hay beneficios en restaurantes de la costa atl...\n",
            "3   3  semana realizar pagar afip monotributo volver ...\n",
            "4   4      por un prestamo de mil. cuanto es el interes?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UVIdAOTJjzL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "3e2181d1314c44cc8f0759c64adeefa6",
            "0ebc8260eadb4381a825e7515cd262c7",
            "904bd9abfaf8471a8b94ea08ec2a0649",
            "ef37eedcf56b4b1ba11b92583284dbe5",
            "39343d332fff418b92a431c02231c539",
            "9a337affe70a4bd6ba704dc3f29d70a6",
            "b7d3664b17244d6895eb84b4748384fa",
            "4361bde7e6d449f9b836cca8d814593b"
          ]
        },
        "outputId": "41a48dbe-3c84-4556-c433-baf006acad57"
      },
      "source": [
        "def normalize_row(row):\n",
        "  row.Pregunta = normailze_question(row.Pregunta)\n",
        "  return row\n",
        "\n",
        "tqdm.pandas()\n",
        "processed = train_data.progress_apply(normalize_row, axis=1)\n",
        "processed.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e2181d1314c44cc8f0759c64adeefa6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20108.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregunta</th>\n",
              "      <th>Intencion</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[com, pued, trabaj, en, santand, rio]</td>\n",
              "      <td>Cat_102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[pag, tarjet, vis, quer, reintegr]</td>\n",
              "      <td>Cat_350</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[pag, tarjet, naranj, sistem]</td>\n",
              "      <td>Cat_132</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[no, se, debit, la, primer, cuot, del, plan, d...</td>\n",
              "      <td>Cat_129</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[abon, tarjet, credit]</td>\n",
              "      <td>Cat_342</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Pregunta Intencion  labels\n",
              "0              [com, pued, trabaj, en, santand, rio]   Cat_102       0\n",
              "1                 [pag, tarjet, vis, quer, reintegr]   Cat_350       1\n",
              "2                      [pag, tarjet, naranj, sistem]   Cat_132       2\n",
              "3  [no, se, debit, la, primer, cuot, del, plan, d...   Cat_129       3\n",
              "4                             [abon, tarjet, credit]   Cat_342       4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "abmY0QOzjzMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "f2a00dcf28204bbab16434c2aa875c13",
            "ff90e6e5c7d64dd3897167b0d6ca7678",
            "ce4572c8ba4548048536f72059aab512",
            "4d1ca7562aec40b6badfff34a4cf8612",
            "f70dfd7672f044578d3cd7c7cc28e745",
            "ba343c8f5b0246cb8690de867c6e0758",
            "7babe94f23ef4ce39e829b9a6d5da948",
            "d5ed62b2952b408bb625360d91fbdaf1"
          ]
        },
        "outputId": "3564a3d4-abb5-4a95-b60d-ef7b3f80d558"
      },
      "source": [
        "# Create dictionary using a Counter\n",
        "\n",
        "from collections import Counter\n",
        "dictionary = Counter()\n",
        "\n",
        "categories = processed.labels\n",
        "questions = processed.Pregunta\n",
        "\n",
        "for tokens in tqdm(questions):\n",
        "  dictionary.update(tokens)\n",
        "\n",
        "print(\"The Dictionary has been generated\")\n",
        "\n",
        "print(\"Mean by word\")\n",
        "mean = np.mean([c for k,c in dictionary.items()])\n",
        "print(mean)\n",
        "\n",
        "print(\"Total words found:\")\n",
        "print(len(dictionary.items()))\n",
        "\n",
        "dictionary_list = [k for k,c in dictionary.items() if c >= MIN_WORD_FQ]\n",
        "\n",
        "print(\"Total words in dictionary\")\n",
        "print(len(dictionary_list))\n",
        "\n",
        "dictionary = np.array(dictionary_list);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2a00dcf28204bbab16434c2aa875c13",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20108.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The Dictionary has been generated\n",
            "Mean by word\n",
            "47.49407933688573\n",
            "Total words found:\n",
            "3378\n",
            "Total words in dictionary\n",
            "3378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yAhlg6ynjzMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "f0f02a2ec490437ebc70a02bf22b770e",
            "025f4e67245f4c0bbc0568950cbe5da1",
            "89d4446c1fb14148a8051f563bc02c49",
            "436b38c02bda478892667cb1cf6b68c1",
            "d7d091d95acd43c2bfd8d028cda8d59f",
            "c3dde0c875ed468f8f2b478189baeadc",
            "81318d69e830486188d49f2ab7eb7485",
            "ac9fad3ddd5946b8b154fae7ab85eaaf"
          ]
        },
        "outputId": "1074f767-10ba-45fe-fb44-2ca6c9bd3696"
      },
      "source": [
        "# Map words to dictionary index\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "mean = np.mean([len(c) for c in questions])\n",
        "print('mean by items ', mean)\n",
        "\n",
        "vocabulary_size = len(dictionary)\n",
        "dic_list = list(dictionary)\n",
        "dictOfWords = { word : i for i, word in enumerate(dic_list) }\n",
        "\n",
        "def _hash(arr):\n",
        "  hashed_list = []\n",
        "  for item in tqdm(arr):\n",
        "    _list = []\n",
        "    for token in item:\n",
        "      if token in dictOfWords:\n",
        "        _list.append((dictOfWords.get(token)+1))\n",
        "    hashed_list.append(_list)\n",
        "  return hashed_list\n",
        "\n",
        "print('All items processed')\n",
        "hashed_list = _hash(questions)\n",
        "print(hashed_list[0])\n",
        "\n",
        "assert questions[0] == [dic_list[k-1] for k in hashed_list[0]]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean by items  7.978665207877461\n",
            "All items processed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0f02a2ec490437ebc70a02bf22b770e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20108.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[1, 2, 3, 4, 5, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VGo93g_rjzMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "428390122ca64f58af8a383bb1636727",
            "5d94d5f4a8cc48bd88b3d4ad0a9155ba",
            "7e8645441942461e8772342fd4611c9e",
            "463450b0f4354f9e9a6cb2ad400efcde",
            "c58aa08c8a264117a4598e520e3553f5",
            "09d0c59dc4eb4dd68def1723d0948b99",
            "c3b84c332de54cee81441855b3113a4c",
            "55ca1d19ab24463bb5d3ae94e74b2550",
            "450e5744c8a24009b2aa9b441af570c8",
            "d7cb641152464b24bd10c6df9a197000",
            "237f86702e9741838f164bd5e720ec87",
            "6844208eb2de4b00abc5390c55d38a25",
            "63671e5a9c8f4e7ab5bead9dec96046b",
            "7cc4e3354a2642beaa913821191de90a",
            "bf939f72f59a46288025bbe4c1711268",
            "4e0305399a6e413b859ae2cf3604b681"
          ]
        },
        "outputId": "8106ae43-ad39-46b4-d941-706b0301fad3"
      },
      "source": [
        "x = hashed_list\n",
        "\n",
        "test_data = pd.read_csv(TEST_CSV_DIR, sep=',')\n",
        "test_data.head()\n",
        "test_data.sample(10)\n",
        "\n",
        "# Process test data\n",
        "processed_test = test_data.progress_apply(normalize_row, axis=1)\n",
        "\n",
        "# Hash test data\n",
        "processed_test_questions = _hash(processed_test.Pregunta)\n",
        "assert processed_test.Pregunta.values[0] == [dic_list[k-1] for k in processed_test_questions[0]]\n",
        "processed_test_questions = pad_sequences(processed_test_questions, maxlen=MAX_LEN_WORD)\n",
        "\n",
        "print(processed_test_questions[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "428390122ca64f58af8a383bb1636727",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6702.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "450e5744c8a24009b2aa9b441af570c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6702.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  10  26   8 397 189]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-cdx3kPtR4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicts using all the models\n",
        "def ensemble_pred(models, testX, apply_argmax):\n",
        "  yhats = [model.predict(testX) for model in models]\n",
        "  yhats = np.array(yhats)\n",
        "  summed = np.sum(yhats, axis=0)\n",
        "  if apply_argmax:\n",
        "    summed = np.argmax(summed, axis=1)\n",
        "  return summed"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R_tp07p1jzMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def generateModel(x, y, x_test, y_test, class_weights, categories, epochs, use_gru=False, iteration=0):\n",
        "  input = Input(shape=(x.shape[1],), dtype='int32')\n",
        "\n",
        "  input_layer = Embedding(\n",
        "    trainable=True,\n",
        "    input_length=x.shape[1],\n",
        "    output_dim=EMBEDDINGS_DIMENSION,\n",
        "    input_dim=(dictionary.shape[0]+1)\n",
        "  )(input)\n",
        "\n",
        "  input_layer = SpatialDropout1D(0.5)(input_layer)\n",
        "  if use_gru:\n",
        "    i1 = Bidirectional(GRU(EMBEDDINGS_DIMENSION*2, return_sequences=True), name=\"BGRU\")(input_layer)\n",
        "  else:\n",
        "    i1 = Bidirectional(LSTM(EMBEDDINGS_DIMENSION*2, return_sequences=True), name=\"BLSTM\")(input_layer)\n",
        "  \n",
        "  i1 = GlobalMaxPooling1D()(i1)\n",
        "  i1 = Dropout(0.5)(i1)\n",
        "  i1 = Dense(512, activation='relu')(i1)\n",
        "  i1 = BatchNormalization()(i1)\n",
        "  output = Dense(len(categories), activation=\"softmax\")(i1)\n",
        "  model = Model(inputs=input, outputs=output)\n",
        "  model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=Adam(),\n",
        "    metrics=[\"acc\"]\n",
        "  )\n",
        "\n",
        "  if iteration == 0:\n",
        "    print(model.summary())\n",
        "\n",
        "  es = EarlyStopping(\n",
        "        monitor='val_acc',\n",
        "        mode='max',\n",
        "        verbose=1,\n",
        "        patience=15,\n",
        "        restore_best_weights=True)\n",
        "  \n",
        "  callbacks_list=[es]\n",
        "\n",
        "  history = model.fit(x,\n",
        "            y,\n",
        "            epochs=epochs,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_data=(x_test, y_test),\n",
        "            class_weight=dict(enumerate(class_weights)),\n",
        "            callbacks=callbacks_list,\n",
        "            verbose=2)\n",
        "  \n",
        "  prefix = 'lstm'\n",
        "\n",
        "  if use_gru:\n",
        "    prefix = 'gru'\n",
        "  \n",
        "  plt.figure(1)\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.savefig(str(iteration)+'_acc_'+prefix+'.png')\n",
        "  plt.clf()\n",
        "  plt.figure(1)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.savefig(str(iteration)+'_loss_'+prefix+'.png')\n",
        "  plt.clf()\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "L6MeIWzpjzMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "def trainModel(gru=False):\n",
        "  N_FOLDS = 10 # 10\n",
        "  EPOCHS = 200 # 200\n",
        "\n",
        "  y = np.array(categories)\n",
        "  x = pad_sequences(hashed_list, maxlen=MAX_LEN_WORD)\n",
        "\n",
        "  class_weights = class_weight.compute_class_weight(\n",
        "      'balanced',\n",
        "      classes=np.unique(y),\n",
        "      y=y)\n",
        "\n",
        "  kfold = StratifiedKFold(N_FOLDS, True, 1)\n",
        "  iteration = 0\n",
        "  models = []\n",
        "  scores = []\n",
        "\n",
        "  for train_ix, test_ix in kfold.split(x, y):\n",
        "      print('ðŸš€ Starting kfold iteration: ' + str(iteration) + '/' + str(N_FOLDS-1))\n",
        "      trainX, trainy = x[train_ix], y[train_ix]\n",
        "      testX, testy = x[test_ix], y[test_ix]\n",
        "      \n",
        "      model = generateModel(\n",
        "          trainX,\n",
        "          trainy,\n",
        "          testX,\n",
        "          testy,\n",
        "          class_weights,\n",
        "          np.unique(categories),\n",
        "          EPOCHS,\n",
        "          gru,\n",
        "          iteration)\n",
        "      \n",
        "      y_pred = model.predict(testX, verbose=0)\n",
        "      y_pred_max = np.argmax(y_pred, axis=1).tolist()\n",
        "      iteration = iteration + 1\n",
        "\n",
        "      models.append(model)\n",
        "      bacc = balanced_accuracy_score(testy, y_pred_max)\n",
        "      print (\"\\n########## Balanced Acc: %0.8f ##########\\n\" % bacc )\n",
        "      scores.append(bacc)\n",
        "\n",
        "  summed = np.sum(scores, axis=0)\n",
        "  print (\"\\n########## Global Balanced Acc: %0.8f ##########\\n\" % (summed/len(models)) )\n",
        "  return models, scores"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AI9UuP3yCQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e58fa33d-c8d7-488e-fb4c-f54a0b4bbd7e"
      },
      "source": [
        "lstm_models, lstm_scores = trainModel(gru=False)\n",
        "np.save('lstm.npy', ensemble_pred(lstm_models, processed_test_questions, False))\n",
        "\n",
        "\n",
        "del lstm_models"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ðŸš€ Starting kfold iteration: 0/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 30, 120)           405480    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 30, 120)           0         \n",
            "_________________________________________________________________\n",
            "BLSTM (Bidirectional)        (None, 30, 480)           693120    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               246272    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 352)               180576    \n",
            "=================================================================\n",
            "Total params: 1,527,496\n",
            "Trainable params: 1,526,472\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4979 - acc: 0.0350 - val_loss: 4.4103 - val_acc: 0.1795\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.4737 - acc: 0.2381 - val_loss: 2.2556 - val_acc: 0.4455\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.1376 - acc: 0.3899 - val_loss: 1.7225 - val_acc: 0.5520\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5686 - acc: 0.4835 - val_loss: 1.4712 - val_acc: 0.6047\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2819 - acc: 0.5462 - val_loss: 1.3249 - val_acc: 0.6579\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0839 - acc: 0.5904 - val_loss: 1.2187 - val_acc: 0.6852\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9319 - acc: 0.6248 - val_loss: 1.1353 - val_acc: 0.6992\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8361 - acc: 0.6488 - val_loss: 1.2111 - val_acc: 0.6977\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7541 - acc: 0.6650 - val_loss: 1.1492 - val_acc: 0.7190\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7323 - acc: 0.6758 - val_loss: 1.1294 - val_acc: 0.7235\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.7070 - acc: 0.6880 - val_loss: 1.1456 - val_acc: 0.7185\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6494 - acc: 0.7047 - val_loss: 1.0858 - val_acc: 0.7330\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6172 - acc: 0.7155 - val_loss: 1.1502 - val_acc: 0.7230\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5830 - acc: 0.7268 - val_loss: 1.0559 - val_acc: 0.7553\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5599 - acc: 0.7379 - val_loss: 1.1154 - val_acc: 0.7444\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5098 - acc: 0.7527 - val_loss: 1.0566 - val_acc: 0.7553\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5324 - acc: 0.7488 - val_loss: 1.0608 - val_acc: 0.7633\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4769 - acc: 0.7587 - val_loss: 1.0786 - val_acc: 0.7524\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4743 - acc: 0.7633 - val_loss: 1.0630 - val_acc: 0.7563\n",
            "Epoch 20/200\n",
            "566/566 - 7s - loss: 0.4323 - acc: 0.7764 - val_loss: 1.0218 - val_acc: 0.7668\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4164 - acc: 0.7792 - val_loss: 1.0474 - val_acc: 0.7703\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4263 - acc: 0.7800 - val_loss: 1.0172 - val_acc: 0.7663\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4216 - acc: 0.7874 - val_loss: 1.0482 - val_acc: 0.7638\n",
            "Epoch 24/200\n",
            "566/566 - 7s - loss: 0.4024 - acc: 0.7874 - val_loss: 1.0375 - val_acc: 0.7548\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.4005 - acc: 0.7879 - val_loss: 1.0718 - val_acc: 0.7653\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3956 - acc: 0.7954 - val_loss: 1.0272 - val_acc: 0.7732\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3714 - acc: 0.8059 - val_loss: 1.0587 - val_acc: 0.7638\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3981 - acc: 0.7961 - val_loss: 1.0810 - val_acc: 0.7658\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3569 - acc: 0.8054 - val_loss: 1.0233 - val_acc: 0.7723\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3706 - acc: 0.8063 - val_loss: 1.0153 - val_acc: 0.7797\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3422 - acc: 0.8057 - val_loss: 1.0023 - val_acc: 0.7737\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3388 - acc: 0.8134 - val_loss: 1.0050 - val_acc: 0.7698\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3281 - acc: 0.8215 - val_loss: 1.0418 - val_acc: 0.7747\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3224 - acc: 0.8243 - val_loss: 1.0464 - val_acc: 0.7708\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3226 - acc: 0.8164 - val_loss: 0.9817 - val_acc: 0.7857\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3137 - acc: 0.8243 - val_loss: 0.9561 - val_acc: 0.7907\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2932 - acc: 0.8290 - val_loss: 0.9813 - val_acc: 0.7832\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2841 - acc: 0.8368 - val_loss: 0.9588 - val_acc: 0.8011\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2864 - acc: 0.8343 - val_loss: 0.9794 - val_acc: 0.7971\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.3080 - acc: 0.8288 - val_loss: 0.9427 - val_acc: 0.7996\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2780 - acc: 0.8390 - val_loss: 1.0335 - val_acc: 0.7946\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2893 - acc: 0.8359 - val_loss: 0.9236 - val_acc: 0.7986\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2859 - acc: 0.8416 - val_loss: 0.9894 - val_acc: 0.7991\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2696 - acc: 0.8422 - val_loss: 1.0161 - val_acc: 0.7872\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2667 - acc: 0.8410 - val_loss: 0.9751 - val_acc: 0.8095\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2777 - acc: 0.8413 - val_loss: 1.0099 - val_acc: 0.7976\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2636 - acc: 0.8498 - val_loss: 0.9395 - val_acc: 0.8120\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2734 - acc: 0.8475 - val_loss: 0.9566 - val_acc: 0.7951\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2580 - acc: 0.8461 - val_loss: 0.9586 - val_acc: 0.8115\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2393 - acc: 0.8568 - val_loss: 0.9788 - val_acc: 0.7996\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2469 - acc: 0.8521 - val_loss: 0.9270 - val_acc: 0.8046\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2344 - acc: 0.8563 - val_loss: 0.9869 - val_acc: 0.8036\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2604 - acc: 0.8512 - val_loss: 0.9537 - val_acc: 0.7951\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2557 - acc: 0.8507 - val_loss: 0.9838 - val_acc: 0.8086\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2268 - acc: 0.8625 - val_loss: 0.9474 - val_acc: 0.8120\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2166 - acc: 0.8621 - val_loss: 0.9666 - val_acc: 0.8076\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2154 - acc: 0.8680 - val_loss: 0.9306 - val_acc: 0.8105\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2209 - acc: 0.8653 - val_loss: 0.9669 - val_acc: 0.8071\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2460 - acc: 0.8615 - val_loss: 0.9826 - val_acc: 0.7991\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2180 - acc: 0.8640 - val_loss: 0.9564 - val_acc: 0.8165\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1981 - acc: 0.8731 - val_loss: 0.9765 - val_acc: 0.8036\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2037 - acc: 0.8708 - val_loss: 0.9677 - val_acc: 0.8046\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2014 - acc: 0.8737 - val_loss: 0.9871 - val_acc: 0.8140\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2133 - acc: 0.8714 - val_loss: 0.9400 - val_acc: 0.8195\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.2044 - acc: 0.8692 - val_loss: 0.9320 - val_acc: 0.8240\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.2016 - acc: 0.8727 - val_loss: 0.9633 - val_acc: 0.8105\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1888 - acc: 0.8768 - val_loss: 0.9727 - val_acc: 0.8165\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1812 - acc: 0.8830 - val_loss: 0.9373 - val_acc: 0.8274\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.2043 - acc: 0.8758 - val_loss: 0.9090 - val_acc: 0.8185\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1957 - acc: 0.8740 - val_loss: 0.9575 - val_acc: 0.8150\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.2042 - acc: 0.8789 - val_loss: 0.9493 - val_acc: 0.8175\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.2046 - acc: 0.8719 - val_loss: 0.9575 - val_acc: 0.8145\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1837 - acc: 0.8839 - val_loss: 0.9635 - val_acc: 0.8160\n",
            "Epoch 74/200\n",
            "566/566 - 7s - loss: 0.1899 - acc: 0.8795 - val_loss: 0.9444 - val_acc: 0.8289\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1917 - acc: 0.8825 - val_loss: 0.9402 - val_acc: 0.8225\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1857 - acc: 0.8823 - val_loss: 0.9934 - val_acc: 0.8190\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1775 - acc: 0.8866 - val_loss: 0.9241 - val_acc: 0.8265\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1802 - acc: 0.8883 - val_loss: 0.9168 - val_acc: 0.8270\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1799 - acc: 0.8901 - val_loss: 0.8992 - val_acc: 0.8250\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1753 - acc: 0.8875 - val_loss: 0.9099 - val_acc: 0.8260\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1821 - acc: 0.8884 - val_loss: 0.9173 - val_acc: 0.8294\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1746 - acc: 0.8929 - val_loss: 0.9233 - val_acc: 0.8255\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1569 - acc: 0.8929 - val_loss: 0.9369 - val_acc: 0.8279\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1722 - acc: 0.8922 - val_loss: 0.9111 - val_acc: 0.8349\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1708 - acc: 0.8893 - val_loss: 0.9198 - val_acc: 0.8250\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1813 - acc: 0.8906 - val_loss: 0.9201 - val_acc: 0.8235\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1666 - acc: 0.8945 - val_loss: 0.9517 - val_acc: 0.8190\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1695 - acc: 0.8921 - val_loss: 0.8885 - val_acc: 0.8329\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1591 - acc: 0.8959 - val_loss: 0.9133 - val_acc: 0.8299\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1585 - acc: 0.8999 - val_loss: 0.9091 - val_acc: 0.8314\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1680 - acc: 0.8945 - val_loss: 0.9378 - val_acc: 0.8319\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1638 - acc: 0.8915 - val_loss: 0.9047 - val_acc: 0.8319\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1555 - acc: 0.8980 - val_loss: 0.9000 - val_acc: 0.8309\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1627 - acc: 0.9026 - val_loss: 0.9223 - val_acc: 0.8274\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1487 - acc: 0.9017 - val_loss: 0.9009 - val_acc: 0.8270\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1541 - acc: 0.8996 - val_loss: 0.9363 - val_acc: 0.8255\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1563 - acc: 0.9019 - val_loss: 0.9339 - val_acc: 0.8324\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1554 - acc: 0.8963 - val_loss: 0.9768 - val_acc: 0.8279\n",
            "Epoch 99/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1556 - acc: 0.9004 - val_loss: 0.9466 - val_acc: 0.8314\n",
            "Epoch 00099: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Balanced Acc: 0.81118978 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 1/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.5253 - acc: 0.0372 - val_loss: 4.3953 - val_acc: 0.2168\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.4034 - acc: 0.2427 - val_loss: 2.5191 - val_acc: 0.4142\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.1399 - acc: 0.3907 - val_loss: 1.9330 - val_acc: 0.5137\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5501 - acc: 0.4888 - val_loss: 1.6340 - val_acc: 0.5738\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2935 - acc: 0.5437 - val_loss: 1.6157 - val_acc: 0.5922\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0675 - acc: 0.5809 - val_loss: 1.3637 - val_acc: 0.6574\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9311 - acc: 0.6221 - val_loss: 1.3658 - val_acc: 0.6584\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8856 - acc: 0.6364 - val_loss: 1.3306 - val_acc: 0.6703\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7942 - acc: 0.6605 - val_loss: 1.2762 - val_acc: 0.6897\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7519 - acc: 0.6683 - val_loss: 1.1939 - val_acc: 0.7126\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6748 - acc: 0.6890 - val_loss: 1.2126 - val_acc: 0.7225\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6506 - acc: 0.7048 - val_loss: 1.1776 - val_acc: 0.7210\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6312 - acc: 0.7105 - val_loss: 1.2828 - val_acc: 0.6977\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5964 - acc: 0.7209 - val_loss: 1.2640 - val_acc: 0.7146\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.6039 - acc: 0.7198 - val_loss: 1.2344 - val_acc: 0.7220\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5181 - acc: 0.7429 - val_loss: 1.1705 - val_acc: 0.7479\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5220 - acc: 0.7512 - val_loss: 1.1522 - val_acc: 0.7474\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.5297 - acc: 0.7479 - val_loss: 1.1394 - val_acc: 0.7489\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.5047 - acc: 0.7539 - val_loss: 1.1880 - val_acc: 0.7459\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4944 - acc: 0.7578 - val_loss: 1.1919 - val_acc: 0.7404\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4362 - acc: 0.7723 - val_loss: 1.1282 - val_acc: 0.7608\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4519 - acc: 0.7728 - val_loss: 1.1326 - val_acc: 0.7578\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4399 - acc: 0.7841 - val_loss: 1.1580 - val_acc: 0.7524\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4010 - acc: 0.7825 - val_loss: 1.1226 - val_acc: 0.7568\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.4080 - acc: 0.7920 - val_loss: 1.1665 - val_acc: 0.7464\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3959 - acc: 0.7881 - val_loss: 1.1112 - val_acc: 0.7727\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3873 - acc: 0.7963 - val_loss: 1.1616 - val_acc: 0.7603\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3782 - acc: 0.7971 - val_loss: 1.1309 - val_acc: 0.7598\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3635 - acc: 0.8067 - val_loss: 1.0968 - val_acc: 0.7703\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3230 - acc: 0.8136 - val_loss: 1.0882 - val_acc: 0.7668\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3526 - acc: 0.8076 - val_loss: 1.1361 - val_acc: 0.7703\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3362 - acc: 0.8092 - val_loss: 1.1245 - val_acc: 0.7688\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3430 - acc: 0.8110 - val_loss: 1.0786 - val_acc: 0.7777\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3337 - acc: 0.8174 - val_loss: 1.0824 - val_acc: 0.7852\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3439 - acc: 0.8126 - val_loss: 1.0991 - val_acc: 0.7772\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3040 - acc: 0.8244 - val_loss: 1.0691 - val_acc: 0.7852\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2912 - acc: 0.8375 - val_loss: 1.1136 - val_acc: 0.7718\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2969 - acc: 0.8332 - val_loss: 1.1481 - val_acc: 0.7787\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.3376 - acc: 0.8209 - val_loss: 1.1473 - val_acc: 0.7698\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.3173 - acc: 0.8247 - val_loss: 1.1005 - val_acc: 0.7772\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2837 - acc: 0.8369 - val_loss: 1.0863 - val_acc: 0.7857\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2905 - acc: 0.8355 - val_loss: 1.1248 - val_acc: 0.7782\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2748 - acc: 0.8371 - val_loss: 1.0625 - val_acc: 0.7892\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2572 - acc: 0.8458 - val_loss: 1.0754 - val_acc: 0.8021\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2714 - acc: 0.8394 - val_loss: 1.0592 - val_acc: 0.7941\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2638 - acc: 0.8505 - val_loss: 1.0906 - val_acc: 0.7847\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2555 - acc: 0.8516 - val_loss: 1.0381 - val_acc: 0.7971\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2777 - acc: 0.8457 - val_loss: 1.1009 - val_acc: 0.7911\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2673 - acc: 0.8526 - val_loss: 1.0729 - val_acc: 0.7921\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2613 - acc: 0.8479 - val_loss: 1.0822 - val_acc: 0.7921\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2390 - acc: 0.8554 - val_loss: 1.1080 - val_acc: 0.7792\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2334 - acc: 0.8608 - val_loss: 1.0518 - val_acc: 0.7887\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2358 - acc: 0.8573 - val_loss: 1.1058 - val_acc: 0.7941\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2289 - acc: 0.8561 - val_loss: 1.0608 - val_acc: 0.7956\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2538 - acc: 0.8579 - val_loss: 1.1024 - val_acc: 0.7961\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2405 - acc: 0.8606 - val_loss: 1.1026 - val_acc: 0.8021\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2367 - acc: 0.8615 - val_loss: 1.0810 - val_acc: 0.7996\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2247 - acc: 0.8644 - val_loss: 1.0785 - val_acc: 0.8026\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2274 - acc: 0.8653 - val_loss: 1.1040 - val_acc: 0.8031\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2105 - acc: 0.8703 - val_loss: 1.1318 - val_acc: 0.7971\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2065 - acc: 0.8696 - val_loss: 1.0966 - val_acc: 0.8016\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2017 - acc: 0.8748 - val_loss: 1.0593 - val_acc: 0.8031\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2073 - acc: 0.8740 - val_loss: 1.0501 - val_acc: 0.8066\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2003 - acc: 0.8768 - val_loss: 1.1076 - val_acc: 0.8061\n",
            "Epoch 65/200\n",
            "566/566 - 7s - loss: 0.1978 - acc: 0.8767 - val_loss: 1.0994 - val_acc: 0.7996\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.2170 - acc: 0.8760 - val_loss: 1.2007 - val_acc: 0.7916\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.2062 - acc: 0.8716 - val_loss: 1.1016 - val_acc: 0.8046\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.2024 - acc: 0.8767 - val_loss: 1.0920 - val_acc: 0.8066\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.2031 - acc: 0.8724 - val_loss: 1.1295 - val_acc: 0.8001\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1981 - acc: 0.8762 - val_loss: 1.0962 - val_acc: 0.8041\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.2018 - acc: 0.8732 - val_loss: 1.0797 - val_acc: 0.8066\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.2079 - acc: 0.8772 - val_loss: 1.1219 - val_acc: 0.7961\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1774 - acc: 0.8850 - val_loss: 1.0581 - val_acc: 0.8120\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1877 - acc: 0.8854 - val_loss: 1.0743 - val_acc: 0.8095\n",
            "Epoch 75/200\n",
            "566/566 - 7s - loss: 0.1924 - acc: 0.8783 - val_loss: 1.0869 - val_acc: 0.8051\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1824 - acc: 0.8827 - val_loss: 1.0782 - val_acc: 0.8076\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1854 - acc: 0.8862 - val_loss: 1.1083 - val_acc: 0.8046\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1949 - acc: 0.8799 - val_loss: 1.0556 - val_acc: 0.8110\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1680 - acc: 0.8890 - val_loss: 1.0684 - val_acc: 0.8086\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1837 - acc: 0.8833 - val_loss: 1.0988 - val_acc: 0.8061\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1742 - acc: 0.8899 - val_loss: 1.0774 - val_acc: 0.8110\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1768 - acc: 0.8880 - val_loss: 1.0892 - val_acc: 0.8066\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1790 - acc: 0.8842 - val_loss: 1.1241 - val_acc: 0.8095\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1849 - acc: 0.8890 - val_loss: 1.1098 - val_acc: 0.8115\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1609 - acc: 0.8939 - val_loss: 1.0967 - val_acc: 0.8031\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1727 - acc: 0.8912 - val_loss: 1.0692 - val_acc: 0.8115\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1664 - acc: 0.8938 - val_loss: 1.0827 - val_acc: 0.8135\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1588 - acc: 0.8940 - val_loss: 1.0409 - val_acc: 0.8135\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1651 - acc: 0.8957 - val_loss: 1.0587 - val_acc: 0.8205\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1520 - acc: 0.8981 - val_loss: 1.0765 - val_acc: 0.8145\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1653 - acc: 0.8902 - val_loss: 1.1000 - val_acc: 0.8130\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1613 - acc: 0.8925 - val_loss: 1.0606 - val_acc: 0.8175\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1483 - acc: 0.9000 - val_loss: 1.0707 - val_acc: 0.8210\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1519 - acc: 0.8982 - val_loss: 1.0760 - val_acc: 0.8170\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1610 - acc: 0.8998 - val_loss: 1.0799 - val_acc: 0.8140\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1564 - acc: 0.8979 - val_loss: 1.0657 - val_acc: 0.8076\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1585 - acc: 0.9023 - val_loss: 1.0533 - val_acc: 0.8180\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1540 - acc: 0.9034 - val_loss: 1.0942 - val_acc: 0.8130\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1524 - acc: 0.9050 - val_loss: 1.0542 - val_acc: 0.8205\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1427 - acc: 0.9022 - val_loss: 1.0412 - val_acc: 0.8170\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1557 - acc: 0.9041 - val_loss: 1.0526 - val_acc: 0.8190\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1416 - acc: 0.9010 - val_loss: 1.0503 - val_acc: 0.8180\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1460 - acc: 0.9053 - val_loss: 1.0522 - val_acc: 0.8205\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1509 - acc: 0.9089 - val_loss: 1.0518 - val_acc: 0.8205\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1580 - acc: 0.8990 - val_loss: 1.0610 - val_acc: 0.8215\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1511 - acc: 0.9032 - val_loss: 1.0834 - val_acc: 0.8185\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1399 - acc: 0.9066 - val_loss: 1.1120 - val_acc: 0.8115\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1333 - acc: 0.9073 - val_loss: 1.0493 - val_acc: 0.8334\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1358 - acc: 0.9115 - val_loss: 1.0824 - val_acc: 0.8245\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1428 - acc: 0.9091 - val_loss: 1.0954 - val_acc: 0.8195\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1389 - acc: 0.9106 - val_loss: 1.1243 - val_acc: 0.8185\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1360 - acc: 0.9102 - val_loss: 1.0864 - val_acc: 0.8215\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1359 - acc: 0.9120 - val_loss: 1.0290 - val_acc: 0.8250\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1462 - acc: 0.9118 - val_loss: 1.0400 - val_acc: 0.8265\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1571 - acc: 0.9064 - val_loss: 1.1040 - val_acc: 0.8185\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1394 - acc: 0.9095 - val_loss: 1.0617 - val_acc: 0.8230\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1342 - acc: 0.9106 - val_loss: 1.0811 - val_acc: 0.8250\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1410 - acc: 0.9090 - val_loss: 1.0631 - val_acc: 0.8270\n",
            "Epoch 119/200\n",
            "566/566 - 6s - loss: 0.1432 - acc: 0.9085 - val_loss: 1.0709 - val_acc: 0.8279\n",
            "Epoch 120/200\n",
            "566/566 - 6s - loss: 0.1284 - acc: 0.9142 - val_loss: 1.0661 - val_acc: 0.8260\n",
            "Epoch 121/200\n",
            "566/566 - 6s - loss: 0.1367 - acc: 0.9139 - val_loss: 1.0367 - val_acc: 0.8260\n",
            "Epoch 122/200\n",
            "566/566 - 6s - loss: 0.1337 - acc: 0.9130 - val_loss: 1.0717 - val_acc: 0.8225\n",
            "Epoch 123/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1196 - acc: 0.9190 - val_loss: 1.0816 - val_acc: 0.8235\n",
            "Epoch 00123: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.77728321 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 2/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4982 - acc: 0.0346 - val_loss: 4.3381 - val_acc: 0.2093\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.4354 - acc: 0.2272 - val_loss: 2.1828 - val_acc: 0.4625\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.1525 - acc: 0.3902 - val_loss: 1.7940 - val_acc: 0.5271\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.6196 - acc: 0.4753 - val_loss: 1.4920 - val_acc: 0.5932\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2815 - acc: 0.5291 - val_loss: 1.3543 - val_acc: 0.6390\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0918 - acc: 0.5814 - val_loss: 1.1950 - val_acc: 0.6952\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9557 - acc: 0.6184 - val_loss: 1.2296 - val_acc: 0.6678\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8587 - acc: 0.6347 - val_loss: 1.1216 - val_acc: 0.7136\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7792 - acc: 0.6566 - val_loss: 1.1863 - val_acc: 0.7026\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7790 - acc: 0.6749 - val_loss: 1.4563 - val_acc: 0.6514\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.7332 - acc: 0.6787 - val_loss: 1.0588 - val_acc: 0.7325\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6710 - acc: 0.6961 - val_loss: 1.1290 - val_acc: 0.7076\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.5945 - acc: 0.7169 - val_loss: 1.0163 - val_acc: 0.7509\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5840 - acc: 0.7258 - val_loss: 1.0462 - val_acc: 0.7439\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5444 - acc: 0.7413 - val_loss: 1.1628 - val_acc: 0.7255\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5734 - acc: 0.7339 - val_loss: 1.0460 - val_acc: 0.7539\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5141 - acc: 0.7474 - val_loss: 1.0340 - val_acc: 0.7464\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4887 - acc: 0.7547 - val_loss: 0.9821 - val_acc: 0.7772\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4863 - acc: 0.7617 - val_loss: 1.0117 - val_acc: 0.7558\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4622 - acc: 0.7623 - val_loss: 1.0300 - val_acc: 0.7653\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4495 - acc: 0.7739 - val_loss: 1.0567 - val_acc: 0.7509\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4409 - acc: 0.7729 - val_loss: 1.0334 - val_acc: 0.7608\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4429 - acc: 0.7753 - val_loss: 1.0381 - val_acc: 0.7568\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4060 - acc: 0.7851 - val_loss: 1.0163 - val_acc: 0.7688\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.4099 - acc: 0.7836 - val_loss: 1.0435 - val_acc: 0.7688\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3963 - acc: 0.7863 - val_loss: 1.0023 - val_acc: 0.7842\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3699 - acc: 0.7983 - val_loss: 1.0507 - val_acc: 0.7668\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3842 - acc: 0.7969 - val_loss: 1.0021 - val_acc: 0.7658\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3797 - acc: 0.8039 - val_loss: 1.0709 - val_acc: 0.7737\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3513 - acc: 0.8110 - val_loss: 1.0247 - val_acc: 0.7757\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3626 - acc: 0.8072 - val_loss: 1.0312 - val_acc: 0.7727\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3392 - acc: 0.8138 - val_loss: 1.0501 - val_acc: 0.7777\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3219 - acc: 0.8174 - val_loss: 1.0011 - val_acc: 0.7902\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3187 - acc: 0.8168 - val_loss: 1.0529 - val_acc: 0.7732\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3071 - acc: 0.8250 - val_loss: 1.0034 - val_acc: 0.7931\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3282 - acc: 0.8230 - val_loss: 1.0513 - val_acc: 0.7827\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.3085 - acc: 0.8215 - val_loss: 0.9760 - val_acc: 0.7981\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2906 - acc: 0.8314 - val_loss: 1.0132 - val_acc: 0.7892\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2903 - acc: 0.8344 - val_loss: 0.9594 - val_acc: 0.7966\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2985 - acc: 0.8333 - val_loss: 1.0071 - val_acc: 0.7941\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2920 - acc: 0.8346 - val_loss: 1.0582 - val_acc: 0.7832\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2975 - acc: 0.8347 - val_loss: 0.9841 - val_acc: 0.7956\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2574 - acc: 0.8448 - val_loss: 1.0095 - val_acc: 0.7961\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2771 - acc: 0.8447 - val_loss: 0.9725 - val_acc: 0.8041\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2775 - acc: 0.8404 - val_loss: 1.0348 - val_acc: 0.7907\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2991 - acc: 0.8379 - val_loss: 1.0128 - val_acc: 0.7892\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2581 - acc: 0.8462 - val_loss: 0.9923 - val_acc: 0.8061\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2540 - acc: 0.8514 - val_loss: 1.0046 - val_acc: 0.7946\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2766 - acc: 0.8442 - val_loss: 0.9547 - val_acc: 0.8125\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2473 - acc: 0.8523 - val_loss: 0.9935 - val_acc: 0.8041\n",
            "Epoch 51/200\n",
            "566/566 - 7s - loss: 0.2403 - acc: 0.8554 - val_loss: 0.9793 - val_acc: 0.8150\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2145 - acc: 0.8645 - val_loss: 0.9461 - val_acc: 0.8185\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2432 - acc: 0.8579 - val_loss: 0.9702 - val_acc: 0.8155\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2327 - acc: 0.8567 - val_loss: 0.9582 - val_acc: 0.8091\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2436 - acc: 0.8572 - val_loss: 1.0154 - val_acc: 0.8071\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2382 - acc: 0.8587 - val_loss: 0.9467 - val_acc: 0.8110\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2522 - acc: 0.8612 - val_loss: 0.9580 - val_acc: 0.8031\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2254 - acc: 0.8639 - val_loss: 0.9847 - val_acc: 0.8120\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2119 - acc: 0.8689 - val_loss: 0.9891 - val_acc: 0.8021\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2230 - acc: 0.8690 - val_loss: 0.9350 - val_acc: 0.8175\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2044 - acc: 0.8743 - val_loss: 0.9445 - val_acc: 0.8165\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2060 - acc: 0.8746 - val_loss: 0.9405 - val_acc: 0.8115\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2194 - acc: 0.8682 - val_loss: 0.9651 - val_acc: 0.8120\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2152 - acc: 0.8664 - val_loss: 0.9649 - val_acc: 0.8190\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1981 - acc: 0.8732 - val_loss: 0.9388 - val_acc: 0.8165\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1903 - acc: 0.8804 - val_loss: 0.9850 - val_acc: 0.8160\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.2045 - acc: 0.8767 - val_loss: 0.9721 - val_acc: 0.8180\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1938 - acc: 0.8788 - val_loss: 1.0041 - val_acc: 0.8140\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.2026 - acc: 0.8732 - val_loss: 0.9378 - val_acc: 0.8185\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1909 - acc: 0.8794 - val_loss: 0.9508 - val_acc: 0.8279\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1920 - acc: 0.8774 - val_loss: 0.9496 - val_acc: 0.8230\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1790 - acc: 0.8825 - val_loss: 0.9727 - val_acc: 0.8160\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1768 - acc: 0.8884 - val_loss: 0.9799 - val_acc: 0.8265\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1890 - acc: 0.8835 - val_loss: 0.9568 - val_acc: 0.8314\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1950 - acc: 0.8820 - val_loss: 0.9390 - val_acc: 0.8319\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1798 - acc: 0.8896 - val_loss: 0.9416 - val_acc: 0.8314\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1806 - acc: 0.8915 - val_loss: 1.0031 - val_acc: 0.8150\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1732 - acc: 0.8885 - val_loss: 0.9920 - val_acc: 0.8294\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1861 - acc: 0.8837 - val_loss: 0.9890 - val_acc: 0.8260\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1676 - acc: 0.8911 - val_loss: 1.0106 - val_acc: 0.8255\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1647 - acc: 0.8924 - val_loss: 0.9983 - val_acc: 0.8319\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1870 - acc: 0.8884 - val_loss: 0.9888 - val_acc: 0.8364\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1789 - acc: 0.8878 - val_loss: 0.9875 - val_acc: 0.8294\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1664 - acc: 0.8937 - val_loss: 0.9732 - val_acc: 0.8309\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1739 - acc: 0.8927 - val_loss: 1.0115 - val_acc: 0.8230\n",
            "Epoch 86/200\n",
            "566/566 - 7s - loss: 0.1630 - acc: 0.8961 - val_loss: 0.9998 - val_acc: 0.8260\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1703 - acc: 0.8942 - val_loss: 0.9913 - val_acc: 0.8274\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1658 - acc: 0.8967 - val_loss: 0.9914 - val_acc: 0.8314\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1641 - acc: 0.8988 - val_loss: 1.0049 - val_acc: 0.8205\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1666 - acc: 0.8945 - val_loss: 0.9665 - val_acc: 0.8245\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1678 - acc: 0.8926 - val_loss: 1.0194 - val_acc: 0.8274\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1601 - acc: 0.8996 - val_loss: 0.9733 - val_acc: 0.8354\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1570 - acc: 0.8950 - val_loss: 0.9505 - val_acc: 0.8419\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1587 - acc: 0.8968 - val_loss: 1.0070 - val_acc: 0.8319\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1636 - acc: 0.8948 - val_loss: 0.9771 - val_acc: 0.8274\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1688 - acc: 0.8943 - val_loss: 0.9828 - val_acc: 0.8374\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1531 - acc: 0.9027 - val_loss: 1.0306 - val_acc: 0.8359\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1509 - acc: 0.9017 - val_loss: 0.9818 - val_acc: 0.8354\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1593 - acc: 0.8993 - val_loss: 0.9972 - val_acc: 0.8339\n",
            "Epoch 100/200\n",
            "566/566 - 7s - loss: 0.1466 - acc: 0.8977 - val_loss: 0.9963 - val_acc: 0.8384\n",
            "Epoch 101/200\n",
            "566/566 - 7s - loss: 0.1597 - acc: 0.9014 - val_loss: 0.9984 - val_acc: 0.8304\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1428 - acc: 0.9038 - val_loss: 1.0315 - val_acc: 0.8230\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1494 - acc: 0.9032 - val_loss: 1.0220 - val_acc: 0.8284\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1452 - acc: 0.9047 - val_loss: 0.9379 - val_acc: 0.8369\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1461 - acc: 0.9053 - val_loss: 0.9613 - val_acc: 0.8329\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1370 - acc: 0.9064 - val_loss: 0.9895 - val_acc: 0.8454\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1481 - acc: 0.9018 - val_loss: 0.9674 - val_acc: 0.8468\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1442 - acc: 0.9036 - val_loss: 0.9736 - val_acc: 0.8444\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1477 - acc: 0.9086 - val_loss: 1.0011 - val_acc: 0.8374\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1319 - acc: 0.9111 - val_loss: 0.9575 - val_acc: 0.8414\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1429 - acc: 0.9085 - val_loss: 0.9676 - val_acc: 0.8409\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1302 - acc: 0.9135 - val_loss: 1.0028 - val_acc: 0.8274\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1472 - acc: 0.9067 - val_loss: 1.0257 - val_acc: 0.8344\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1415 - acc: 0.9073 - val_loss: 0.9770 - val_acc: 0.8444\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1315 - acc: 0.9136 - val_loss: 0.9621 - val_acc: 0.8424\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1379 - acc: 0.9055 - val_loss: 0.9713 - val_acc: 0.8444\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1392 - acc: 0.9127 - val_loss: 0.9807 - val_acc: 0.8304\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1274 - acc: 0.9142 - val_loss: 0.9854 - val_acc: 0.8429\n",
            "Epoch 119/200\n",
            "566/566 - 6s - loss: 0.1270 - acc: 0.9126 - val_loss: 0.9780 - val_acc: 0.8394\n",
            "Epoch 120/200\n",
            "566/566 - 6s - loss: 0.1299 - acc: 0.9103 - val_loss: 0.9526 - val_acc: 0.8449\n",
            "Epoch 121/200\n",
            "566/566 - 6s - loss: 0.1280 - acc: 0.9129 - val_loss: 1.0219 - val_acc: 0.8329\n",
            "Epoch 122/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1343 - acc: 0.9111 - val_loss: 0.9791 - val_acc: 0.8434\n",
            "Epoch 00122: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.81751691 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 3/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4960 - acc: 0.0376 - val_loss: 4.3304 - val_acc: 0.2173\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.3660 - acc: 0.2478 - val_loss: 2.2180 - val_acc: 0.4535\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.1109 - acc: 0.3901 - val_loss: 1.6989 - val_acc: 0.5420\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5599 - acc: 0.4847 - val_loss: 1.5340 - val_acc: 0.5753\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2339 - acc: 0.5492 - val_loss: 1.3740 - val_acc: 0.6161\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0422 - acc: 0.5928 - val_loss: 1.2718 - val_acc: 0.6529\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9294 - acc: 0.6191 - val_loss: 1.2087 - val_acc: 0.6773\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8446 - acc: 0.6403 - val_loss: 1.1315 - val_acc: 0.7006\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7474 - acc: 0.6705 - val_loss: 1.1831 - val_acc: 0.6827\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7120 - acc: 0.6811 - val_loss: 1.1254 - val_acc: 0.7195\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6839 - acc: 0.6906 - val_loss: 1.1326 - val_acc: 0.6932\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6459 - acc: 0.7041 - val_loss: 1.0809 - val_acc: 0.7205\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6038 - acc: 0.7192 - val_loss: 1.0484 - val_acc: 0.7350\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5739 - acc: 0.7301 - val_loss: 1.0775 - val_acc: 0.7355\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5702 - acc: 0.7307 - val_loss: 1.0218 - val_acc: 0.7404\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5252 - acc: 0.7444 - val_loss: 1.1320 - val_acc: 0.7250\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5119 - acc: 0.7459 - val_loss: 1.0671 - val_acc: 0.7474\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.5079 - acc: 0.7504 - val_loss: 1.0652 - val_acc: 0.7384\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4923 - acc: 0.7569 - val_loss: 1.0705 - val_acc: 0.7419\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4847 - acc: 0.7628 - val_loss: 1.0274 - val_acc: 0.7598\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4350 - acc: 0.7695 - val_loss: 0.9986 - val_acc: 0.7668\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4129 - acc: 0.7883 - val_loss: 0.9765 - val_acc: 0.7648\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4378 - acc: 0.7804 - val_loss: 1.0322 - val_acc: 0.7648\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4499 - acc: 0.7755 - val_loss: 1.0312 - val_acc: 0.7683\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3766 - acc: 0.7927 - val_loss: 0.9748 - val_acc: 0.7792\n",
            "Epoch 26/200\n",
            "566/566 - 7s - loss: 0.3944 - acc: 0.7942 - val_loss: 1.0148 - val_acc: 0.7663\n",
            "Epoch 27/200\n",
            "566/566 - 7s - loss: 0.3986 - acc: 0.7975 - val_loss: 1.0112 - val_acc: 0.7757\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3643 - acc: 0.8002 - val_loss: 0.9508 - val_acc: 0.7902\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3646 - acc: 0.8014 - val_loss: 1.0334 - val_acc: 0.7713\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3590 - acc: 0.8091 - val_loss: 1.0290 - val_acc: 0.7718\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3524 - acc: 0.8086 - val_loss: 1.0451 - val_acc: 0.7747\n",
            "Epoch 32/200\n",
            "566/566 - 7s - loss: 0.3282 - acc: 0.8206 - val_loss: 0.9705 - val_acc: 0.7802\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3262 - acc: 0.8191 - val_loss: 0.9828 - val_acc: 0.7842\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3279 - acc: 0.8162 - val_loss: 1.0028 - val_acc: 0.7872\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3064 - acc: 0.8271 - val_loss: 1.0477 - val_acc: 0.7817\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3302 - acc: 0.8244 - val_loss: 1.0260 - val_acc: 0.7762\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2998 - acc: 0.8269 - val_loss: 0.9764 - val_acc: 0.7941\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.3182 - acc: 0.8280 - val_loss: 1.0138 - val_acc: 0.7752\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2799 - acc: 0.8326 - val_loss: 1.0511 - val_acc: 0.7827\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2921 - acc: 0.8311 - val_loss: 1.0058 - val_acc: 0.7812\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2982 - acc: 0.8342 - val_loss: 0.9886 - val_acc: 0.7887\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2805 - acc: 0.8393 - val_loss: 0.9640 - val_acc: 0.7971\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2748 - acc: 0.8433 - val_loss: 0.9393 - val_acc: 0.8056\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2610 - acc: 0.8467 - val_loss: 0.9619 - val_acc: 0.8001\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2622 - acc: 0.8467 - val_loss: 1.0452 - val_acc: 0.7842\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2596 - acc: 0.8450 - val_loss: 0.9653 - val_acc: 0.8036\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2771 - acc: 0.8472 - val_loss: 0.9476 - val_acc: 0.8056\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2538 - acc: 0.8531 - val_loss: 0.9693 - val_acc: 0.8036\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2592 - acc: 0.8473 - val_loss: 0.9234 - val_acc: 0.8081\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2508 - acc: 0.8499 - val_loss: 0.9955 - val_acc: 0.7946\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2380 - acc: 0.8596 - val_loss: 0.9094 - val_acc: 0.8155\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2597 - acc: 0.8527 - val_loss: 0.9547 - val_acc: 0.8046\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2423 - acc: 0.8577 - val_loss: 1.0235 - val_acc: 0.7996\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2285 - acc: 0.8578 - val_loss: 0.9659 - val_acc: 0.8031\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2392 - acc: 0.8548 - val_loss: 1.0673 - val_acc: 0.7887\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2246 - acc: 0.8613 - val_loss: 1.0109 - val_acc: 0.7986\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2268 - acc: 0.8607 - val_loss: 0.9972 - val_acc: 0.7877\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2238 - acc: 0.8610 - val_loss: 0.9076 - val_acc: 0.8135\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2324 - acc: 0.8646 - val_loss: 1.0276 - val_acc: 0.7911\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2344 - acc: 0.8606 - val_loss: 0.9408 - val_acc: 0.8200\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2081 - acc: 0.8666 - val_loss: 0.9109 - val_acc: 0.8155\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2055 - acc: 0.8689 - val_loss: 0.9159 - val_acc: 0.8170\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2048 - acc: 0.8743 - val_loss: 0.9559 - val_acc: 0.8140\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2002 - acc: 0.8725 - val_loss: 0.9893 - val_acc: 0.8086\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.2080 - acc: 0.8733 - val_loss: 0.9629 - val_acc: 0.8095\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.2016 - acc: 0.8732 - val_loss: 0.9950 - val_acc: 0.8091\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.2223 - acc: 0.8688 - val_loss: 0.9011 - val_acc: 0.8339\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.2083 - acc: 0.8705 - val_loss: 0.9668 - val_acc: 0.8230\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1871 - acc: 0.8838 - val_loss: 0.9174 - val_acc: 0.8314\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1884 - acc: 0.8803 - val_loss: 0.9583 - val_acc: 0.8299\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1882 - acc: 0.8800 - val_loss: 0.9578 - val_acc: 0.8225\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1977 - acc: 0.8820 - val_loss: 0.9411 - val_acc: 0.8260\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1716 - acc: 0.8850 - val_loss: 0.9109 - val_acc: 0.8215\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1790 - acc: 0.8879 - val_loss: 0.9425 - val_acc: 0.8220\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1954 - acc: 0.8797 - val_loss: 0.9582 - val_acc: 0.8190\n",
            "Epoch 76/200\n",
            "566/566 - 7s - loss: 0.1996 - acc: 0.8802 - val_loss: 0.9563 - val_acc: 0.8270\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1691 - acc: 0.8909 - val_loss: 0.9543 - val_acc: 0.8324\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1855 - acc: 0.8862 - val_loss: 0.9426 - val_acc: 0.8279\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1714 - acc: 0.8907 - val_loss: 0.9016 - val_acc: 0.8399\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1644 - acc: 0.8902 - val_loss: 0.9198 - val_acc: 0.8270\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1687 - acc: 0.8921 - val_loss: 0.9146 - val_acc: 0.8339\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1783 - acc: 0.8873 - val_loss: 0.9806 - val_acc: 0.8284\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1596 - acc: 0.8936 - val_loss: 0.9607 - val_acc: 0.8225\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1644 - acc: 0.8963 - val_loss: 0.9110 - val_acc: 0.8354\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1561 - acc: 0.8977 - val_loss: 0.9530 - val_acc: 0.8304\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1713 - acc: 0.8925 - val_loss: 0.9116 - val_acc: 0.8394\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1628 - acc: 0.8974 - val_loss: 0.9580 - val_acc: 0.8250\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1667 - acc: 0.8922 - val_loss: 0.9730 - val_acc: 0.8240\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1512 - acc: 0.8979 - val_loss: 0.9425 - val_acc: 0.8265\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1645 - acc: 0.8972 - val_loss: 0.9792 - val_acc: 0.8200\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1574 - acc: 0.8974 - val_loss: 0.9218 - val_acc: 0.8304\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1581 - acc: 0.9040 - val_loss: 0.9707 - val_acc: 0.8260\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1560 - acc: 0.8990 - val_loss: 0.9542 - val_acc: 0.8195\n",
            "Epoch 94/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1515 - acc: 0.9025 - val_loss: 0.9116 - val_acc: 0.8394\n",
            "Epoch 00094: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.81340690 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 4/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4770 - acc: 0.0359 - val_loss: 4.4270 - val_acc: 0.1810\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.4004 - acc: 0.2336 - val_loss: 2.3329 - val_acc: 0.4321\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.1182 - acc: 0.3929 - val_loss: 1.8976 - val_acc: 0.5137\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5545 - acc: 0.4835 - val_loss: 1.5815 - val_acc: 0.5883\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2565 - acc: 0.5491 - val_loss: 1.4475 - val_acc: 0.6325\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0579 - acc: 0.5912 - val_loss: 1.3798 - val_acc: 0.6559\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9433 - acc: 0.6192 - val_loss: 1.3043 - val_acc: 0.6768\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8403 - acc: 0.6424 - val_loss: 1.3149 - val_acc: 0.6788\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7856 - acc: 0.6651 - val_loss: 1.2254 - val_acc: 0.6997\n",
            "Epoch 10/200\n",
            "566/566 - 7s - loss: 0.7211 - acc: 0.6802 - val_loss: 1.2851 - val_acc: 0.6867\n",
            "Epoch 11/200\n",
            "566/566 - 7s - loss: 0.6868 - acc: 0.6927 - val_loss: 1.1957 - val_acc: 0.7166\n",
            "Epoch 12/200\n",
            "566/566 - 7s - loss: 0.6517 - acc: 0.7004 - val_loss: 1.2445 - val_acc: 0.7116\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6291 - acc: 0.7098 - val_loss: 1.2491 - val_acc: 0.7066\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5778 - acc: 0.7264 - val_loss: 1.1857 - val_acc: 0.7265\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5403 - acc: 0.7360 - val_loss: 1.1562 - val_acc: 0.7265\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5278 - acc: 0.7443 - val_loss: 1.2430 - val_acc: 0.7131\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.4986 - acc: 0.7530 - val_loss: 1.1299 - val_acc: 0.7429\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.5104 - acc: 0.7508 - val_loss: 1.1914 - val_acc: 0.7230\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4634 - acc: 0.7660 - val_loss: 1.1367 - val_acc: 0.7414\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4608 - acc: 0.7679 - val_loss: 1.1199 - val_acc: 0.7474\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4765 - acc: 0.7612 - val_loss: 1.1354 - val_acc: 0.7519\n",
            "Epoch 22/200\n",
            "566/566 - 7s - loss: 0.4329 - acc: 0.7796 - val_loss: 1.0936 - val_acc: 0.7633\n",
            "Epoch 23/200\n",
            "566/566 - 7s - loss: 0.4297 - acc: 0.7804 - val_loss: 1.1321 - val_acc: 0.7474\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4441 - acc: 0.7760 - val_loss: 1.1074 - val_acc: 0.7648\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3813 - acc: 0.7948 - val_loss: 1.1215 - val_acc: 0.7539\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3834 - acc: 0.7946 - val_loss: 1.0818 - val_acc: 0.7613\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3911 - acc: 0.7921 - val_loss: 1.2668 - val_acc: 0.7389\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3735 - acc: 0.7970 - val_loss: 1.0380 - val_acc: 0.7688\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3557 - acc: 0.8051 - val_loss: 1.1125 - val_acc: 0.7668\n",
            "Epoch 30/200\n",
            "566/566 - 7s - loss: 0.3510 - acc: 0.8127 - val_loss: 1.1326 - val_acc: 0.7608\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3418 - acc: 0.8108 - val_loss: 1.1063 - val_acc: 0.7777\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3496 - acc: 0.8059 - val_loss: 1.1332 - val_acc: 0.7658\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3266 - acc: 0.8145 - val_loss: 1.0521 - val_acc: 0.7827\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3319 - acc: 0.8200 - val_loss: 1.0848 - val_acc: 0.7723\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3086 - acc: 0.8266 - val_loss: 1.0894 - val_acc: 0.7698\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3145 - acc: 0.8279 - val_loss: 1.0084 - val_acc: 0.7926\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2938 - acc: 0.8327 - val_loss: 1.0129 - val_acc: 0.7936\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2926 - acc: 0.8333 - val_loss: 1.0888 - val_acc: 0.7842\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2925 - acc: 0.8337 - val_loss: 1.0760 - val_acc: 0.7747\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2973 - acc: 0.8296 - val_loss: 1.0859 - val_acc: 0.7872\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2956 - acc: 0.8378 - val_loss: 1.0684 - val_acc: 0.7872\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2966 - acc: 0.8384 - val_loss: 1.0476 - val_acc: 0.7911\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2695 - acc: 0.8470 - val_loss: 1.0414 - val_acc: 0.7827\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2536 - acc: 0.8447 - val_loss: 1.0011 - val_acc: 0.7976\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2700 - acc: 0.8401 - val_loss: 1.0071 - val_acc: 0.8001\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2502 - acc: 0.8477 - val_loss: 1.0821 - val_acc: 0.7951\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2732 - acc: 0.8464 - val_loss: 1.0363 - val_acc: 0.7946\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2516 - acc: 0.8462 - val_loss: 0.9761 - val_acc: 0.8086\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2525 - acc: 0.8529 - val_loss: 1.0476 - val_acc: 0.7996\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2421 - acc: 0.8586 - val_loss: 1.0734 - val_acc: 0.7986\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2366 - acc: 0.8580 - val_loss: 1.0010 - val_acc: 0.8051\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2371 - acc: 0.8583 - val_loss: 1.0518 - val_acc: 0.7966\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2510 - acc: 0.8526 - val_loss: 1.0320 - val_acc: 0.7941\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2290 - acc: 0.8628 - val_loss: 0.9892 - val_acc: 0.8086\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2400 - acc: 0.8649 - val_loss: 1.0144 - val_acc: 0.8086\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2245 - acc: 0.8638 - val_loss: 1.0194 - val_acc: 0.8011\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2150 - acc: 0.8671 - val_loss: 1.0312 - val_acc: 0.8130\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2143 - acc: 0.8736 - val_loss: 1.0442 - val_acc: 0.8066\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2160 - acc: 0.8664 - val_loss: 1.0468 - val_acc: 0.7951\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2041 - acc: 0.8727 - val_loss: 1.0393 - val_acc: 0.7941\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2118 - acc: 0.8719 - val_loss: 1.0789 - val_acc: 0.7902\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2032 - acc: 0.8760 - val_loss: 1.0934 - val_acc: 0.8006\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2290 - acc: 0.8620 - val_loss: 1.0900 - val_acc: 0.7941\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2117 - acc: 0.8687 - val_loss: 1.0476 - val_acc: 0.8041\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.2147 - acc: 0.8710 - val_loss: 1.0132 - val_acc: 0.8115\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1909 - acc: 0.8806 - val_loss: 1.0206 - val_acc: 0.8120\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1950 - acc: 0.8785 - val_loss: 1.0472 - val_acc: 0.8066\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1950 - acc: 0.8758 - val_loss: 1.0107 - val_acc: 0.8120\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1988 - acc: 0.8794 - val_loss: 1.0152 - val_acc: 0.8130\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1819 - acc: 0.8866 - val_loss: 0.9940 - val_acc: 0.8125\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1858 - acc: 0.8782 - val_loss: 1.0311 - val_acc: 0.8086\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1860 - acc: 0.8794 - val_loss: 1.0175 - val_acc: 0.8155\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1837 - acc: 0.8891 - val_loss: 1.0205 - val_acc: 0.8255\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1714 - acc: 0.8878 - val_loss: 1.0023 - val_acc: 0.8135\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1808 - acc: 0.8878 - val_loss: 1.0166 - val_acc: 0.8145\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1941 - acc: 0.8834 - val_loss: 0.9740 - val_acc: 0.8185\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1637 - acc: 0.8942 - val_loss: 0.9892 - val_acc: 0.8230\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1875 - acc: 0.8843 - val_loss: 0.9758 - val_acc: 0.8240\n",
            "Epoch 79/200\n",
            "566/566 - 7s - loss: 0.1854 - acc: 0.8864 - val_loss: 1.0106 - val_acc: 0.8195\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1730 - acc: 0.8908 - val_loss: 0.9686 - val_acc: 0.8210\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1620 - acc: 0.8985 - val_loss: 0.9636 - val_acc: 0.8260\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1764 - acc: 0.8914 - val_loss: 1.0422 - val_acc: 0.8100\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1741 - acc: 0.8906 - val_loss: 0.9794 - val_acc: 0.8245\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1676 - acc: 0.8901 - val_loss: 0.9865 - val_acc: 0.8140\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1772 - acc: 0.8893 - val_loss: 0.9996 - val_acc: 0.8165\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1582 - acc: 0.8952 - val_loss: 0.9912 - val_acc: 0.8245\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1608 - acc: 0.8957 - val_loss: 0.9927 - val_acc: 0.8250\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1490 - acc: 0.8973 - val_loss: 1.0189 - val_acc: 0.8210\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1615 - acc: 0.8972 - val_loss: 0.9997 - val_acc: 0.8185\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1562 - acc: 0.8974 - val_loss: 0.9751 - val_acc: 0.8279\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1538 - acc: 0.8983 - val_loss: 0.9899 - val_acc: 0.8230\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1580 - acc: 0.8989 - val_loss: 0.9761 - val_acc: 0.8294\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1543 - acc: 0.9017 - val_loss: 0.9291 - val_acc: 0.8274\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1549 - acc: 0.9024 - val_loss: 0.9392 - val_acc: 0.8304\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1439 - acc: 0.9089 - val_loss: 0.9526 - val_acc: 0.8304\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1454 - acc: 0.9089 - val_loss: 0.9629 - val_acc: 0.8289\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1507 - acc: 0.9041 - val_loss: 0.9682 - val_acc: 0.8260\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1425 - acc: 0.9068 - val_loss: 1.0043 - val_acc: 0.8245\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1526 - acc: 0.8988 - val_loss: 0.9680 - val_acc: 0.8270\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1486 - acc: 0.9032 - val_loss: 0.9848 - val_acc: 0.8329\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1570 - acc: 0.9027 - val_loss: 1.0053 - val_acc: 0.8205\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1470 - acc: 0.9034 - val_loss: 0.9613 - val_acc: 0.8379\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1412 - acc: 0.9084 - val_loss: 0.9543 - val_acc: 0.8394\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1443 - acc: 0.9053 - val_loss: 0.9701 - val_acc: 0.8339\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1388 - acc: 0.9076 - val_loss: 0.9697 - val_acc: 0.8374\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1411 - acc: 0.9050 - val_loss: 0.9762 - val_acc: 0.8359\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1417 - acc: 0.9085 - val_loss: 0.9526 - val_acc: 0.8349\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1432 - acc: 0.9085 - val_loss: 0.9483 - val_acc: 0.8344\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1534 - acc: 0.9014 - val_loss: 0.9387 - val_acc: 0.8394\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1547 - acc: 0.9031 - val_loss: 0.9391 - val_acc: 0.8289\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1417 - acc: 0.9072 - val_loss: 0.9354 - val_acc: 0.8344\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1388 - acc: 0.9066 - val_loss: 0.9589 - val_acc: 0.8324\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1233 - acc: 0.9195 - val_loss: 0.9533 - val_acc: 0.8314\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1336 - acc: 0.9148 - val_loss: 0.9457 - val_acc: 0.8399\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1403 - acc: 0.9099 - val_loss: 0.9449 - val_acc: 0.8304\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1272 - acc: 0.9123 - val_loss: 0.9575 - val_acc: 0.8379\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1322 - acc: 0.9148 - val_loss: 0.9744 - val_acc: 0.8279\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1263 - acc: 0.9144 - val_loss: 0.9384 - val_acc: 0.8324\n",
            "Epoch 119/200\n",
            "566/566 - 6s - loss: 0.1411 - acc: 0.9067 - val_loss: 0.9615 - val_acc: 0.8314\n",
            "Epoch 120/200\n",
            "566/566 - 6s - loss: 0.1175 - acc: 0.9121 - val_loss: 0.9356 - val_acc: 0.8389\n",
            "Epoch 121/200\n",
            "566/566 - 6s - loss: 0.1248 - acc: 0.9142 - val_loss: 0.9737 - val_acc: 0.8364\n",
            "Epoch 122/200\n",
            "566/566 - 6s - loss: 0.1391 - acc: 0.9103 - val_loss: 0.9580 - val_acc: 0.8359\n",
            "Epoch 123/200\n",
            "566/566 - 6s - loss: 0.1288 - acc: 0.9172 - val_loss: 0.9701 - val_acc: 0.8334\n",
            "Epoch 124/200\n",
            "566/566 - 6s - loss: 0.1447 - acc: 0.9119 - val_loss: 0.9780 - val_acc: 0.8299\n",
            "Epoch 125/200\n",
            "566/566 - 6s - loss: 0.1261 - acc: 0.9168 - val_loss: 0.9888 - val_acc: 0.8379\n",
            "Epoch 126/200\n",
            "566/566 - 6s - loss: 0.1208 - acc: 0.9181 - val_loss: 0.9625 - val_acc: 0.8394\n",
            "Epoch 127/200\n",
            "566/566 - 6s - loss: 0.1304 - acc: 0.9130 - val_loss: 0.9881 - val_acc: 0.8299\n",
            "Epoch 128/200\n",
            "566/566 - 7s - loss: 0.1290 - acc: 0.9141 - val_loss: 1.0176 - val_acc: 0.8235\n",
            "Epoch 129/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1259 - acc: 0.9177 - val_loss: 0.9863 - val_acc: 0.8334\n",
            "Epoch 00129: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.81100636 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 5/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4607 - acc: 0.0442 - val_loss: 4.3156 - val_acc: 0.2198\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.3565 - acc: 0.2537 - val_loss: 2.2342 - val_acc: 0.4545\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.0724 - acc: 0.4043 - val_loss: 1.7779 - val_acc: 0.5480\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4942 - acc: 0.4973 - val_loss: 1.5574 - val_acc: 0.5922\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2188 - acc: 0.5599 - val_loss: 1.5351 - val_acc: 0.6067\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0705 - acc: 0.5911 - val_loss: 1.4361 - val_acc: 0.6290\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9333 - acc: 0.6239 - val_loss: 1.2775 - val_acc: 0.6683\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8555 - acc: 0.6466 - val_loss: 1.1997 - val_acc: 0.6967\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7974 - acc: 0.6605 - val_loss: 1.2121 - val_acc: 0.6877\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7385 - acc: 0.6746 - val_loss: 1.1865 - val_acc: 0.7071\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6577 - acc: 0.7050 - val_loss: 1.1441 - val_acc: 0.7280\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6475 - acc: 0.7023 - val_loss: 1.1401 - val_acc: 0.7305\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6210 - acc: 0.7111 - val_loss: 1.2260 - val_acc: 0.7041\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5773 - acc: 0.7321 - val_loss: 1.1007 - val_acc: 0.7449\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5532 - acc: 0.7349 - val_loss: 1.1504 - val_acc: 0.7285\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5387 - acc: 0.7394 - val_loss: 1.1753 - val_acc: 0.7350\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5288 - acc: 0.7474 - val_loss: 1.1401 - val_acc: 0.7454\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4953 - acc: 0.7561 - val_loss: 1.1333 - val_acc: 0.7548\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4903 - acc: 0.7552 - val_loss: 1.1477 - val_acc: 0.7429\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4827 - acc: 0.7662 - val_loss: 1.1244 - val_acc: 0.7568\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4438 - acc: 0.7760 - val_loss: 1.1119 - val_acc: 0.7459\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4189 - acc: 0.7793 - val_loss: 1.1027 - val_acc: 0.7499\n",
            "Epoch 23/200\n",
            "566/566 - 7s - loss: 0.4292 - acc: 0.7811 - val_loss: 1.1236 - val_acc: 0.7583\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4049 - acc: 0.7883 - val_loss: 1.1818 - val_acc: 0.7404\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.4025 - acc: 0.7843 - val_loss: 1.1579 - val_acc: 0.7484\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.4008 - acc: 0.7931 - val_loss: 1.1412 - val_acc: 0.7509\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3736 - acc: 0.7967 - val_loss: 1.0910 - val_acc: 0.7573\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3746 - acc: 0.8007 - val_loss: 1.1800 - val_acc: 0.7464\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3820 - acc: 0.7954 - val_loss: 1.0744 - val_acc: 0.7732\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3379 - acc: 0.8090 - val_loss: 1.0781 - val_acc: 0.7777\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3337 - acc: 0.8139 - val_loss: 1.1107 - val_acc: 0.7693\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3290 - acc: 0.8177 - val_loss: 1.0885 - val_acc: 0.7732\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3454 - acc: 0.8137 - val_loss: 1.1267 - val_acc: 0.7727\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3449 - acc: 0.8113 - val_loss: 1.1032 - val_acc: 0.7713\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3385 - acc: 0.8162 - val_loss: 1.1182 - val_acc: 0.7718\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3265 - acc: 0.8238 - val_loss: 1.0898 - val_acc: 0.7802\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2960 - acc: 0.8304 - val_loss: 1.0680 - val_acc: 0.7882\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2825 - acc: 0.8375 - val_loss: 1.1171 - val_acc: 0.7817\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2865 - acc: 0.8360 - val_loss: 1.0474 - val_acc: 0.7852\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2993 - acc: 0.8333 - val_loss: 1.0553 - val_acc: 0.7822\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2760 - acc: 0.8397 - val_loss: 1.0817 - val_acc: 0.7782\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2841 - acc: 0.8435 - val_loss: 1.1196 - val_acc: 0.7718\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2854 - acc: 0.8382 - val_loss: 1.0895 - val_acc: 0.7767\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2744 - acc: 0.8433 - val_loss: 1.0544 - val_acc: 0.7792\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2775 - acc: 0.8384 - val_loss: 1.0569 - val_acc: 0.7916\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2594 - acc: 0.8481 - val_loss: 1.0590 - val_acc: 0.7951\n",
            "Epoch 47/200\n",
            "566/566 - 7s - loss: 0.2558 - acc: 0.8534 - val_loss: 1.0298 - val_acc: 0.7981\n",
            "Epoch 48/200\n",
            "566/566 - 7s - loss: 0.2552 - acc: 0.8525 - val_loss: 1.0958 - val_acc: 0.7877\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2401 - acc: 0.8553 - val_loss: 1.0274 - val_acc: 0.7916\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2574 - acc: 0.8507 - val_loss: 1.0527 - val_acc: 0.7936\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2503 - acc: 0.8556 - val_loss: 1.0853 - val_acc: 0.7986\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2320 - acc: 0.8575 - val_loss: 1.0636 - val_acc: 0.7976\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2339 - acc: 0.8618 - val_loss: 1.0597 - val_acc: 0.7971\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2327 - acc: 0.8577 - val_loss: 1.0564 - val_acc: 0.7946\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2244 - acc: 0.8628 - val_loss: 1.0567 - val_acc: 0.7966\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2227 - acc: 0.8678 - val_loss: 1.0664 - val_acc: 0.7986\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2404 - acc: 0.8613 - val_loss: 1.0474 - val_acc: 0.7931\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2248 - acc: 0.8624 - val_loss: 1.0543 - val_acc: 0.7892\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2275 - acc: 0.8629 - val_loss: 1.0352 - val_acc: 0.8016\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2266 - acc: 0.8612 - val_loss: 1.0732 - val_acc: 0.8001\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2200 - acc: 0.8643 - val_loss: 1.0428 - val_acc: 0.7961\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2051 - acc: 0.8742 - val_loss: 1.0124 - val_acc: 0.8056\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2021 - acc: 0.8755 - val_loss: 1.0275 - val_acc: 0.8081\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2139 - acc: 0.8720 - val_loss: 1.0699 - val_acc: 0.8041\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.2103 - acc: 0.8719 - val_loss: 1.1114 - val_acc: 0.7902\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1988 - acc: 0.8788 - val_loss: 1.0892 - val_acc: 0.8011\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.2118 - acc: 0.8716 - val_loss: 1.0458 - val_acc: 0.8081\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1964 - acc: 0.8753 - val_loss: 1.0219 - val_acc: 0.8076\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1854 - acc: 0.8846 - val_loss: 1.0393 - val_acc: 0.8006\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1852 - acc: 0.8794 - val_loss: 1.0389 - val_acc: 0.8100\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1940 - acc: 0.8827 - val_loss: 1.0126 - val_acc: 0.8066\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.2000 - acc: 0.8793 - val_loss: 1.0366 - val_acc: 0.8091\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1809 - acc: 0.8820 - val_loss: 1.0107 - val_acc: 0.8165\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1776 - acc: 0.8855 - val_loss: 1.0273 - val_acc: 0.8120\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1767 - acc: 0.8862 - val_loss: 1.0596 - val_acc: 0.8165\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1977 - acc: 0.8823 - val_loss: 1.0137 - val_acc: 0.8175\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1783 - acc: 0.8840 - val_loss: 1.0096 - val_acc: 0.8250\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1857 - acc: 0.8845 - val_loss: 1.0176 - val_acc: 0.8071\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1765 - acc: 0.8876 - val_loss: 0.9940 - val_acc: 0.8170\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1770 - acc: 0.8893 - val_loss: 1.0379 - val_acc: 0.8105\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1766 - acc: 0.8897 - val_loss: 1.0740 - val_acc: 0.8086\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1731 - acc: 0.8918 - val_loss: 1.0342 - val_acc: 0.8081\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1623 - acc: 0.8949 - val_loss: 1.0414 - val_acc: 0.8170\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1736 - acc: 0.8945 - val_loss: 1.0694 - val_acc: 0.8091\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1596 - acc: 0.8960 - val_loss: 1.0592 - val_acc: 0.8210\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1587 - acc: 0.8959 - val_loss: 1.0008 - val_acc: 0.8245\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1571 - acc: 0.8987 - val_loss: 0.9930 - val_acc: 0.8225\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1588 - acc: 0.8962 - val_loss: 1.0256 - val_acc: 0.8309\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1657 - acc: 0.8988 - val_loss: 1.0427 - val_acc: 0.8225\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1546 - acc: 0.8961 - val_loss: 1.0297 - val_acc: 0.8225\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1845 - acc: 0.8916 - val_loss: 1.0232 - val_acc: 0.8255\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1631 - acc: 0.8989 - val_loss: 1.0229 - val_acc: 0.8210\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1535 - acc: 0.9002 - val_loss: 0.9935 - val_acc: 0.8299\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1612 - acc: 0.8947 - val_loss: 0.9976 - val_acc: 0.8265\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1503 - acc: 0.8977 - val_loss: 1.0341 - val_acc: 0.8225\n",
            "Epoch 96/200\n",
            "566/566 - 7s - loss: 0.1549 - acc: 0.9009 - val_loss: 0.9613 - val_acc: 0.8274\n",
            "Epoch 97/200\n",
            "566/566 - 7s - loss: 0.1633 - acc: 0.8972 - val_loss: 0.9908 - val_acc: 0.8185\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1563 - acc: 0.8977 - val_loss: 1.0256 - val_acc: 0.8175\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1510 - acc: 0.9042 - val_loss: 1.0075 - val_acc: 0.8165\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1480 - acc: 0.9050 - val_loss: 1.0037 - val_acc: 0.8205\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1401 - acc: 0.9042 - val_loss: 1.0183 - val_acc: 0.8235\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1380 - acc: 0.9081 - val_loss: 1.0048 - val_acc: 0.8289\n",
            "Epoch 103/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1519 - acc: 0.9036 - val_loss: 1.0461 - val_acc: 0.8225\n",
            "Epoch 00103: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.78952331 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 6/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4742 - acc: 0.0379 - val_loss: 4.3511 - val_acc: 0.2039\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.3637 - acc: 0.2426 - val_loss: 2.2361 - val_acc: 0.4530\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.0905 - acc: 0.3988 - val_loss: 1.7334 - val_acc: 0.5510\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5320 - acc: 0.4907 - val_loss: 1.4989 - val_acc: 0.6017\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2535 - acc: 0.5469 - val_loss: 1.3840 - val_acc: 0.6395\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0731 - acc: 0.5836 - val_loss: 1.3077 - val_acc: 0.6629\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9337 - acc: 0.6175 - val_loss: 1.2249 - val_acc: 0.6773\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8533 - acc: 0.6404 - val_loss: 1.2169 - val_acc: 0.6907\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7838 - acc: 0.6565 - val_loss: 1.1344 - val_acc: 0.7210\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.6992 - acc: 0.6890 - val_loss: 1.2014 - val_acc: 0.7006\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.7098 - acc: 0.6834 - val_loss: 1.1630 - val_acc: 0.7240\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6433 - acc: 0.6960 - val_loss: 1.1039 - val_acc: 0.7320\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6328 - acc: 0.7095 - val_loss: 1.1329 - val_acc: 0.7399\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5628 - acc: 0.7303 - val_loss: 1.1048 - val_acc: 0.7449\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5955 - acc: 0.7289 - val_loss: 1.1215 - val_acc: 0.7315\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5699 - acc: 0.7296 - val_loss: 1.1269 - val_acc: 0.7350\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5079 - acc: 0.7466 - val_loss: 1.0926 - val_acc: 0.7464\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4887 - acc: 0.7533 - val_loss: 1.0628 - val_acc: 0.7578\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4555 - acc: 0.7674 - val_loss: 1.1003 - val_acc: 0.7509\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4574 - acc: 0.7686 - val_loss: 1.1277 - val_acc: 0.7539\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4588 - acc: 0.7645 - val_loss: 1.0607 - val_acc: 0.7663\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4519 - acc: 0.7708 - val_loss: 0.9807 - val_acc: 0.7827\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.3985 - acc: 0.7866 - val_loss: 1.0205 - val_acc: 0.7638\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4212 - acc: 0.7814 - val_loss: 1.0642 - val_acc: 0.7683\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.4100 - acc: 0.7835 - val_loss: 1.0965 - val_acc: 0.7603\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3860 - acc: 0.7901 - val_loss: 1.0428 - val_acc: 0.7643\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3921 - acc: 0.7886 - val_loss: 1.0869 - val_acc: 0.7713\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3782 - acc: 0.7991 - val_loss: 1.0227 - val_acc: 0.7822\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3514 - acc: 0.8069 - val_loss: 1.0696 - val_acc: 0.7658\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3614 - acc: 0.8081 - val_loss: 1.0462 - val_acc: 0.7663\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3636 - acc: 0.8026 - val_loss: 1.0393 - val_acc: 0.7762\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3316 - acc: 0.8146 - val_loss: 1.0028 - val_acc: 0.7931\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3386 - acc: 0.8146 - val_loss: 1.0102 - val_acc: 0.7827\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3155 - acc: 0.8290 - val_loss: 1.0008 - val_acc: 0.7926\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3151 - acc: 0.8260 - val_loss: 1.0103 - val_acc: 0.7911\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2915 - acc: 0.8240 - val_loss: 0.9736 - val_acc: 0.7921\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.3058 - acc: 0.8255 - val_loss: 0.9655 - val_acc: 0.7971\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.3068 - acc: 0.8278 - val_loss: 1.0429 - val_acc: 0.7797\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2972 - acc: 0.8275 - val_loss: 1.0075 - val_acc: 0.7916\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2795 - acc: 0.8336 - val_loss: 1.0123 - val_acc: 0.7971\n",
            "Epoch 41/200\n",
            "566/566 - 7s - loss: 0.2704 - acc: 0.8398 - val_loss: 1.0282 - val_acc: 0.7907\n",
            "Epoch 42/200\n",
            "566/566 - 7s - loss: 0.2734 - acc: 0.8409 - val_loss: 0.9731 - val_acc: 0.8145\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2838 - acc: 0.8412 - val_loss: 0.9786 - val_acc: 0.7971\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2707 - acc: 0.8404 - val_loss: 0.9896 - val_acc: 0.8026\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2814 - acc: 0.8412 - val_loss: 1.0475 - val_acc: 0.7911\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2468 - acc: 0.8499 - val_loss: 1.0236 - val_acc: 0.8011\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2393 - acc: 0.8503 - val_loss: 1.0210 - val_acc: 0.8011\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2545 - acc: 0.8571 - val_loss: 1.0214 - val_acc: 0.8081\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2571 - acc: 0.8498 - val_loss: 1.0343 - val_acc: 0.8021\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2478 - acc: 0.8549 - val_loss: 1.0672 - val_acc: 0.8001\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2467 - acc: 0.8522 - val_loss: 1.0139 - val_acc: 0.8125\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2439 - acc: 0.8570 - val_loss: 1.0664 - val_acc: 0.7931\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2300 - acc: 0.8633 - val_loss: 1.0126 - val_acc: 0.8031\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2237 - acc: 0.8616 - val_loss: 1.0545 - val_acc: 0.7946\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2268 - acc: 0.8622 - val_loss: 1.0442 - val_acc: 0.8076\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2256 - acc: 0.8617 - val_loss: 1.0243 - val_acc: 0.8081\n",
            "Epoch 57/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.2152 - acc: 0.8667 - val_loss: 1.0219 - val_acc: 0.8066\n",
            "Epoch 00057: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.79945703 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 7/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4717 - acc: 0.0392 - val_loss: 4.3136 - val_acc: 0.1979\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.4146 - acc: 0.2362 - val_loss: 2.3242 - val_acc: 0.4058\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.1380 - acc: 0.3927 - val_loss: 1.8383 - val_acc: 0.5196\n",
            "Epoch 4/200\n",
            "566/566 - 7s - loss: 1.5906 - acc: 0.4788 - val_loss: 1.6158 - val_acc: 0.5833\n",
            "Epoch 5/200\n",
            "566/566 - 7s - loss: 1.2656 - acc: 0.5446 - val_loss: 1.4405 - val_acc: 0.6380\n",
            "Epoch 6/200\n",
            "566/566 - 7s - loss: 1.0620 - acc: 0.5861 - val_loss: 1.3978 - val_acc: 0.6355\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9404 - acc: 0.6186 - val_loss: 1.2548 - val_acc: 0.6648\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8539 - acc: 0.6398 - val_loss: 1.2724 - val_acc: 0.6748\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7651 - acc: 0.6682 - val_loss: 1.1845 - val_acc: 0.7066\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7480 - acc: 0.6726 - val_loss: 1.1785 - val_acc: 0.7086\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6955 - acc: 0.6879 - val_loss: 1.1701 - val_acc: 0.7176\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6609 - acc: 0.6972 - val_loss: 1.1567 - val_acc: 0.7036\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6102 - acc: 0.7158 - val_loss: 1.1468 - val_acc: 0.7126\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5760 - acc: 0.7221 - val_loss: 1.1743 - val_acc: 0.7176\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5429 - acc: 0.7333 - val_loss: 1.0952 - val_acc: 0.7275\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5256 - acc: 0.7391 - val_loss: 1.0704 - val_acc: 0.7434\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.4923 - acc: 0.7473 - val_loss: 1.1032 - val_acc: 0.7399\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4726 - acc: 0.7616 - val_loss: 1.0334 - val_acc: 0.7529\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.5028 - acc: 0.7600 - val_loss: 1.0251 - val_acc: 0.7563\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4774 - acc: 0.7636 - val_loss: 1.1196 - val_acc: 0.7449\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4216 - acc: 0.7744 - val_loss: 1.0706 - val_acc: 0.7454\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4431 - acc: 0.7788 - val_loss: 1.0658 - val_acc: 0.7544\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4137 - acc: 0.7838 - val_loss: 1.1049 - val_acc: 0.7494\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4123 - acc: 0.7829 - val_loss: 1.0498 - val_acc: 0.7544\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3907 - acc: 0.7902 - val_loss: 1.0166 - val_acc: 0.7708\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3733 - acc: 0.7989 - val_loss: 0.9963 - val_acc: 0.7747\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3778 - acc: 0.7988 - val_loss: 1.0710 - val_acc: 0.7534\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3657 - acc: 0.8025 - val_loss: 1.0340 - val_acc: 0.7668\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3558 - acc: 0.8037 - val_loss: 1.0968 - val_acc: 0.7539\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3537 - acc: 0.8076 - val_loss: 1.0674 - val_acc: 0.7653\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3372 - acc: 0.8115 - val_loss: 1.0520 - val_acc: 0.7703\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3218 - acc: 0.8205 - val_loss: 1.0461 - val_acc: 0.7708\n",
            "Epoch 33/200\n",
            "566/566 - 7s - loss: 0.3339 - acc: 0.8183 - val_loss: 1.0578 - val_acc: 0.7792\n",
            "Epoch 34/200\n",
            "566/566 - 7s - loss: 0.3188 - acc: 0.8212 - val_loss: 1.0075 - val_acc: 0.7897\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3527 - acc: 0.8190 - val_loss: 1.1410 - val_acc: 0.7573\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3075 - acc: 0.8196 - val_loss: 1.0712 - val_acc: 0.7678\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2946 - acc: 0.8352 - val_loss: 1.0368 - val_acc: 0.7911\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2859 - acc: 0.8361 - val_loss: 0.9820 - val_acc: 0.7941\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.3023 - acc: 0.8322 - val_loss: 1.0703 - val_acc: 0.7787\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2985 - acc: 0.8310 - val_loss: 1.0309 - val_acc: 0.7817\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2717 - acc: 0.8357 - val_loss: 1.0463 - val_acc: 0.7787\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2760 - acc: 0.8398 - val_loss: 1.0549 - val_acc: 0.7777\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2903 - acc: 0.8376 - val_loss: 1.0365 - val_acc: 0.7842\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2653 - acc: 0.8419 - val_loss: 0.9745 - val_acc: 0.7897\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2642 - acc: 0.8456 - val_loss: 1.0444 - val_acc: 0.7872\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2484 - acc: 0.8503 - val_loss: 0.9877 - val_acc: 0.7966\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2339 - acc: 0.8557 - val_loss: 1.0369 - val_acc: 0.7911\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2562 - acc: 0.8494 - val_loss: 1.0220 - val_acc: 0.7887\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2442 - acc: 0.8509 - val_loss: 1.0457 - val_acc: 0.7832\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2531 - acc: 0.8518 - val_loss: 1.0401 - val_acc: 0.7936\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2383 - acc: 0.8574 - val_loss: 1.0052 - val_acc: 0.8046\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2407 - acc: 0.8621 - val_loss: 0.9969 - val_acc: 0.8001\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2204 - acc: 0.8604 - val_loss: 1.0382 - val_acc: 0.8071\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2238 - acc: 0.8642 - val_loss: 1.0431 - val_acc: 0.7966\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2332 - acc: 0.8601 - val_loss: 1.0849 - val_acc: 0.7916\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2338 - acc: 0.8599 - val_loss: 1.0363 - val_acc: 0.7986\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2046 - acc: 0.8711 - val_loss: 1.0513 - val_acc: 0.7956\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2290 - acc: 0.8690 - val_loss: 1.0185 - val_acc: 0.8051\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2087 - acc: 0.8688 - val_loss: 0.9847 - val_acc: 0.8091\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2160 - acc: 0.8657 - val_loss: 1.0207 - val_acc: 0.8001\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2154 - acc: 0.8654 - val_loss: 1.0494 - val_acc: 0.7966\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2070 - acc: 0.8697 - val_loss: 1.0342 - val_acc: 0.7916\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2189 - acc: 0.8694 - val_loss: 1.1031 - val_acc: 0.7872\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2080 - acc: 0.8705 - val_loss: 1.0488 - val_acc: 0.7986\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1908 - acc: 0.8777 - val_loss: 1.0723 - val_acc: 0.7991\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1995 - acc: 0.8812 - val_loss: 1.0434 - val_acc: 0.8046\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1881 - acc: 0.8833 - val_loss: 1.0351 - val_acc: 0.7991\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1992 - acc: 0.8774 - val_loss: 1.0381 - val_acc: 0.7907\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1996 - acc: 0.8784 - val_loss: 1.0426 - val_acc: 0.8046\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.2014 - acc: 0.8744 - val_loss: 1.0635 - val_acc: 0.7936\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.2015 - acc: 0.8747 - val_loss: 1.0707 - val_acc: 0.7971\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1788 - acc: 0.8801 - val_loss: 1.0502 - val_acc: 0.8051\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1689 - acc: 0.8871 - val_loss: 1.0196 - val_acc: 0.8086\n",
            "Epoch 74/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1820 - acc: 0.8849 - val_loss: 1.0446 - val_acc: 0.8051\n",
            "Epoch 00074: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.78994648 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 8/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4198 - acc: 0.0438 - val_loss: 4.1899 - val_acc: 0.2438\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.3108 - acc: 0.2488 - val_loss: 2.2003 - val_acc: 0.4632\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.0901 - acc: 0.3953 - val_loss: 1.8045 - val_acc: 0.5378\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5699 - acc: 0.4852 - val_loss: 1.4773 - val_acc: 0.6114\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2408 - acc: 0.5472 - val_loss: 1.4148 - val_acc: 0.6313\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0782 - acc: 0.5822 - val_loss: 1.4285 - val_acc: 0.6373\n",
            "Epoch 7/200\n",
            "566/566 - 7s - loss: 0.9646 - acc: 0.6126 - val_loss: 1.2274 - val_acc: 0.6950\n",
            "Epoch 8/200\n",
            "566/566 - 7s - loss: 0.8502 - acc: 0.6460 - val_loss: 1.2245 - val_acc: 0.6886\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7805 - acc: 0.6643 - val_loss: 1.1580 - val_acc: 0.7174\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7337 - acc: 0.6748 - val_loss: 1.0801 - val_acc: 0.7433\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.7071 - acc: 0.6866 - val_loss: 1.2398 - val_acc: 0.7090\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6421 - acc: 0.6990 - val_loss: 1.1143 - val_acc: 0.7318\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.5865 - acc: 0.7203 - val_loss: 1.0806 - val_acc: 0.7532\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5748 - acc: 0.7246 - val_loss: 1.1277 - val_acc: 0.7403\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5317 - acc: 0.7364 - val_loss: 1.0034 - val_acc: 0.7706\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5332 - acc: 0.7391 - val_loss: 1.1100 - val_acc: 0.7537\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.4968 - acc: 0.7495 - val_loss: 1.0350 - val_acc: 0.7642\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4885 - acc: 0.7546 - val_loss: 1.1282 - val_acc: 0.7423\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4750 - acc: 0.7538 - val_loss: 1.0889 - val_acc: 0.7627\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4678 - acc: 0.7674 - val_loss: 1.0517 - val_acc: 0.7692\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4481 - acc: 0.7681 - val_loss: 1.0042 - val_acc: 0.7806\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4488 - acc: 0.7663 - val_loss: 1.0723 - val_acc: 0.7791\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4291 - acc: 0.7801 - val_loss: 1.0599 - val_acc: 0.7711\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3938 - acc: 0.7887 - val_loss: 1.0688 - val_acc: 0.7662\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3777 - acc: 0.7962 - val_loss: 1.0318 - val_acc: 0.7846\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3862 - acc: 0.7951 - val_loss: 1.0705 - val_acc: 0.7766\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.4095 - acc: 0.7846 - val_loss: 1.1382 - val_acc: 0.7741\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3868 - acc: 0.7914 - val_loss: 1.0561 - val_acc: 0.7920\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3569 - acc: 0.8062 - val_loss: 1.0403 - val_acc: 0.7876\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3469 - acc: 0.8106 - val_loss: 1.0624 - val_acc: 0.7881\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3638 - acc: 0.8087 - val_loss: 1.0183 - val_acc: 0.7881\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3633 - acc: 0.8088 - val_loss: 1.0741 - val_acc: 0.7796\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3521 - acc: 0.8126 - val_loss: 1.0999 - val_acc: 0.7746\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3099 - acc: 0.8205 - val_loss: 1.0750 - val_acc: 0.7886\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3090 - acc: 0.8231 - val_loss: 1.0663 - val_acc: 0.7900\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3105 - acc: 0.8224 - val_loss: 0.9853 - val_acc: 0.7945\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2925 - acc: 0.8283 - val_loss: 1.0378 - val_acc: 0.7990\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2959 - acc: 0.8284 - val_loss: 1.0352 - val_acc: 0.7930\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.3019 - acc: 0.8282 - val_loss: 1.0233 - val_acc: 0.7975\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.3159 - acc: 0.8281 - val_loss: 1.0870 - val_acc: 0.7945\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2995 - acc: 0.8287 - val_loss: 1.0638 - val_acc: 0.7925\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.3199 - acc: 0.8244 - val_loss: 1.0270 - val_acc: 0.8025\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2795 - acc: 0.8336 - val_loss: 1.0522 - val_acc: 0.7930\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2623 - acc: 0.8432 - val_loss: 1.0112 - val_acc: 0.8045\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2743 - acc: 0.8437 - val_loss: 1.0003 - val_acc: 0.8045\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2746 - acc: 0.8391 - val_loss: 0.9883 - val_acc: 0.8124\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2633 - acc: 0.8452 - val_loss: 1.0777 - val_acc: 0.7910\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2337 - acc: 0.8545 - val_loss: 1.0697 - val_acc: 0.8065\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2449 - acc: 0.8539 - val_loss: 1.0806 - val_acc: 0.8035\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2577 - acc: 0.8476 - val_loss: 1.1016 - val_acc: 0.7970\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2521 - acc: 0.8552 - val_loss: 0.9961 - val_acc: 0.8114\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2418 - acc: 0.8586 - val_loss: 1.0147 - val_acc: 0.8065\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2402 - acc: 0.8580 - val_loss: 1.0443 - val_acc: 0.8080\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2352 - acc: 0.8616 - val_loss: 1.0555 - val_acc: 0.8040\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2297 - acc: 0.8627 - val_loss: 1.0274 - val_acc: 0.8060\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2330 - acc: 0.8628 - val_loss: 1.0283 - val_acc: 0.8119\n",
            "Epoch 57/200\n",
            "566/566 - 7s - loss: 0.2288 - acc: 0.8620 - val_loss: 1.0276 - val_acc: 0.8104\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2214 - acc: 0.8646 - val_loss: 0.9958 - val_acc: 0.8199\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2126 - acc: 0.8691 - val_loss: 0.9794 - val_acc: 0.8244\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2314 - acc: 0.8608 - val_loss: 1.0576 - val_acc: 0.8080\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2083 - acc: 0.8673 - val_loss: 1.0192 - val_acc: 0.8124\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2109 - acc: 0.8698 - val_loss: 1.0411 - val_acc: 0.8080\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2153 - acc: 0.8676 - val_loss: 1.0516 - val_acc: 0.8104\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2176 - acc: 0.8706 - val_loss: 1.0418 - val_acc: 0.8164\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.2046 - acc: 0.8725 - val_loss: 1.0105 - val_acc: 0.8199\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.2051 - acc: 0.8763 - val_loss: 1.0017 - val_acc: 0.8194\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1998 - acc: 0.8765 - val_loss: 1.0362 - val_acc: 0.8204\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.2076 - acc: 0.8740 - val_loss: 1.0556 - val_acc: 0.8159\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1939 - acc: 0.8771 - val_loss: 1.0541 - val_acc: 0.8174\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1913 - acc: 0.8800 - val_loss: 0.9995 - val_acc: 0.8289\n",
            "Epoch 71/200\n",
            "566/566 - 7s - loss: 0.1980 - acc: 0.8777 - val_loss: 0.9986 - val_acc: 0.8303\n",
            "Epoch 72/200\n",
            "566/566 - 7s - loss: 0.1748 - acc: 0.8799 - val_loss: 0.9995 - val_acc: 0.8274\n",
            "Epoch 73/200\n",
            "566/566 - 7s - loss: 0.1826 - acc: 0.8827 - val_loss: 1.0774 - val_acc: 0.8139\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.2000 - acc: 0.8825 - val_loss: 1.0446 - val_acc: 0.8154\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.2007 - acc: 0.8782 - val_loss: 1.0087 - val_acc: 0.8189\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1829 - acc: 0.8871 - val_loss: 1.0540 - val_acc: 0.8124\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1878 - acc: 0.8835 - val_loss: 0.9963 - val_acc: 0.8219\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1808 - acc: 0.8871 - val_loss: 1.0080 - val_acc: 0.8214\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1832 - acc: 0.8849 - val_loss: 1.0367 - val_acc: 0.8254\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1823 - acc: 0.8852 - val_loss: 1.0272 - val_acc: 0.8199\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1694 - acc: 0.8915 - val_loss: 1.0237 - val_acc: 0.8289\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1844 - acc: 0.8885 - val_loss: 1.0378 - val_acc: 0.8169\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1680 - acc: 0.8904 - val_loss: 1.0284 - val_acc: 0.8249\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1803 - acc: 0.8863 - val_loss: 1.0867 - val_acc: 0.8154\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1736 - acc: 0.8894 - val_loss: 1.0419 - val_acc: 0.8194\n",
            "Epoch 86/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1618 - acc: 0.8958 - val_loss: 1.0070 - val_acc: 0.8219\n",
            "Epoch 00086: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.81810514 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 9/9\n",
            "Epoch 1/200\n",
            "566/566 - 7s - loss: 5.4389 - acc: 0.0377 - val_loss: 4.3265 - val_acc: 0.1796\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.3878 - acc: 0.2401 - val_loss: 2.2088 - val_acc: 0.4557\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.1114 - acc: 0.3969 - val_loss: 1.7976 - val_acc: 0.5458\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5445 - acc: 0.4840 - val_loss: 1.5001 - val_acc: 0.6000\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2442 - acc: 0.5442 - val_loss: 1.4442 - val_acc: 0.6119\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0680 - acc: 0.5774 - val_loss: 1.2011 - val_acc: 0.6791\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9622 - acc: 0.6107 - val_loss: 1.2118 - val_acc: 0.6801\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.9026 - acc: 0.6363 - val_loss: 1.2126 - val_acc: 0.6905\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7960 - acc: 0.6568 - val_loss: 1.1481 - val_acc: 0.7075\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.6992 - acc: 0.6801 - val_loss: 1.1076 - val_acc: 0.7274\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6861 - acc: 0.6870 - val_loss: 1.1213 - val_acc: 0.7239\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6557 - acc: 0.7010 - val_loss: 1.2486 - val_acc: 0.6935\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6204 - acc: 0.7126 - val_loss: 1.1346 - val_acc: 0.7244\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.6099 - acc: 0.7181 - val_loss: 1.1050 - val_acc: 0.7269\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5412 - acc: 0.7347 - val_loss: 1.1065 - val_acc: 0.7448\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5265 - acc: 0.7434 - val_loss: 1.0369 - val_acc: 0.7567\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5302 - acc: 0.7416 - val_loss: 1.1323 - val_acc: 0.7274\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.5029 - acc: 0.7532 - val_loss: 1.0597 - val_acc: 0.7443\n",
            "Epoch 19/200\n",
            "566/566 - 7s - loss: 0.4583 - acc: 0.7680 - val_loss: 1.0298 - val_acc: 0.7622\n",
            "Epoch 20/200\n",
            "566/566 - 7s - loss: 0.4643 - acc: 0.7690 - val_loss: 1.0618 - val_acc: 0.7647\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4875 - acc: 0.7648 - val_loss: 1.0372 - val_acc: 0.7781\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4452 - acc: 0.7712 - val_loss: 1.0682 - val_acc: 0.7597\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4136 - acc: 0.7834 - val_loss: 1.0261 - val_acc: 0.7806\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.4005 - acc: 0.7921 - val_loss: 1.0694 - val_acc: 0.7677\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3913 - acc: 0.7957 - val_loss: 1.0729 - val_acc: 0.7672\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3858 - acc: 0.7906 - val_loss: 1.0324 - val_acc: 0.7721\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3809 - acc: 0.7933 - val_loss: 1.0239 - val_acc: 0.7687\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3888 - acc: 0.8010 - val_loss: 1.1253 - val_acc: 0.7557\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3882 - acc: 0.7911 - val_loss: 1.0529 - val_acc: 0.7846\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3734 - acc: 0.8012 - val_loss: 1.0780 - val_acc: 0.7776\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3402 - acc: 0.8119 - val_loss: 1.0046 - val_acc: 0.7741\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3425 - acc: 0.8105 - val_loss: 1.0368 - val_acc: 0.7776\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3224 - acc: 0.8181 - val_loss: 1.0088 - val_acc: 0.7761\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3118 - acc: 0.8178 - val_loss: 1.0672 - val_acc: 0.7657\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3378 - acc: 0.8219 - val_loss: 1.0168 - val_acc: 0.7801\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3181 - acc: 0.8252 - val_loss: 1.0248 - val_acc: 0.7806\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.3364 - acc: 0.8200 - val_loss: 1.0003 - val_acc: 0.7935\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.3263 - acc: 0.8240 - val_loss: 1.0862 - val_acc: 0.7716\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2984 - acc: 0.8248 - val_loss: 1.0226 - val_acc: 0.7866\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2868 - acc: 0.8369 - val_loss: 1.0303 - val_acc: 0.7876\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2808 - acc: 0.8367 - val_loss: 1.0158 - val_acc: 0.7935\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2848 - acc: 0.8343 - val_loss: 1.0211 - val_acc: 0.7930\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2657 - acc: 0.8419 - val_loss: 0.9995 - val_acc: 0.7980\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2694 - acc: 0.8441 - val_loss: 1.0108 - val_acc: 0.7930\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2610 - acc: 0.8484 - val_loss: 1.0200 - val_acc: 0.8030\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2677 - acc: 0.8466 - val_loss: 1.0525 - val_acc: 0.7891\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2811 - acc: 0.8430 - val_loss: 1.0141 - val_acc: 0.7945\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2512 - acc: 0.8509 - val_loss: 1.0051 - val_acc: 0.7995\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2684 - acc: 0.8474 - val_loss: 1.0092 - val_acc: 0.8020\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2351 - acc: 0.8629 - val_loss: 0.9997 - val_acc: 0.8020\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2420 - acc: 0.8541 - val_loss: 1.0261 - val_acc: 0.7995\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2445 - acc: 0.8551 - val_loss: 1.0333 - val_acc: 0.8010\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2399 - acc: 0.8553 - val_loss: 1.0702 - val_acc: 0.7851\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2332 - acc: 0.8592 - val_loss: 1.0043 - val_acc: 0.8015\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2191 - acc: 0.8645 - val_loss: 0.9808 - val_acc: 0.7950\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2413 - acc: 0.8609 - val_loss: 1.0412 - val_acc: 0.7945\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2286 - acc: 0.8648 - val_loss: 0.9940 - val_acc: 0.7980\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2211 - acc: 0.8637 - val_loss: 1.0340 - val_acc: 0.8104\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2214 - acc: 0.8640 - val_loss: 1.0395 - val_acc: 0.7980\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2185 - acc: 0.8677 - val_loss: 1.0886 - val_acc: 0.7960\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.2061 - acc: 0.8701 - val_loss: 1.0325 - val_acc: 0.8055\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2022 - acc: 0.8715 - val_loss: 1.0104 - val_acc: 0.8085\n",
            "Epoch 63/200\n",
            "566/566 - 7s - loss: 0.1972 - acc: 0.8748 - val_loss: 1.0139 - val_acc: 0.8109\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2012 - acc: 0.8769 - val_loss: 1.0320 - val_acc: 0.8040\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.2073 - acc: 0.8726 - val_loss: 1.0496 - val_acc: 0.8065\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.2071 - acc: 0.8754 - val_loss: 0.9915 - val_acc: 0.8124\n",
            "Epoch 67/200\n",
            "566/566 - 7s - loss: 0.1922 - acc: 0.8796 - val_loss: 1.0764 - val_acc: 0.7985\n",
            "Epoch 68/200\n",
            "566/566 - 7s - loss: 0.1919 - acc: 0.8755 - val_loss: 0.9983 - val_acc: 0.8134\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1969 - acc: 0.8765 - val_loss: 0.9911 - val_acc: 0.8124\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1996 - acc: 0.8771 - val_loss: 1.0360 - val_acc: 0.8070\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1950 - acc: 0.8787 - val_loss: 0.9982 - val_acc: 0.8025\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1917 - acc: 0.8797 - val_loss: 1.0187 - val_acc: 0.7970\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1745 - acc: 0.8861 - val_loss: 0.9940 - val_acc: 0.8119\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1900 - acc: 0.8819 - val_loss: 1.0234 - val_acc: 0.8139\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1782 - acc: 0.8841 - val_loss: 1.0014 - val_acc: 0.8109\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1879 - acc: 0.8881 - val_loss: 1.0635 - val_acc: 0.7960\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1775 - acc: 0.8874 - val_loss: 1.0165 - val_acc: 0.8040\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1888 - acc: 0.8856 - val_loss: 0.9700 - val_acc: 0.8095\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1780 - acc: 0.8861 - val_loss: 1.0201 - val_acc: 0.8055\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1750 - acc: 0.8916 - val_loss: 1.0057 - val_acc: 0.8129\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1800 - acc: 0.8879 - val_loss: 1.0098 - val_acc: 0.8114\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1662 - acc: 0.8914 - val_loss: 0.9980 - val_acc: 0.8055\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1782 - acc: 0.8881 - val_loss: 1.0159 - val_acc: 0.8080\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1611 - acc: 0.8955 - val_loss: 1.0121 - val_acc: 0.8134\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1620 - acc: 0.8933 - val_loss: 1.0086 - val_acc: 0.8104\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1588 - acc: 0.8967 - val_loss: 1.0029 - val_acc: 0.8104\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1620 - acc: 0.8936 - val_loss: 0.9766 - val_acc: 0.8154\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1603 - acc: 0.8968 - val_loss: 1.0008 - val_acc: 0.8189\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1601 - acc: 0.8950 - val_loss: 1.0483 - val_acc: 0.8055\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1712 - acc: 0.8947 - val_loss: 1.0069 - val_acc: 0.8149\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1652 - acc: 0.8975 - val_loss: 1.0174 - val_acc: 0.8184\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1734 - acc: 0.8939 - val_loss: 1.0047 - val_acc: 0.8214\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1698 - acc: 0.8974 - val_loss: 1.0427 - val_acc: 0.8095\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1485 - acc: 0.9023 - val_loss: 0.9852 - val_acc: 0.8194\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1518 - acc: 0.8974 - val_loss: 1.0162 - val_acc: 0.8174\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1544 - acc: 0.8989 - val_loss: 0.9801 - val_acc: 0.8224\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1549 - acc: 0.9026 - val_loss: 1.0040 - val_acc: 0.8244\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1380 - acc: 0.9057 - val_loss: 1.0078 - val_acc: 0.8189\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1600 - acc: 0.8986 - val_loss: 1.0015 - val_acc: 0.8194\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1650 - acc: 0.8986 - val_loss: 1.0216 - val_acc: 0.8194\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1503 - acc: 0.9015 - val_loss: 0.9861 - val_acc: 0.8279\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1536 - acc: 0.9039 - val_loss: 0.9892 - val_acc: 0.8323\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1417 - acc: 0.9027 - val_loss: 0.9969 - val_acc: 0.8234\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1383 - acc: 0.9083 - val_loss: 1.0589 - val_acc: 0.8154\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1494 - acc: 0.9050 - val_loss: 0.9976 - val_acc: 0.8244\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1380 - acc: 0.9082 - val_loss: 1.0234 - val_acc: 0.8149\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1345 - acc: 0.9076 - val_loss: 1.0037 - val_acc: 0.8219\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1306 - acc: 0.9089 - val_loss: 1.0172 - val_acc: 0.8194\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1384 - acc: 0.9104 - val_loss: 1.0196 - val_acc: 0.8279\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1320 - acc: 0.9120 - val_loss: 1.0034 - val_acc: 0.8244\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1345 - acc: 0.9093 - val_loss: 0.9933 - val_acc: 0.8254\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1424 - acc: 0.9121 - val_loss: 1.0257 - val_acc: 0.8284\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1325 - acc: 0.9104 - val_loss: 0.9767 - val_acc: 0.8299\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1516 - acc: 0.9071 - val_loss: 1.0165 - val_acc: 0.8204\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1379 - acc: 0.9117 - val_loss: 1.0080 - val_acc: 0.8279\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1436 - acc: 0.9057 - val_loss: 1.0453 - val_acc: 0.8159\n",
            "Epoch 117/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 7s - loss: 0.1384 - acc: 0.9092 - val_loss: 1.0283 - val_acc: 0.8174\n",
            "Epoch 00117: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.81170810 ##########\n",
            "\n",
            "\n",
            "########## Global Balanced Acc: 0.80391432 ##########\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM8bB1FFtKjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f359c26-ace8-49a4-bcf6-d117c0809e4f"
      },
      "source": [
        "gru_models, gru_scores = trainModel(gru=True)\n",
        "np.save('gru.npy', ensemble_pred(gru_models, processed_test_questions, False))\n",
        "\n",
        "print('\\n Done training GRU model, starting LSTM Model')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ðŸš€ Starting kfold iteration: 0/9\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, 30, 120)           405480    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_10 (Spatia (None, 30, 120)           0         \n",
            "_________________________________________________________________\n",
            "BGRU (Bidirectional)         (None, 30, 480)           521280    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_10 (Glo (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               246272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 352)               180576    \n",
            "=================================================================\n",
            "Total params: 1,355,656\n",
            "Trainable params: 1,354,632\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.3102 - acc: 0.0616 - val_loss: 3.9086 - val_acc: 0.2442\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1254 - acc: 0.2739 - val_loss: 2.1427 - val_acc: 0.4635\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9727 - acc: 0.4221 - val_loss: 1.7633 - val_acc: 0.5415\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5135 - acc: 0.4955 - val_loss: 1.4072 - val_acc: 0.6261\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2002 - acc: 0.5625 - val_loss: 1.2925 - val_acc: 0.6653\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0524 - acc: 0.5981 - val_loss: 1.2684 - val_acc: 0.6678\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9477 - acc: 0.6215 - val_loss: 1.2434 - val_acc: 0.6773\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8305 - acc: 0.6445 - val_loss: 1.2120 - val_acc: 0.6932\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7662 - acc: 0.6545 - val_loss: 1.1330 - val_acc: 0.7156\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.6899 - acc: 0.6826 - val_loss: 1.1188 - val_acc: 0.7146\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6561 - acc: 0.6953 - val_loss: 1.1464 - val_acc: 0.7200\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6252 - acc: 0.7076 - val_loss: 1.1204 - val_acc: 0.7350\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6305 - acc: 0.7135 - val_loss: 1.1571 - val_acc: 0.7111\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5577 - acc: 0.7261 - val_loss: 1.0532 - val_acc: 0.7504\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5240 - acc: 0.7400 - val_loss: 1.0697 - val_acc: 0.7529\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5246 - acc: 0.7387 - val_loss: 1.0318 - val_acc: 0.7563\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5340 - acc: 0.7411 - val_loss: 1.0529 - val_acc: 0.7544\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4950 - acc: 0.7557 - val_loss: 1.0407 - val_acc: 0.7529\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4694 - acc: 0.7580 - val_loss: 1.0159 - val_acc: 0.7678\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4465 - acc: 0.7686 - val_loss: 1.0411 - val_acc: 0.7563\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4148 - acc: 0.7743 - val_loss: 1.0229 - val_acc: 0.7588\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4332 - acc: 0.7802 - val_loss: 1.0650 - val_acc: 0.7499\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4071 - acc: 0.7819 - val_loss: 1.0610 - val_acc: 0.7638\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3677 - acc: 0.7976 - val_loss: 0.9736 - val_acc: 0.7718\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3485 - acc: 0.8022 - val_loss: 0.9698 - val_acc: 0.7797\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3560 - acc: 0.8065 - val_loss: 0.9547 - val_acc: 0.7911\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3807 - acc: 0.7990 - val_loss: 1.0173 - val_acc: 0.7737\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3571 - acc: 0.8068 - val_loss: 1.0092 - val_acc: 0.7782\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3417 - acc: 0.8080 - val_loss: 1.0183 - val_acc: 0.7822\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3407 - acc: 0.8155 - val_loss: 0.9718 - val_acc: 0.7832\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3134 - acc: 0.8178 - val_loss: 0.9812 - val_acc: 0.7897\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3171 - acc: 0.8173 - val_loss: 0.9969 - val_acc: 0.7921\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3282 - acc: 0.8238 - val_loss: 0.9701 - val_acc: 0.7956\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3017 - acc: 0.8289 - val_loss: 0.9340 - val_acc: 0.7986\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.2827 - acc: 0.8334 - val_loss: 0.9276 - val_acc: 0.7936\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2796 - acc: 0.8356 - val_loss: 0.9695 - val_acc: 0.8011\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2801 - acc: 0.8372 - val_loss: 1.0063 - val_acc: 0.7867\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2774 - acc: 0.8409 - val_loss: 0.9792 - val_acc: 0.7961\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2598 - acc: 0.8409 - val_loss: 0.9597 - val_acc: 0.8061\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2529 - acc: 0.8462 - val_loss: 0.9483 - val_acc: 0.8016\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2544 - acc: 0.8438 - val_loss: 0.9496 - val_acc: 0.8071\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2655 - acc: 0.8463 - val_loss: 0.9241 - val_acc: 0.8086\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2493 - acc: 0.8531 - val_loss: 0.9412 - val_acc: 0.8165\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2522 - acc: 0.8505 - val_loss: 0.9694 - val_acc: 0.8071\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2418 - acc: 0.8535 - val_loss: 1.0329 - val_acc: 0.7936\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2449 - acc: 0.8480 - val_loss: 0.9647 - val_acc: 0.8095\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2406 - acc: 0.8578 - val_loss: 0.9416 - val_acc: 0.8120\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2239 - acc: 0.8607 - val_loss: 0.9354 - val_acc: 0.8155\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2362 - acc: 0.8529 - val_loss: 0.9422 - val_acc: 0.8160\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2274 - acc: 0.8654 - val_loss: 0.9724 - val_acc: 0.8150\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2140 - acc: 0.8684 - val_loss: 0.9562 - val_acc: 0.8240\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2080 - acc: 0.8679 - val_loss: 0.9199 - val_acc: 0.8180\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2107 - acc: 0.8629 - val_loss: 1.0067 - val_acc: 0.8130\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2162 - acc: 0.8646 - val_loss: 0.9189 - val_acc: 0.8190\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.1975 - acc: 0.8758 - val_loss: 0.9613 - val_acc: 0.8190\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2009 - acc: 0.8717 - val_loss: 1.0032 - val_acc: 0.8125\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2012 - acc: 0.8701 - val_loss: 1.0006 - val_acc: 0.8150\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2221 - acc: 0.8691 - val_loss: 0.9955 - val_acc: 0.8046\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.1928 - acc: 0.8735 - val_loss: 0.9441 - val_acc: 0.8260\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1926 - acc: 0.8793 - val_loss: 0.9846 - val_acc: 0.8245\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1914 - acc: 0.8778 - val_loss: 0.9581 - val_acc: 0.8145\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2016 - acc: 0.8756 - val_loss: 0.9976 - val_acc: 0.8076\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.2014 - acc: 0.8755 - val_loss: 1.0306 - val_acc: 0.8100\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1837 - acc: 0.8842 - val_loss: 0.9308 - val_acc: 0.8284\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1771 - acc: 0.8823 - val_loss: 0.9483 - val_acc: 0.8175\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1741 - acc: 0.8850 - val_loss: 0.9347 - val_acc: 0.8185\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1669 - acc: 0.8893 - val_loss: 0.9986 - val_acc: 0.8225\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1779 - acc: 0.8893 - val_loss: 0.9724 - val_acc: 0.8160\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1788 - acc: 0.8863 - val_loss: 0.9544 - val_acc: 0.8220\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1907 - acc: 0.8802 - val_loss: 0.9316 - val_acc: 0.8240\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1849 - acc: 0.8862 - val_loss: 0.9744 - val_acc: 0.8150\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1852 - acc: 0.8834 - val_loss: 0.9556 - val_acc: 0.8220\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1642 - acc: 0.8918 - val_loss: 0.9287 - val_acc: 0.8319\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1773 - acc: 0.8866 - val_loss: 0.9125 - val_acc: 0.8240\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1703 - acc: 0.8879 - val_loss: 0.9534 - val_acc: 0.8339\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1678 - acc: 0.8985 - val_loss: 0.9485 - val_acc: 0.8339\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1584 - acc: 0.8942 - val_loss: 0.9387 - val_acc: 0.8299\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1731 - acc: 0.8923 - val_loss: 0.9076 - val_acc: 0.8309\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1556 - acc: 0.8950 - val_loss: 0.9139 - val_acc: 0.8225\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1577 - acc: 0.8952 - val_loss: 0.9296 - val_acc: 0.8245\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1563 - acc: 0.8995 - val_loss: 0.9305 - val_acc: 0.8364\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1657 - acc: 0.8933 - val_loss: 0.9473 - val_acc: 0.8319\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1479 - acc: 0.9027 - val_loss: 0.9565 - val_acc: 0.8279\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1526 - acc: 0.8983 - val_loss: 0.9505 - val_acc: 0.8265\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1579 - acc: 0.8946 - val_loss: 0.9424 - val_acc: 0.8284\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1495 - acc: 0.8998 - val_loss: 0.9577 - val_acc: 0.8329\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1514 - acc: 0.9042 - val_loss: 0.9808 - val_acc: 0.8324\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1433 - acc: 0.8989 - val_loss: 0.9935 - val_acc: 0.8279\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1420 - acc: 0.9027 - val_loss: 0.9827 - val_acc: 0.8274\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1417 - acc: 0.9030 - val_loss: 0.9589 - val_acc: 0.8349\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1487 - acc: 0.9018 - val_loss: 0.9622 - val_acc: 0.8299\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1285 - acc: 0.9083 - val_loss: 0.9907 - val_acc: 0.8299\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1552 - acc: 0.9042 - val_loss: 0.9846 - val_acc: 0.8349\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1392 - acc: 0.9051 - val_loss: 0.9452 - val_acc: 0.8414\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1363 - acc: 0.9078 - val_loss: 0.9528 - val_acc: 0.8359\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1413 - acc: 0.9081 - val_loss: 0.9521 - val_acc: 0.8344\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1312 - acc: 0.9073 - val_loss: 0.9388 - val_acc: 0.8399\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1247 - acc: 0.9127 - val_loss: 0.9571 - val_acc: 0.8344\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1517 - acc: 0.9023 - val_loss: 0.9623 - val_acc: 0.8334\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1445 - acc: 0.9072 - val_loss: 0.9470 - val_acc: 0.8364\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1383 - acc: 0.9058 - val_loss: 0.9260 - val_acc: 0.8389\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1249 - acc: 0.9104 - val_loss: 0.9497 - val_acc: 0.8399\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1221 - acc: 0.9140 - val_loss: 0.9499 - val_acc: 0.8434\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1321 - acc: 0.9156 - val_loss: 0.9657 - val_acc: 0.8349\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1282 - acc: 0.9108 - val_loss: 0.9169 - val_acc: 0.8439\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1327 - acc: 0.9109 - val_loss: 0.9504 - val_acc: 0.8409\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1410 - acc: 0.9103 - val_loss: 0.9181 - val_acc: 0.8414\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1313 - acc: 0.9107 - val_loss: 0.9183 - val_acc: 0.8449\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1303 - acc: 0.9127 - val_loss: 0.9252 - val_acc: 0.8399\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1178 - acc: 0.9210 - val_loss: 0.9399 - val_acc: 0.8409\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1336 - acc: 0.9136 - val_loss: 0.9542 - val_acc: 0.8463\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1356 - acc: 0.9165 - val_loss: 0.9663 - val_acc: 0.8409\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1250 - acc: 0.9140 - val_loss: 0.9737 - val_acc: 0.8404\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1194 - acc: 0.9166 - val_loss: 0.9825 - val_acc: 0.8364\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1198 - acc: 0.9166 - val_loss: 0.9748 - val_acc: 0.8329\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1194 - acc: 0.9156 - val_loss: 0.9350 - val_acc: 0.8419\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1253 - acc: 0.9161 - val_loss: 0.9597 - val_acc: 0.8409\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1243 - acc: 0.9123 - val_loss: 0.9630 - val_acc: 0.8399\n",
            "Epoch 119/200\n",
            "566/566 - 6s - loss: 0.1142 - acc: 0.9181 - val_loss: 0.9938 - val_acc: 0.8354\n",
            "Epoch 120/200\n",
            "566/566 - 6s - loss: 0.1060 - acc: 0.9221 - val_loss: 0.9935 - val_acc: 0.8478\n",
            "Epoch 121/200\n",
            "566/566 - 6s - loss: 0.1154 - acc: 0.9229 - val_loss: 0.9463 - val_acc: 0.8394\n",
            "Epoch 122/200\n",
            "566/566 - 6s - loss: 0.1074 - acc: 0.9231 - val_loss: 0.9670 - val_acc: 0.8483\n",
            "Epoch 123/200\n",
            "566/566 - 6s - loss: 0.1284 - acc: 0.9221 - val_loss: 0.9702 - val_acc: 0.8449\n",
            "Epoch 124/200\n",
            "566/566 - 6s - loss: 0.1160 - acc: 0.9158 - val_loss: 0.9663 - val_acc: 0.8394\n",
            "Epoch 125/200\n",
            "566/566 - 6s - loss: 0.1071 - acc: 0.9230 - val_loss: 0.9374 - val_acc: 0.8449\n",
            "Epoch 126/200\n",
            "566/566 - 6s - loss: 0.1157 - acc: 0.9233 - val_loss: 0.9484 - val_acc: 0.8409\n",
            "Epoch 127/200\n",
            "566/566 - 6s - loss: 0.1120 - acc: 0.9225 - val_loss: 0.9505 - val_acc: 0.8424\n",
            "Epoch 128/200\n",
            "566/566 - 6s - loss: 0.1083 - acc: 0.9217 - val_loss: 0.9872 - val_acc: 0.8349\n",
            "Epoch 129/200\n",
            "566/566 - 6s - loss: 0.1223 - acc: 0.9208 - val_loss: 0.9344 - val_acc: 0.8488\n",
            "Epoch 130/200\n",
            "566/566 - 6s - loss: 0.1147 - acc: 0.9182 - val_loss: 0.9399 - val_acc: 0.8493\n",
            "Epoch 131/200\n",
            "566/566 - 6s - loss: 0.1125 - acc: 0.9242 - val_loss: 0.9559 - val_acc: 0.8449\n",
            "Epoch 132/200\n",
            "566/566 - 6s - loss: 0.1155 - acc: 0.9202 - val_loss: 0.9820 - val_acc: 0.8429\n",
            "Epoch 133/200\n",
            "566/566 - 6s - loss: 0.1088 - acc: 0.9249 - val_loss: 0.9844 - val_acc: 0.8414\n",
            "Epoch 134/200\n",
            "566/566 - 6s - loss: 0.1160 - acc: 0.9229 - val_loss: 0.9915 - val_acc: 0.8384\n",
            "Epoch 135/200\n",
            "566/566 - 6s - loss: 0.1059 - acc: 0.9278 - val_loss: 0.9694 - val_acc: 0.8488\n",
            "Epoch 136/200\n",
            "566/566 - 6s - loss: 0.1084 - acc: 0.9247 - val_loss: 0.9509 - val_acc: 0.8468\n",
            "Epoch 137/200\n",
            "566/566 - 6s - loss: 0.1137 - acc: 0.9202 - val_loss: 0.9677 - val_acc: 0.8409\n",
            "Epoch 138/200\n",
            "566/566 - 6s - loss: 0.1143 - acc: 0.9221 - val_loss: 0.9728 - val_acc: 0.8429\n",
            "Epoch 139/200\n",
            "566/566 - 6s - loss: 0.1092 - acc: 0.9255 - val_loss: 0.9924 - val_acc: 0.8409\n",
            "Epoch 140/200\n",
            "566/566 - 6s - loss: 0.1107 - acc: 0.9237 - val_loss: 1.0239 - val_acc: 0.8339\n",
            "Epoch 141/200\n",
            "566/566 - 6s - loss: 0.1156 - acc: 0.9253 - val_loss: 0.9672 - val_acc: 0.8449\n",
            "Epoch 142/200\n",
            "566/566 - 6s - loss: 0.1169 - acc: 0.9260 - val_loss: 0.9948 - val_acc: 0.8424\n",
            "Epoch 143/200\n",
            "566/566 - 6s - loss: 0.1103 - acc: 0.9240 - val_loss: 0.9656 - val_acc: 0.8473\n",
            "Epoch 144/200\n",
            "566/566 - 6s - loss: 0.1067 - acc: 0.9242 - val_loss: 1.0044 - val_acc: 0.8429\n",
            "Epoch 145/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1024 - acc: 0.9292 - val_loss: 0.9819 - val_acc: 0.8409\n",
            "Epoch 00145: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Balanced Acc: 0.80808831 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 1/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.3656 - acc: 0.0544 - val_loss: 3.8824 - val_acc: 0.2546\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1676 - acc: 0.2759 - val_loss: 2.1954 - val_acc: 0.4684\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9654 - acc: 0.4191 - val_loss: 1.7817 - val_acc: 0.5356\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4594 - acc: 0.5021 - val_loss: 1.5319 - val_acc: 0.6022\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.1972 - acc: 0.5568 - val_loss: 1.5671 - val_acc: 0.6111\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0332 - acc: 0.5960 - val_loss: 1.3414 - val_acc: 0.6569\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9070 - acc: 0.6299 - val_loss: 1.2604 - val_acc: 0.6803\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8416 - acc: 0.6480 - val_loss: 1.3792 - val_acc: 0.6713\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7822 - acc: 0.6587 - val_loss: 1.2363 - val_acc: 0.6957\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7069 - acc: 0.6812 - val_loss: 1.1758 - val_acc: 0.7215\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6603 - acc: 0.6919 - val_loss: 1.2704 - val_acc: 0.7081\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6128 - acc: 0.7177 - val_loss: 1.1655 - val_acc: 0.7210\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.5958 - acc: 0.7155 - val_loss: 1.2277 - val_acc: 0.7181\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5692 - acc: 0.7335 - val_loss: 1.1337 - val_acc: 0.7409\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5259 - acc: 0.7407 - val_loss: 1.1733 - val_acc: 0.7404\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.4918 - acc: 0.7448 - val_loss: 1.1499 - val_acc: 0.7414\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5070 - acc: 0.7511 - val_loss: 1.1058 - val_acc: 0.7539\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4684 - acc: 0.7657 - val_loss: 1.1266 - val_acc: 0.7449\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4633 - acc: 0.7653 - val_loss: 1.1313 - val_acc: 0.7553\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4429 - acc: 0.7755 - val_loss: 1.1281 - val_acc: 0.7578\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4049 - acc: 0.7803 - val_loss: 1.0880 - val_acc: 0.7593\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4350 - acc: 0.7785 - val_loss: 1.0757 - val_acc: 0.7603\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4148 - acc: 0.7817 - val_loss: 1.1067 - val_acc: 0.7683\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3938 - acc: 0.7913 - val_loss: 1.0250 - val_acc: 0.7867\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3642 - acc: 0.7988 - val_loss: 1.1112 - val_acc: 0.7678\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3431 - acc: 0.8033 - val_loss: 1.0922 - val_acc: 0.7688\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3699 - acc: 0.8069 - val_loss: 1.0783 - val_acc: 0.7653\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3412 - acc: 0.8080 - val_loss: 1.0290 - val_acc: 0.7877\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3584 - acc: 0.8070 - val_loss: 1.0692 - val_acc: 0.7737\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3476 - acc: 0.8099 - val_loss: 1.1225 - val_acc: 0.7623\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3226 - acc: 0.8168 - val_loss: 1.0212 - val_acc: 0.7921\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3979 - acc: 0.8136 - val_loss: 1.0664 - val_acc: 0.7832\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3905 - acc: 0.8193 - val_loss: 1.0733 - val_acc: 0.7762\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3279 - acc: 0.8216 - val_loss: 1.0052 - val_acc: 0.7857\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.2999 - acc: 0.8300 - val_loss: 1.0500 - val_acc: 0.7807\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3019 - acc: 0.8274 - val_loss: 1.0555 - val_acc: 0.7852\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2755 - acc: 0.8343 - val_loss: 0.9875 - val_acc: 0.7971\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2769 - acc: 0.8347 - val_loss: 0.9901 - val_acc: 0.7981\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2712 - acc: 0.8395 - val_loss: 1.0341 - val_acc: 0.7842\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2806 - acc: 0.8428 - val_loss: 1.0514 - val_acc: 0.8006\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2725 - acc: 0.8496 - val_loss: 1.0093 - val_acc: 0.8026\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2617 - acc: 0.8505 - val_loss: 1.0857 - val_acc: 0.7837\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2505 - acc: 0.8482 - val_loss: 1.0129 - val_acc: 0.7921\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2484 - acc: 0.8526 - val_loss: 1.0216 - val_acc: 0.8011\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2251 - acc: 0.8563 - val_loss: 1.0550 - val_acc: 0.8016\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2472 - acc: 0.8559 - val_loss: 1.0397 - val_acc: 0.7936\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2256 - acc: 0.8574 - val_loss: 1.0090 - val_acc: 0.8041\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2085 - acc: 0.8644 - val_loss: 1.0168 - val_acc: 0.8006\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2469 - acc: 0.8569 - val_loss: 1.0623 - val_acc: 0.7862\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2334 - acc: 0.8620 - val_loss: 1.0456 - val_acc: 0.7931\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2247 - acc: 0.8623 - val_loss: 1.0168 - val_acc: 0.8051\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2254 - acc: 0.8651 - val_loss: 1.0346 - val_acc: 0.7887\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2191 - acc: 0.8682 - val_loss: 1.0464 - val_acc: 0.8021\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2023 - acc: 0.8656 - val_loss: 1.0628 - val_acc: 0.7986\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2090 - acc: 0.8732 - val_loss: 1.0606 - val_acc: 0.7837\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2120 - acc: 0.8692 - val_loss: 1.0332 - val_acc: 0.8011\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.1958 - acc: 0.8728 - val_loss: 1.0408 - val_acc: 0.8056\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2052 - acc: 0.8738 - val_loss: 1.0560 - val_acc: 0.8051\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.1908 - acc: 0.8792 - val_loss: 1.0675 - val_acc: 0.8016\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1737 - acc: 0.8815 - val_loss: 1.0414 - val_acc: 0.8100\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1978 - acc: 0.8774 - val_loss: 1.0813 - val_acc: 0.8066\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.1952 - acc: 0.8752 - val_loss: 1.1080 - val_acc: 0.8021\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1884 - acc: 0.8804 - val_loss: 1.0417 - val_acc: 0.8100\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1895 - acc: 0.8868 - val_loss: 1.0342 - val_acc: 0.8165\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1904 - acc: 0.8805 - val_loss: 1.0475 - val_acc: 0.8120\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1791 - acc: 0.8825 - val_loss: 1.1031 - val_acc: 0.8105\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1878 - acc: 0.8838 - val_loss: 1.0938 - val_acc: 0.8026\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1744 - acc: 0.8840 - val_loss: 1.0200 - val_acc: 0.8185\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1624 - acc: 0.8951 - val_loss: 1.0101 - val_acc: 0.8160\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1693 - acc: 0.8856 - val_loss: 1.0217 - val_acc: 0.8061\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1812 - acc: 0.8892 - val_loss: 1.0299 - val_acc: 0.8210\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1890 - acc: 0.8828 - val_loss: 1.0584 - val_acc: 0.8165\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1607 - acc: 0.8948 - val_loss: 1.0578 - val_acc: 0.8120\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1521 - acc: 0.8962 - val_loss: 0.9966 - val_acc: 0.8260\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1672 - acc: 0.8924 - val_loss: 1.0439 - val_acc: 0.8205\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1588 - acc: 0.8915 - val_loss: 1.1056 - val_acc: 0.8160\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1637 - acc: 0.8944 - val_loss: 1.0779 - val_acc: 0.8205\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1670 - acc: 0.8938 - val_loss: 1.0488 - val_acc: 0.8235\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1445 - acc: 0.9022 - val_loss: 1.0646 - val_acc: 0.8185\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1458 - acc: 0.9013 - val_loss: 1.0493 - val_acc: 0.8165\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1529 - acc: 0.8952 - val_loss: 1.0671 - val_acc: 0.8145\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1587 - acc: 0.8944 - val_loss: 1.0469 - val_acc: 0.8210\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1613 - acc: 0.9015 - val_loss: 1.0417 - val_acc: 0.8225\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1552 - acc: 0.8974 - val_loss: 1.0435 - val_acc: 0.8150\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1611 - acc: 0.8937 - val_loss: 1.0365 - val_acc: 0.8240\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1439 - acc: 0.9011 - val_loss: 1.0390 - val_acc: 0.8190\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1505 - acc: 0.9004 - val_loss: 1.0168 - val_acc: 0.8225\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1446 - acc: 0.9036 - val_loss: 0.9845 - val_acc: 0.8279\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1457 - acc: 0.9031 - val_loss: 1.0648 - val_acc: 0.8245\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1570 - acc: 0.9003 - val_loss: 1.0409 - val_acc: 0.8170\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1451 - acc: 0.9046 - val_loss: 0.9972 - val_acc: 0.8279\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1345 - acc: 0.9104 - val_loss: 1.0110 - val_acc: 0.8220\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1482 - acc: 0.9025 - val_loss: 1.0576 - val_acc: 0.8160\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1462 - acc: 0.9072 - val_loss: 1.0695 - val_acc: 0.8205\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1401 - acc: 0.9059 - val_loss: 1.0312 - val_acc: 0.8235\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1539 - acc: 0.9008 - val_loss: 1.0367 - val_acc: 0.8250\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1305 - acc: 0.9115 - val_loss: 1.0137 - val_acc: 0.8304\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1385 - acc: 0.9090 - val_loss: 1.0382 - val_acc: 0.8235\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1350 - acc: 0.9098 - val_loss: 1.0552 - val_acc: 0.8274\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1271 - acc: 0.9130 - val_loss: 1.0304 - val_acc: 0.8304\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1272 - acc: 0.9161 - val_loss: 1.0441 - val_acc: 0.8235\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1278 - acc: 0.9148 - val_loss: 1.0723 - val_acc: 0.8190\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1278 - acc: 0.9131 - val_loss: 1.0147 - val_acc: 0.8294\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1253 - acc: 0.9131 - val_loss: 1.0123 - val_acc: 0.8294\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1390 - acc: 0.9108 - val_loss: 1.0310 - val_acc: 0.8240\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1252 - acc: 0.9126 - val_loss: 1.0232 - val_acc: 0.8270\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1267 - acc: 0.9161 - val_loss: 1.0384 - val_acc: 0.8265\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1278 - acc: 0.9136 - val_loss: 1.0386 - val_acc: 0.8274\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1218 - acc: 0.9157 - val_loss: 1.0231 - val_acc: 0.8294\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1211 - acc: 0.9176 - val_loss: 1.0370 - val_acc: 0.8314\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1286 - acc: 0.9110 - val_loss: 1.0472 - val_acc: 0.8274\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1335 - acc: 0.9158 - val_loss: 1.0500 - val_acc: 0.8235\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1159 - acc: 0.9188 - val_loss: 1.0314 - val_acc: 0.8284\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1239 - acc: 0.9161 - val_loss: 1.0405 - val_acc: 0.8304\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1188 - acc: 0.9157 - val_loss: 1.0705 - val_acc: 0.8225\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1129 - acc: 0.9185 - val_loss: 1.0378 - val_acc: 0.8265\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1209 - acc: 0.9200 - val_loss: 1.0593 - val_acc: 0.8260\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1163 - acc: 0.9211 - val_loss: 1.0718 - val_acc: 0.8274\n",
            "Epoch 119/200\n",
            "566/566 - 6s - loss: 0.1245 - acc: 0.9212 - val_loss: 1.0482 - val_acc: 0.8319\n",
            "Epoch 120/200\n",
            "566/566 - 6s - loss: 0.1100 - acc: 0.9242 - val_loss: 1.0297 - val_acc: 0.8289\n",
            "Epoch 121/200\n",
            "566/566 - 6s - loss: 0.1189 - acc: 0.9204 - val_loss: 1.0528 - val_acc: 0.8309\n",
            "Epoch 122/200\n",
            "566/566 - 6s - loss: 0.1166 - acc: 0.9204 - val_loss: 1.0442 - val_acc: 0.8170\n",
            "Epoch 123/200\n",
            "566/566 - 6s - loss: 0.1171 - acc: 0.9174 - val_loss: 1.0125 - val_acc: 0.8304\n",
            "Epoch 124/200\n",
            "566/566 - 6s - loss: 0.1144 - acc: 0.9257 - val_loss: 1.0093 - val_acc: 0.8279\n",
            "Epoch 125/200\n",
            "566/566 - 6s - loss: 0.1241 - acc: 0.9179 - val_loss: 1.0396 - val_acc: 0.8304\n",
            "Epoch 126/200\n",
            "566/566 - 6s - loss: 0.1149 - acc: 0.9231 - val_loss: 1.0165 - val_acc: 0.8384\n",
            "Epoch 127/200\n",
            "566/566 - 6s - loss: 0.1153 - acc: 0.9246 - val_loss: 1.0360 - val_acc: 0.8299\n",
            "Epoch 128/200\n",
            "566/566 - 6s - loss: 0.1149 - acc: 0.9210 - val_loss: 1.0475 - val_acc: 0.8319\n",
            "Epoch 129/200\n",
            "566/566 - 6s - loss: 0.1243 - acc: 0.9194 - val_loss: 1.0594 - val_acc: 0.8304\n",
            "Epoch 130/200\n",
            "566/566 - 6s - loss: 0.1114 - acc: 0.9226 - val_loss: 1.0196 - val_acc: 0.8359\n",
            "Epoch 131/200\n",
            "566/566 - 6s - loss: 0.1130 - acc: 0.9234 - val_loss: 1.0321 - val_acc: 0.8334\n",
            "Epoch 132/200\n",
            "566/566 - 6s - loss: 0.1095 - acc: 0.9226 - val_loss: 1.0463 - val_acc: 0.8225\n",
            "Epoch 133/200\n",
            "566/566 - 6s - loss: 0.1145 - acc: 0.9203 - val_loss: 1.0619 - val_acc: 0.8265\n",
            "Epoch 134/200\n",
            "566/566 - 6s - loss: 0.1122 - acc: 0.9251 - val_loss: 1.0883 - val_acc: 0.8270\n",
            "Epoch 135/200\n",
            "566/566 - 6s - loss: 0.1083 - acc: 0.9248 - val_loss: 1.1006 - val_acc: 0.8165\n",
            "Epoch 136/200\n",
            "566/566 - 6s - loss: 0.1060 - acc: 0.9259 - val_loss: 1.0428 - val_acc: 0.8294\n",
            "Epoch 137/200\n",
            "566/566 - 6s - loss: 0.1077 - acc: 0.9297 - val_loss: 1.0932 - val_acc: 0.8245\n",
            "Epoch 138/200\n",
            "566/566 - 6s - loss: 0.1170 - acc: 0.9248 - val_loss: 1.0818 - val_acc: 0.8250\n",
            "Epoch 139/200\n",
            "566/566 - 6s - loss: 0.1107 - acc: 0.9255 - val_loss: 1.0490 - val_acc: 0.8294\n",
            "Epoch 140/200\n",
            "566/566 - 6s - loss: 0.1164 - acc: 0.9241 - val_loss: 1.0497 - val_acc: 0.8170\n",
            "Epoch 141/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.0982 - acc: 0.9304 - val_loss: 1.1071 - val_acc: 0.8195\n",
            "Epoch 00141: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.78676855 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 2/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.2855 - acc: 0.0611 - val_loss: 3.7817 - val_acc: 0.2715\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1057 - acc: 0.2760 - val_loss: 1.9685 - val_acc: 0.4908\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9775 - acc: 0.4158 - val_loss: 1.6209 - val_acc: 0.5714\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4913 - acc: 0.4974 - val_loss: 1.3114 - val_acc: 0.6539\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.1975 - acc: 0.5634 - val_loss: 1.2120 - val_acc: 0.6778\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0239 - acc: 0.6000 - val_loss: 1.1822 - val_acc: 0.6917\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.8953 - acc: 0.6270 - val_loss: 1.1717 - val_acc: 0.6897\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8226 - acc: 0.6483 - val_loss: 1.0847 - val_acc: 0.7205\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7678 - acc: 0.6682 - val_loss: 1.1192 - val_acc: 0.7151\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7028 - acc: 0.6794 - val_loss: 1.0761 - val_acc: 0.7340\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6922 - acc: 0.6969 - val_loss: 1.1218 - val_acc: 0.7270\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6338 - acc: 0.7053 - val_loss: 1.0945 - val_acc: 0.7389\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6012 - acc: 0.7204 - val_loss: 1.0206 - val_acc: 0.7633\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5495 - acc: 0.7299 - val_loss: 0.9944 - val_acc: 0.7673\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5491 - acc: 0.7321 - val_loss: 1.1719 - val_acc: 0.7340\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5042 - acc: 0.7429 - val_loss: 1.0514 - val_acc: 0.7588\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5001 - acc: 0.7521 - val_loss: 1.0735 - val_acc: 0.7474\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4841 - acc: 0.7594 - val_loss: 0.9720 - val_acc: 0.7723\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4740 - acc: 0.7601 - val_loss: 1.0407 - val_acc: 0.7648\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4499 - acc: 0.7636 - val_loss: 0.9816 - val_acc: 0.7757\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4236 - acc: 0.7788 - val_loss: 0.9957 - val_acc: 0.7752\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4320 - acc: 0.7741 - val_loss: 0.9995 - val_acc: 0.7772\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4004 - acc: 0.7885 - val_loss: 0.9764 - val_acc: 0.7797\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3912 - acc: 0.7917 - val_loss: 0.9720 - val_acc: 0.7797\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3726 - acc: 0.7925 - val_loss: 0.9809 - val_acc: 0.7926\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3750 - acc: 0.7954 - val_loss: 0.9577 - val_acc: 0.7812\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3570 - acc: 0.8010 - val_loss: 0.9393 - val_acc: 0.7936\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3484 - acc: 0.8070 - val_loss: 0.9406 - val_acc: 0.7966\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3346 - acc: 0.8090 - val_loss: 0.9971 - val_acc: 0.7772\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3058 - acc: 0.8223 - val_loss: 0.9641 - val_acc: 0.7872\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3403 - acc: 0.8106 - val_loss: 0.9471 - val_acc: 0.7867\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3193 - acc: 0.8163 - val_loss: 0.9692 - val_acc: 0.7911\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3034 - acc: 0.8240 - val_loss: 0.9640 - val_acc: 0.7902\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3071 - acc: 0.8284 - val_loss: 0.9503 - val_acc: 0.8016\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.2981 - acc: 0.8304 - val_loss: 0.9275 - val_acc: 0.8031\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2836 - acc: 0.8407 - val_loss: 0.9402 - val_acc: 0.8011\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2743 - acc: 0.8368 - val_loss: 0.9269 - val_acc: 0.8041\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2664 - acc: 0.8421 - val_loss: 0.9610 - val_acc: 0.7842\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2707 - acc: 0.8404 - val_loss: 0.9121 - val_acc: 0.8095\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2715 - acc: 0.8365 - val_loss: 0.9481 - val_acc: 0.8086\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2679 - acc: 0.8420 - val_loss: 0.9151 - val_acc: 0.8081\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2525 - acc: 0.8469 - val_loss: 0.9107 - val_acc: 0.8041\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2448 - acc: 0.8500 - val_loss: 0.9131 - val_acc: 0.8130\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2253 - acc: 0.8521 - val_loss: 0.9018 - val_acc: 0.8160\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2314 - acc: 0.8557 - val_loss: 0.8763 - val_acc: 0.8130\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2446 - acc: 0.8528 - val_loss: 0.9208 - val_acc: 0.8140\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2366 - acc: 0.8569 - val_loss: 0.9107 - val_acc: 0.8210\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2353 - acc: 0.8561 - val_loss: 0.9422 - val_acc: 0.8140\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2323 - acc: 0.8525 - val_loss: 0.9369 - val_acc: 0.8160\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2148 - acc: 0.8654 - val_loss: 0.9206 - val_acc: 0.8205\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2174 - acc: 0.8657 - val_loss: 0.9472 - val_acc: 0.8210\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2147 - acc: 0.8693 - val_loss: 0.9536 - val_acc: 0.8170\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2234 - acc: 0.8642 - val_loss: 0.9654 - val_acc: 0.8165\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2021 - acc: 0.8738 - val_loss: 0.9341 - val_acc: 0.8190\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2080 - acc: 0.8735 - val_loss: 0.9681 - val_acc: 0.8235\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.1995 - acc: 0.8729 - val_loss: 0.9551 - val_acc: 0.8150\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2077 - acc: 0.8678 - val_loss: 0.9447 - val_acc: 0.8170\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.1950 - acc: 0.8698 - val_loss: 1.0181 - val_acc: 0.7996\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2113 - acc: 0.8754 - val_loss: 0.9211 - val_acc: 0.8260\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1912 - acc: 0.8781 - val_loss: 0.9281 - val_acc: 0.8250\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1716 - acc: 0.8825 - val_loss: 0.9469 - val_acc: 0.8240\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.2044 - acc: 0.8777 - val_loss: 0.9238 - val_acc: 0.8235\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1959 - acc: 0.8753 - val_loss: 0.9260 - val_acc: 0.8304\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1862 - acc: 0.8752 - val_loss: 0.9743 - val_acc: 0.8289\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1775 - acc: 0.8836 - val_loss: 0.9313 - val_acc: 0.8274\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1835 - acc: 0.8823 - val_loss: 0.9381 - val_acc: 0.8274\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1852 - acc: 0.8806 - val_loss: 0.9710 - val_acc: 0.8195\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1726 - acc: 0.8878 - val_loss: 0.9647 - val_acc: 0.8274\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1790 - acc: 0.8860 - val_loss: 0.9174 - val_acc: 0.8314\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1867 - acc: 0.8850 - val_loss: 0.9528 - val_acc: 0.8240\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1731 - acc: 0.8907 - val_loss: 0.9593 - val_acc: 0.8319\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1659 - acc: 0.8885 - val_loss: 1.0175 - val_acc: 0.8195\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1531 - acc: 0.8947 - val_loss: 0.9596 - val_acc: 0.8294\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1507 - acc: 0.8976 - val_loss: 0.9496 - val_acc: 0.8270\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1593 - acc: 0.8932 - val_loss: 0.9395 - val_acc: 0.8374\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1708 - acc: 0.8929 - val_loss: 1.0217 - val_acc: 0.8180\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1577 - acc: 0.8900 - val_loss: 0.9704 - val_acc: 0.8289\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1486 - acc: 0.8954 - val_loss: 0.9528 - val_acc: 0.8299\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1677 - acc: 0.8945 - val_loss: 0.9531 - val_acc: 0.8394\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1593 - acc: 0.8936 - val_loss: 0.9719 - val_acc: 0.8294\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1520 - acc: 0.8957 - val_loss: 0.9897 - val_acc: 0.8349\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1565 - acc: 0.9008 - val_loss: 0.9583 - val_acc: 0.8334\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1562 - acc: 0.8967 - val_loss: 1.0311 - val_acc: 0.8245\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1463 - acc: 0.9016 - val_loss: 0.9515 - val_acc: 0.8309\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1425 - acc: 0.9031 - val_loss: 0.9524 - val_acc: 0.8314\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1511 - acc: 0.8992 - val_loss: 0.9531 - val_acc: 0.8344\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1495 - acc: 0.9014 - val_loss: 0.9404 - val_acc: 0.8334\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1388 - acc: 0.9027 - val_loss: 0.9589 - val_acc: 0.8364\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1531 - acc: 0.9030 - val_loss: 0.9453 - val_acc: 0.8449\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1400 - acc: 0.9014 - val_loss: 0.9998 - val_acc: 0.8354\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1251 - acc: 0.9122 - val_loss: 0.9742 - val_acc: 0.8369\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1275 - acc: 0.9130 - val_loss: 1.0010 - val_acc: 0.8289\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1470 - acc: 0.9034 - val_loss: 0.9805 - val_acc: 0.8309\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1505 - acc: 0.9052 - val_loss: 0.9998 - val_acc: 0.8265\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1458 - acc: 0.9025 - val_loss: 0.9772 - val_acc: 0.8369\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1326 - acc: 0.9066 - val_loss: 0.9709 - val_acc: 0.8394\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1376 - acc: 0.9104 - val_loss: 0.9986 - val_acc: 0.8359\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1320 - acc: 0.9071 - val_loss: 0.9584 - val_acc: 0.8439\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1301 - acc: 0.9104 - val_loss: 0.9788 - val_acc: 0.8404\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1352 - acc: 0.9119 - val_loss: 0.9942 - val_acc: 0.8419\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1340 - acc: 0.9086 - val_loss: 0.9835 - val_acc: 0.8444\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1263 - acc: 0.9126 - val_loss: 1.0328 - val_acc: 0.8309\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1397 - acc: 0.9077 - val_loss: 0.9868 - val_acc: 0.8334\n",
            "Epoch 104/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1248 - acc: 0.9126 - val_loss: 0.9905 - val_acc: 0.8399\n",
            "Epoch 00104: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.80576939 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 3/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.2723 - acc: 0.0572 - val_loss: 3.7926 - val_acc: 0.2601\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.0894 - acc: 0.2763 - val_loss: 2.0286 - val_acc: 0.4923\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9433 - acc: 0.4196 - val_loss: 1.6303 - val_acc: 0.5540\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4915 - acc: 0.5032 - val_loss: 1.5856 - val_acc: 0.5878\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2187 - acc: 0.5538 - val_loss: 1.3317 - val_acc: 0.6385\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0185 - acc: 0.6013 - val_loss: 1.3345 - val_acc: 0.6514\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9357 - acc: 0.6161 - val_loss: 1.3635 - val_acc: 0.6638\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8306 - acc: 0.6492 - val_loss: 1.1402 - val_acc: 0.7051\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7887 - acc: 0.6691 - val_loss: 1.1852 - val_acc: 0.6947\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7046 - acc: 0.6813 - val_loss: 1.1813 - val_acc: 0.7041\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6748 - acc: 0.6965 - val_loss: 1.1331 - val_acc: 0.7215\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6055 - acc: 0.7137 - val_loss: 1.0787 - val_acc: 0.7360\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.5847 - acc: 0.7172 - val_loss: 1.1731 - val_acc: 0.7220\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5850 - acc: 0.7243 - val_loss: 1.0771 - val_acc: 0.7414\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5574 - acc: 0.7299 - val_loss: 1.0910 - val_acc: 0.7389\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5202 - acc: 0.7412 - val_loss: 1.0660 - val_acc: 0.7529\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5149 - acc: 0.7465 - val_loss: 1.0573 - val_acc: 0.7558\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.5029 - acc: 0.7533 - val_loss: 1.0824 - val_acc: 0.7524\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4538 - acc: 0.7582 - val_loss: 1.0710 - val_acc: 0.7529\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4687 - acc: 0.7654 - val_loss: 1.0618 - val_acc: 0.7573\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4170 - acc: 0.7853 - val_loss: 1.0112 - val_acc: 0.7703\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4309 - acc: 0.7771 - val_loss: 1.0312 - val_acc: 0.7732\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.3855 - acc: 0.7868 - val_loss: 0.9919 - val_acc: 0.7673\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3932 - acc: 0.7926 - val_loss: 0.9895 - val_acc: 0.7752\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3971 - acc: 0.7918 - val_loss: 1.0477 - val_acc: 0.7623\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3609 - acc: 0.7970 - val_loss: 1.0024 - val_acc: 0.7822\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3608 - acc: 0.7986 - val_loss: 1.0705 - val_acc: 0.7683\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3781 - acc: 0.7953 - val_loss: 1.0087 - val_acc: 0.7782\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3497 - acc: 0.8065 - val_loss: 0.9960 - val_acc: 0.7907\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3199 - acc: 0.8193 - val_loss: 0.9915 - val_acc: 0.7842\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3001 - acc: 0.8265 - val_loss: 0.9534 - val_acc: 0.7931\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3122 - acc: 0.8203 - val_loss: 1.0764 - val_acc: 0.7777\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3084 - acc: 0.8242 - val_loss: 0.9459 - val_acc: 0.7986\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3357 - acc: 0.8194 - val_loss: 0.9797 - val_acc: 0.7902\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3125 - acc: 0.8260 - val_loss: 0.9861 - val_acc: 0.7916\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2906 - acc: 0.8342 - val_loss: 0.9285 - val_acc: 0.7931\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2899 - acc: 0.8341 - val_loss: 0.9539 - val_acc: 0.8001\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.3347 - acc: 0.8240 - val_loss: 0.9903 - val_acc: 0.7887\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2931 - acc: 0.8309 - val_loss: 0.9859 - val_acc: 0.7842\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2666 - acc: 0.8377 - val_loss: 0.9671 - val_acc: 0.7996\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2460 - acc: 0.8498 - val_loss: 0.9329 - val_acc: 0.8115\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2367 - acc: 0.8569 - val_loss: 0.9493 - val_acc: 0.8056\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2612 - acc: 0.8444 - val_loss: 1.0009 - val_acc: 0.7951\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2423 - acc: 0.8488 - val_loss: 0.9460 - val_acc: 0.7966\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2327 - acc: 0.8538 - val_loss: 1.0033 - val_acc: 0.7956\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2370 - acc: 0.8549 - val_loss: 0.9636 - val_acc: 0.8021\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2433 - acc: 0.8535 - val_loss: 0.9097 - val_acc: 0.8086\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2405 - acc: 0.8507 - val_loss: 0.9368 - val_acc: 0.7996\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2248 - acc: 0.8628 - val_loss: 0.9269 - val_acc: 0.8061\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2284 - acc: 0.8617 - val_loss: 0.9788 - val_acc: 0.7981\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2335 - acc: 0.8607 - val_loss: 0.9513 - val_acc: 0.8036\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2150 - acc: 0.8663 - val_loss: 1.0274 - val_acc: 0.7956\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2257 - acc: 0.8646 - val_loss: 1.0068 - val_acc: 0.7951\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2207 - acc: 0.8633 - val_loss: 1.0075 - val_acc: 0.8016\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2106 - acc: 0.8752 - val_loss: 1.0000 - val_acc: 0.8081\n",
            "Epoch 56/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.2158 - acc: 0.8679 - val_loss: 0.9937 - val_acc: 0.8011\n",
            "Epoch 00056: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.80094154 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 4/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.3037 - acc: 0.0571 - val_loss: 4.0319 - val_acc: 0.2183\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.0652 - acc: 0.2862 - val_loss: 2.1875 - val_acc: 0.4600\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9584 - acc: 0.4228 - val_loss: 1.7635 - val_acc: 0.5554\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4729 - acc: 0.5020 - val_loss: 1.5461 - val_acc: 0.5992\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2365 - acc: 0.5509 - val_loss: 1.4109 - val_acc: 0.6330\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0166 - acc: 0.5955 - val_loss: 1.3679 - val_acc: 0.6564\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9094 - acc: 0.6233 - val_loss: 1.3020 - val_acc: 0.6748\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8335 - acc: 0.6476 - val_loss: 1.5143 - val_acc: 0.6698\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7706 - acc: 0.6648 - val_loss: 1.3084 - val_acc: 0.6887\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7244 - acc: 0.6764 - val_loss: 1.3552 - val_acc: 0.6827\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6580 - acc: 0.6937 - val_loss: 1.2146 - val_acc: 0.7091\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6106 - acc: 0.7064 - val_loss: 1.2364 - val_acc: 0.7036\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6067 - acc: 0.7106 - val_loss: 1.2001 - val_acc: 0.7230\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5661 - acc: 0.7256 - val_loss: 1.1796 - val_acc: 0.7255\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5602 - acc: 0.7322 - val_loss: 1.2906 - val_acc: 0.6997\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5223 - acc: 0.7411 - val_loss: 1.2494 - val_acc: 0.7141\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5038 - acc: 0.7522 - val_loss: 1.1587 - val_acc: 0.7335\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4677 - acc: 0.7609 - val_loss: 1.1917 - val_acc: 0.7230\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4753 - acc: 0.7594 - val_loss: 1.1196 - val_acc: 0.7509\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4330 - acc: 0.7777 - val_loss: 1.1033 - val_acc: 0.7469\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4324 - acc: 0.7703 - val_loss: 1.0782 - val_acc: 0.7633\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4147 - acc: 0.7796 - val_loss: 1.0837 - val_acc: 0.7693\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4383 - acc: 0.7755 - val_loss: 1.0886 - val_acc: 0.7668\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3905 - acc: 0.7922 - val_loss: 1.0790 - val_acc: 0.7673\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3807 - acc: 0.7920 - val_loss: 1.0642 - val_acc: 0.7703\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3621 - acc: 0.8020 - val_loss: 1.0736 - val_acc: 0.7708\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3617 - acc: 0.8038 - val_loss: 1.0779 - val_acc: 0.7802\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3736 - acc: 0.8081 - val_loss: 1.0537 - val_acc: 0.7673\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3484 - acc: 0.8084 - val_loss: 1.1065 - val_acc: 0.7752\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3241 - acc: 0.8145 - val_loss: 1.0823 - val_acc: 0.7752\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3231 - acc: 0.8189 - val_loss: 1.0275 - val_acc: 0.7752\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3161 - acc: 0.8161 - val_loss: 1.0251 - val_acc: 0.7877\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.2936 - acc: 0.8305 - val_loss: 1.0028 - val_acc: 0.7862\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3028 - acc: 0.8307 - val_loss: 1.0046 - val_acc: 0.7902\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3018 - acc: 0.8298 - val_loss: 1.0732 - val_acc: 0.7897\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2711 - acc: 0.8391 - val_loss: 1.0644 - val_acc: 0.7897\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2895 - acc: 0.8298 - val_loss: 1.1092 - val_acc: 0.7772\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2758 - acc: 0.8372 - val_loss: 1.0614 - val_acc: 0.7867\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2651 - acc: 0.8414 - val_loss: 1.0662 - val_acc: 0.7897\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2629 - acc: 0.8430 - val_loss: 1.0812 - val_acc: 0.7941\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2587 - acc: 0.8459 - val_loss: 1.0694 - val_acc: 0.7921\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2545 - acc: 0.8480 - val_loss: 1.0100 - val_acc: 0.8021\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2447 - acc: 0.8519 - val_loss: 1.0466 - val_acc: 0.7981\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2327 - acc: 0.8546 - val_loss: 1.0417 - val_acc: 0.7966\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2425 - acc: 0.8576 - val_loss: 1.1061 - val_acc: 0.7887\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2608 - acc: 0.8553 - val_loss: 1.0815 - val_acc: 0.7951\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2267 - acc: 0.8606 - val_loss: 1.0590 - val_acc: 0.7976\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2341 - acc: 0.8620 - val_loss: 1.0539 - val_acc: 0.7986\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2216 - acc: 0.8571 - val_loss: 1.1249 - val_acc: 0.7941\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2254 - acc: 0.8653 - val_loss: 1.0237 - val_acc: 0.7976\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2231 - acc: 0.8612 - val_loss: 1.0662 - val_acc: 0.7981\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2045 - acc: 0.8667 - val_loss: 1.0164 - val_acc: 0.8095\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2228 - acc: 0.8686 - val_loss: 1.0476 - val_acc: 0.7991\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2083 - acc: 0.8727 - val_loss: 1.0236 - val_acc: 0.8046\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2124 - acc: 0.8722 - val_loss: 1.0508 - val_acc: 0.7996\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2037 - acc: 0.8754 - val_loss: 1.0059 - val_acc: 0.8115\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.1935 - acc: 0.8751 - val_loss: 1.0127 - val_acc: 0.8051\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.1864 - acc: 0.8781 - val_loss: 1.0420 - val_acc: 0.8076\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.1891 - acc: 0.8785 - val_loss: 1.0329 - val_acc: 0.8135\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1866 - acc: 0.8782 - val_loss: 1.0805 - val_acc: 0.7946\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1872 - acc: 0.8782 - val_loss: 1.0394 - val_acc: 0.8165\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.1853 - acc: 0.8785 - val_loss: 1.0168 - val_acc: 0.8135\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1927 - acc: 0.8823 - val_loss: 1.0703 - val_acc: 0.8135\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1805 - acc: 0.8848 - val_loss: 1.0169 - val_acc: 0.8150\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1746 - acc: 0.8832 - val_loss: 0.9898 - val_acc: 0.8215\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1700 - acc: 0.8887 - val_loss: 1.0197 - val_acc: 0.8120\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1816 - acc: 0.8860 - val_loss: 1.0389 - val_acc: 0.8170\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1815 - acc: 0.8853 - val_loss: 1.0400 - val_acc: 0.8120\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1866 - acc: 0.8839 - val_loss: 1.0892 - val_acc: 0.8056\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1754 - acc: 0.8887 - val_loss: 1.0304 - val_acc: 0.8170\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1668 - acc: 0.8880 - val_loss: 1.0169 - val_acc: 0.8105\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1589 - acc: 0.8964 - val_loss: 1.0381 - val_acc: 0.8170\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1656 - acc: 0.8920 - val_loss: 1.1174 - val_acc: 0.7996\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1710 - acc: 0.8889 - val_loss: 1.0477 - val_acc: 0.8115\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1654 - acc: 0.8927 - val_loss: 1.0085 - val_acc: 0.8160\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1740 - acc: 0.8888 - val_loss: 1.0409 - val_acc: 0.8210\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1603 - acc: 0.8946 - val_loss: 1.0090 - val_acc: 0.8225\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1685 - acc: 0.8947 - val_loss: 1.0012 - val_acc: 0.8230\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1702 - acc: 0.8935 - val_loss: 1.0121 - val_acc: 0.8255\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1546 - acc: 0.8944 - val_loss: 0.9883 - val_acc: 0.8265\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1477 - acc: 0.9033 - val_loss: 0.9939 - val_acc: 0.8250\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1622 - acc: 0.8947 - val_loss: 1.0276 - val_acc: 0.8170\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1391 - acc: 0.9029 - val_loss: 1.0512 - val_acc: 0.8245\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1410 - acc: 0.9016 - val_loss: 0.9987 - val_acc: 0.8215\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1391 - acc: 0.9037 - val_loss: 1.0353 - val_acc: 0.8294\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1474 - acc: 0.9005 - val_loss: 1.0308 - val_acc: 0.8260\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1365 - acc: 0.9085 - val_loss: 1.0085 - val_acc: 0.8270\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1607 - acc: 0.8977 - val_loss: 1.0276 - val_acc: 0.8274\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1468 - acc: 0.9023 - val_loss: 1.0576 - val_acc: 0.8265\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1310 - acc: 0.9085 - val_loss: 1.0004 - val_acc: 0.8279\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1474 - acc: 0.9089 - val_loss: 1.0129 - val_acc: 0.8270\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1429 - acc: 0.9076 - val_loss: 1.0724 - val_acc: 0.8240\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1371 - acc: 0.9059 - val_loss: 1.0270 - val_acc: 0.8289\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1484 - acc: 0.9039 - val_loss: 1.0145 - val_acc: 0.8279\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1472 - acc: 0.9090 - val_loss: 1.0317 - val_acc: 0.8284\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1409 - acc: 0.9055 - val_loss: 1.0471 - val_acc: 0.8185\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1386 - acc: 0.9078 - val_loss: 1.0169 - val_acc: 0.8245\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1426 - acc: 0.9092 - val_loss: 1.0248 - val_acc: 0.8334\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1402 - acc: 0.9081 - val_loss: 1.0528 - val_acc: 0.8220\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1349 - acc: 0.9104 - val_loss: 1.0584 - val_acc: 0.8265\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1348 - acc: 0.9132 - val_loss: 1.0301 - val_acc: 0.8240\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1480 - acc: 0.9098 - val_loss: 1.0048 - val_acc: 0.8274\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1146 - acc: 0.9160 - val_loss: 1.0098 - val_acc: 0.8255\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1172 - acc: 0.9166 - val_loss: 1.0428 - val_acc: 0.8210\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1284 - acc: 0.9098 - val_loss: 1.0181 - val_acc: 0.8279\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1324 - acc: 0.9148 - val_loss: 1.0621 - val_acc: 0.8210\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1277 - acc: 0.9142 - val_loss: 1.0180 - val_acc: 0.8270\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1301 - acc: 0.9118 - val_loss: 1.0224 - val_acc: 0.8334\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1188 - acc: 0.9164 - val_loss: 1.0310 - val_acc: 0.8274\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1176 - acc: 0.9160 - val_loss: 1.0415 - val_acc: 0.8289\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1303 - acc: 0.9160 - val_loss: 1.1004 - val_acc: 0.8270\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1242 - acc: 0.9156 - val_loss: 1.0354 - val_acc: 0.8359\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1236 - acc: 0.9132 - val_loss: 1.0395 - val_acc: 0.8240\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1263 - acc: 0.9145 - val_loss: 1.0078 - val_acc: 0.8294\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1189 - acc: 0.9181 - val_loss: 1.0286 - val_acc: 0.8334\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1195 - acc: 0.9186 - val_loss: 1.0365 - val_acc: 0.8324\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1172 - acc: 0.9187 - val_loss: 1.0426 - val_acc: 0.8319\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1137 - acc: 0.9203 - val_loss: 1.0283 - val_acc: 0.8354\n",
            "Epoch 119/200\n",
            "566/566 - 6s - loss: 0.1244 - acc: 0.9176 - val_loss: 1.0176 - val_acc: 0.8314\n",
            "Epoch 120/200\n",
            "566/566 - 6s - loss: 0.1119 - acc: 0.9241 - val_loss: 1.0226 - val_acc: 0.8309\n",
            "Epoch 121/200\n",
            "566/566 - 6s - loss: 0.1156 - acc: 0.9220 - val_loss: 1.0353 - val_acc: 0.8309\n",
            "Epoch 122/200\n",
            "566/566 - 6s - loss: 0.1134 - acc: 0.9209 - val_loss: 1.1221 - val_acc: 0.8210\n",
            "Epoch 123/200\n",
            "566/566 - 6s - loss: 0.1178 - acc: 0.9142 - val_loss: 1.0259 - val_acc: 0.8339\n",
            "Epoch 124/200\n",
            "566/566 - 6s - loss: 0.1188 - acc: 0.9200 - val_loss: 1.0209 - val_acc: 0.8319\n",
            "Epoch 125/200\n",
            "566/566 - 6s - loss: 0.1213 - acc: 0.9220 - val_loss: 1.0139 - val_acc: 0.8429\n",
            "Epoch 126/200\n",
            "566/566 - 6s - loss: 0.1167 - acc: 0.9210 - val_loss: 1.0316 - val_acc: 0.8399\n",
            "Epoch 127/200\n",
            "566/566 - 6s - loss: 0.1165 - acc: 0.9230 - val_loss: 1.0247 - val_acc: 0.8354\n",
            "Epoch 128/200\n",
            "566/566 - 6s - loss: 0.1173 - acc: 0.9194 - val_loss: 0.9913 - val_acc: 0.8399\n",
            "Epoch 129/200\n",
            "566/566 - 6s - loss: 0.1067 - acc: 0.9253 - val_loss: 1.0139 - val_acc: 0.8354\n",
            "Epoch 130/200\n",
            "566/566 - 6s - loss: 0.1079 - acc: 0.9221 - val_loss: 1.0222 - val_acc: 0.8369\n",
            "Epoch 131/200\n",
            "566/566 - 6s - loss: 0.1101 - acc: 0.9230 - val_loss: 1.0553 - val_acc: 0.8309\n",
            "Epoch 132/200\n",
            "566/566 - 6s - loss: 0.1086 - acc: 0.9227 - val_loss: 1.0069 - val_acc: 0.8384\n",
            "Epoch 133/200\n",
            "566/566 - 6s - loss: 0.1147 - acc: 0.9227 - val_loss: 1.0107 - val_acc: 0.8404\n",
            "Epoch 134/200\n",
            "566/566 - 6s - loss: 0.1150 - acc: 0.9216 - val_loss: 1.0815 - val_acc: 0.8279\n",
            "Epoch 135/200\n",
            "566/566 - 6s - loss: 0.1145 - acc: 0.9267 - val_loss: 1.0335 - val_acc: 0.8329\n",
            "Epoch 136/200\n",
            "566/566 - 6s - loss: 0.1159 - acc: 0.9214 - val_loss: 1.0208 - val_acc: 0.8339\n",
            "Epoch 137/200\n",
            "566/566 - 6s - loss: 0.1062 - acc: 0.9257 - val_loss: 0.9921 - val_acc: 0.8434\n",
            "Epoch 138/200\n",
            "566/566 - 6s - loss: 0.1003 - acc: 0.9275 - val_loss: 1.0313 - val_acc: 0.8384\n",
            "Epoch 139/200\n",
            "566/566 - 6s - loss: 0.1072 - acc: 0.9272 - val_loss: 0.9940 - val_acc: 0.8454\n",
            "Epoch 140/200\n",
            "566/566 - 6s - loss: 0.1091 - acc: 0.9298 - val_loss: 0.9827 - val_acc: 0.8473\n",
            "Epoch 141/200\n",
            "566/566 - 6s - loss: 0.0976 - acc: 0.9266 - val_loss: 0.9872 - val_acc: 0.8493\n",
            "Epoch 142/200\n",
            "566/566 - 6s - loss: 0.0913 - acc: 0.9313 - val_loss: 0.9897 - val_acc: 0.8414\n",
            "Epoch 143/200\n",
            "566/566 - 6s - loss: 0.1101 - acc: 0.9273 - val_loss: 1.0192 - val_acc: 0.8399\n",
            "Epoch 144/200\n",
            "566/566 - 6s - loss: 0.0972 - acc: 0.9257 - val_loss: 0.9847 - val_acc: 0.8454\n",
            "Epoch 145/200\n",
            "566/566 - 6s - loss: 0.1109 - acc: 0.9231 - val_loss: 1.0057 - val_acc: 0.8439\n",
            "Epoch 146/200\n",
            "566/566 - 6s - loss: 0.1022 - acc: 0.9240 - val_loss: 0.9905 - val_acc: 0.8449\n",
            "Epoch 147/200\n",
            "566/566 - 6s - loss: 0.1006 - acc: 0.9299 - val_loss: 1.0015 - val_acc: 0.8379\n",
            "Epoch 148/200\n",
            "566/566 - 6s - loss: 0.0986 - acc: 0.9304 - val_loss: 1.0140 - val_acc: 0.8449\n",
            "Epoch 149/200\n",
            "566/566 - 6s - loss: 0.1055 - acc: 0.9270 - val_loss: 0.9806 - val_acc: 0.8429\n",
            "Epoch 150/200\n",
            "566/566 - 6s - loss: 0.1056 - acc: 0.9297 - val_loss: 1.0005 - val_acc: 0.8384\n",
            "Epoch 151/200\n",
            "566/566 - 6s - loss: 0.1061 - acc: 0.9281 - val_loss: 1.0293 - val_acc: 0.8379\n",
            "Epoch 152/200\n",
            "566/566 - 6s - loss: 0.1043 - acc: 0.9247 - val_loss: 1.0316 - val_acc: 0.8379\n",
            "Epoch 153/200\n",
            "566/566 - 6s - loss: 0.1077 - acc: 0.9277 - val_loss: 1.0445 - val_acc: 0.8334\n",
            "Epoch 154/200\n",
            "566/566 - 6s - loss: 0.1061 - acc: 0.9292 - val_loss: 1.0055 - val_acc: 0.8389\n",
            "Epoch 155/200\n",
            "566/566 - 6s - loss: 0.1072 - acc: 0.9271 - val_loss: 1.0466 - val_acc: 0.8389\n",
            "Epoch 156/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1066 - acc: 0.9283 - val_loss: 1.0403 - val_acc: 0.8404\n",
            "Epoch 00156: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.80732243 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 5/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.3304 - acc: 0.0593 - val_loss: 3.8195 - val_acc: 0.2810\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1454 - acc: 0.2772 - val_loss: 2.1799 - val_acc: 0.4485\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9676 - acc: 0.4191 - val_loss: 1.7198 - val_acc: 0.5505\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4704 - acc: 0.5049 - val_loss: 1.5378 - val_acc: 0.6027\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2142 - acc: 0.5530 - val_loss: 1.4665 - val_acc: 0.6300\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0543 - acc: 0.5992 - val_loss: 1.3110 - val_acc: 0.6643\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9260 - acc: 0.6212 - val_loss: 1.3673 - val_acc: 0.6634\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8180 - acc: 0.6475 - val_loss: 1.2090 - val_acc: 0.6982\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7830 - acc: 0.6662 - val_loss: 1.2093 - val_acc: 0.6912\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7040 - acc: 0.6866 - val_loss: 1.1123 - val_acc: 0.7335\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6974 - acc: 0.6965 - val_loss: 1.1804 - val_acc: 0.7185\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6150 - acc: 0.7060 - val_loss: 1.2652 - val_acc: 0.7200\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6144 - acc: 0.7204 - val_loss: 1.1872 - val_acc: 0.7285\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5771 - acc: 0.7185 - val_loss: 1.2122 - val_acc: 0.7280\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5610 - acc: 0.7293 - val_loss: 1.1960 - val_acc: 0.7245\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5079 - acc: 0.7413 - val_loss: 1.1173 - val_acc: 0.7409\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.4896 - acc: 0.7482 - val_loss: 1.1524 - val_acc: 0.7529\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.5180 - acc: 0.7498 - val_loss: 1.1328 - val_acc: 0.7409\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4616 - acc: 0.7654 - val_loss: 1.0960 - val_acc: 0.7628\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4475 - acc: 0.7721 - val_loss: 1.1593 - val_acc: 0.7494\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4454 - acc: 0.7690 - val_loss: 1.1133 - val_acc: 0.7544\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4081 - acc: 0.7853 - val_loss: 1.0921 - val_acc: 0.7673\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.3965 - acc: 0.7837 - val_loss: 1.1056 - val_acc: 0.7663\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3780 - acc: 0.7928 - val_loss: 1.1102 - val_acc: 0.7608\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3908 - acc: 0.7906 - val_loss: 1.0763 - val_acc: 0.7633\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3929 - acc: 0.7938 - val_loss: 1.1567 - val_acc: 0.7548\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3674 - acc: 0.7965 - val_loss: 1.1163 - val_acc: 0.7613\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3563 - acc: 0.8000 - val_loss: 1.1572 - val_acc: 0.7613\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3436 - acc: 0.8105 - val_loss: 1.1279 - val_acc: 0.7723\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3340 - acc: 0.8109 - val_loss: 1.1436 - val_acc: 0.7529\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3265 - acc: 0.8167 - val_loss: 1.0976 - val_acc: 0.7718\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3223 - acc: 0.8169 - val_loss: 1.0781 - val_acc: 0.7623\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.2988 - acc: 0.8257 - val_loss: 1.1311 - val_acc: 0.7698\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3037 - acc: 0.8239 - val_loss: 1.0775 - val_acc: 0.7872\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.3117 - acc: 0.8235 - val_loss: 1.0620 - val_acc: 0.7832\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.3009 - acc: 0.8312 - val_loss: 1.0933 - val_acc: 0.7862\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2803 - acc: 0.8322 - val_loss: 1.1059 - val_acc: 0.7802\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2473 - acc: 0.8390 - val_loss: 1.0370 - val_acc: 0.7911\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2640 - acc: 0.8422 - val_loss: 1.0639 - val_acc: 0.7921\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2685 - acc: 0.8375 - val_loss: 1.0555 - val_acc: 0.7887\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2663 - acc: 0.8412 - val_loss: 1.0660 - val_acc: 0.7897\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2740 - acc: 0.8460 - val_loss: 1.0422 - val_acc: 0.7951\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2586 - acc: 0.8421 - val_loss: 1.0558 - val_acc: 0.7931\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2478 - acc: 0.8513 - val_loss: 1.0438 - val_acc: 0.7946\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2283 - acc: 0.8561 - val_loss: 1.0370 - val_acc: 0.8061\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2552 - acc: 0.8475 - val_loss: 1.0624 - val_acc: 0.7996\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2408 - acc: 0.8532 - val_loss: 1.0347 - val_acc: 0.8046\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2239 - acc: 0.8598 - val_loss: 1.0542 - val_acc: 0.8001\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2166 - acc: 0.8647 - val_loss: 0.9880 - val_acc: 0.8091\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2180 - acc: 0.8641 - val_loss: 1.0683 - val_acc: 0.7926\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2288 - acc: 0.8594 - val_loss: 1.0528 - val_acc: 0.7976\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2163 - acc: 0.8574 - val_loss: 1.0515 - val_acc: 0.7991\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2257 - acc: 0.8669 - val_loss: 1.0614 - val_acc: 0.7991\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2139 - acc: 0.8652 - val_loss: 1.0761 - val_acc: 0.7951\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2035 - acc: 0.8712 - val_loss: 1.0534 - val_acc: 0.8021\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.1976 - acc: 0.8696 - val_loss: 1.0754 - val_acc: 0.8056\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2062 - acc: 0.8679 - val_loss: 1.0839 - val_acc: 0.8105\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.1987 - acc: 0.8708 - val_loss: 1.0648 - val_acc: 0.8016\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2003 - acc: 0.8731 - val_loss: 1.1168 - val_acc: 0.8021\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1870 - acc: 0.8811 - val_loss: 1.0624 - val_acc: 0.8026\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1957 - acc: 0.8743 - val_loss: 1.0233 - val_acc: 0.8105\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.1903 - acc: 0.8803 - val_loss: 1.0512 - val_acc: 0.8145\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1821 - acc: 0.8777 - val_loss: 1.0534 - val_acc: 0.8086\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.2081 - acc: 0.8740 - val_loss: 1.0893 - val_acc: 0.8071\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1871 - acc: 0.8838 - val_loss: 1.0559 - val_acc: 0.8061\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1747 - acc: 0.8869 - val_loss: 1.0348 - val_acc: 0.8095\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1792 - acc: 0.8848 - val_loss: 1.0700 - val_acc: 0.8210\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1816 - acc: 0.8882 - val_loss: 1.0586 - val_acc: 0.8160\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1698 - acc: 0.8880 - val_loss: 1.0810 - val_acc: 0.8120\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1768 - acc: 0.8840 - val_loss: 1.0876 - val_acc: 0.8130\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1578 - acc: 0.8897 - val_loss: 1.0674 - val_acc: 0.8081\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1672 - acc: 0.8921 - val_loss: 1.0956 - val_acc: 0.8056\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1758 - acc: 0.8876 - val_loss: 1.0680 - val_acc: 0.8195\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1559 - acc: 0.8907 - val_loss: 1.0767 - val_acc: 0.8145\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1695 - acc: 0.8889 - val_loss: 1.1115 - val_acc: 0.8110\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1565 - acc: 0.8936 - val_loss: 1.0773 - val_acc: 0.8145\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1639 - acc: 0.8911 - val_loss: 1.0882 - val_acc: 0.8180\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1677 - acc: 0.8923 - val_loss: 1.0732 - val_acc: 0.8046\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1505 - acc: 0.8918 - val_loss: 1.0460 - val_acc: 0.8125\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1606 - acc: 0.8891 - val_loss: 1.0512 - val_acc: 0.8100\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1437 - acc: 0.9019 - val_loss: 1.0773 - val_acc: 0.8135\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1526 - acc: 0.9010 - val_loss: 1.0191 - val_acc: 0.8220\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1373 - acc: 0.9019 - val_loss: 1.0307 - val_acc: 0.8284\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1487 - acc: 0.8999 - val_loss: 1.0463 - val_acc: 0.8210\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1589 - acc: 0.8973 - val_loss: 1.0530 - val_acc: 0.8170\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1571 - acc: 0.8970 - val_loss: 1.0329 - val_acc: 0.8125\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1579 - acc: 0.8970 - val_loss: 1.0137 - val_acc: 0.8185\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1496 - acc: 0.9011 - val_loss: 0.9917 - val_acc: 0.8255\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1501 - acc: 0.9026 - val_loss: 1.0186 - val_acc: 0.8225\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1285 - acc: 0.9078 - val_loss: 1.0187 - val_acc: 0.8220\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1476 - acc: 0.9039 - val_loss: 1.0187 - val_acc: 0.8314\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1573 - acc: 0.9021 - val_loss: 1.0486 - val_acc: 0.8170\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1351 - acc: 0.9055 - val_loss: 1.0428 - val_acc: 0.8230\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1446 - acc: 0.9046 - val_loss: 1.0643 - val_acc: 0.8200\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1351 - acc: 0.9102 - val_loss: 1.0784 - val_acc: 0.8215\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1275 - acc: 0.9068 - val_loss: 1.0745 - val_acc: 0.8230\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1324 - acc: 0.9118 - val_loss: 1.0463 - val_acc: 0.8190\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1479 - acc: 0.9029 - val_loss: 1.0552 - val_acc: 0.8289\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1387 - acc: 0.9112 - val_loss: 1.0789 - val_acc: 0.8294\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1423 - acc: 0.9073 - val_loss: 1.0736 - val_acc: 0.8235\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1319 - acc: 0.9099 - val_loss: 1.0723 - val_acc: 0.8245\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1262 - acc: 0.9100 - val_loss: 1.0354 - val_acc: 0.8309\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1218 - acc: 0.9132 - val_loss: 1.0589 - val_acc: 0.8284\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1221 - acc: 0.9121 - val_loss: 1.0669 - val_acc: 0.8339\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1290 - acc: 0.9139 - val_loss: 1.0874 - val_acc: 0.8235\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1382 - acc: 0.9101 - val_loss: 1.0687 - val_acc: 0.8279\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1281 - acc: 0.9124 - val_loss: 1.0395 - val_acc: 0.8284\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1323 - acc: 0.9116 - val_loss: 1.0482 - val_acc: 0.8329\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1231 - acc: 0.9146 - val_loss: 1.0852 - val_acc: 0.8205\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1235 - acc: 0.9167 - val_loss: 1.0834 - val_acc: 0.8190\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1228 - acc: 0.9116 - val_loss: 1.0581 - val_acc: 0.8324\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1241 - acc: 0.9151 - val_loss: 1.0967 - val_acc: 0.8245\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1230 - acc: 0.9142 - val_loss: 1.0776 - val_acc: 0.8299\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1233 - acc: 0.9190 - val_loss: 1.0803 - val_acc: 0.8190\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1208 - acc: 0.9179 - val_loss: 1.0922 - val_acc: 0.8215\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1130 - acc: 0.9207 - val_loss: 1.0514 - val_acc: 0.8265\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1315 - acc: 0.9141 - val_loss: 1.0935 - val_acc: 0.8319\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1235 - acc: 0.9180 - val_loss: 1.0927 - val_acc: 0.8155\n",
            "Epoch 119/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1292 - acc: 0.9139 - val_loss: 1.0868 - val_acc: 0.8265\n",
            "Epoch 00119: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.78787974 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 6/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.2839 - acc: 0.0608 - val_loss: 3.8679 - val_acc: 0.2586\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1307 - acc: 0.2812 - val_loss: 2.0738 - val_acc: 0.4923\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9546 - acc: 0.4212 - val_loss: 1.6040 - val_acc: 0.5793\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4942 - acc: 0.5068 - val_loss: 1.4605 - val_acc: 0.6350\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.1900 - acc: 0.5619 - val_loss: 1.3642 - val_acc: 0.6464\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0434 - acc: 0.5958 - val_loss: 1.2324 - val_acc: 0.6837\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.8992 - acc: 0.6330 - val_loss: 1.2788 - val_acc: 0.6842\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8343 - acc: 0.6463 - val_loss: 1.1499 - val_acc: 0.7106\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7490 - acc: 0.6726 - val_loss: 1.1535 - val_acc: 0.7181\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.6956 - acc: 0.6877 - val_loss: 1.1774 - val_acc: 0.7111\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6660 - acc: 0.6966 - val_loss: 1.1385 - val_acc: 0.7310\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6183 - acc: 0.7111 - val_loss: 1.1328 - val_acc: 0.7330\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.5956 - acc: 0.7209 - val_loss: 1.1195 - val_acc: 0.7340\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5866 - acc: 0.7305 - val_loss: 1.2429 - val_acc: 0.7220\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5237 - acc: 0.7355 - val_loss: 1.2043 - val_acc: 0.7414\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5033 - acc: 0.7473 - val_loss: 1.0606 - val_acc: 0.7459\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.4843 - acc: 0.7559 - val_loss: 1.1140 - val_acc: 0.7489\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4703 - acc: 0.7605 - val_loss: 1.0141 - val_acc: 0.7638\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4547 - acc: 0.7678 - val_loss: 1.0229 - val_acc: 0.7613\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4310 - acc: 0.7790 - val_loss: 1.0635 - val_acc: 0.7553\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4433 - acc: 0.7671 - val_loss: 1.0190 - val_acc: 0.7698\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4175 - acc: 0.7750 - val_loss: 1.0175 - val_acc: 0.7663\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4037 - acc: 0.7866 - val_loss: 1.0265 - val_acc: 0.7673\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3838 - acc: 0.7933 - val_loss: 1.0080 - val_acc: 0.7827\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3615 - acc: 0.8049 - val_loss: 0.9687 - val_acc: 0.7767\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3743 - acc: 0.7931 - val_loss: 1.0078 - val_acc: 0.7762\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3503 - acc: 0.7997 - val_loss: 1.0550 - val_acc: 0.7713\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3496 - acc: 0.8056 - val_loss: 0.9998 - val_acc: 0.7767\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3268 - acc: 0.8174 - val_loss: 0.9778 - val_acc: 0.7802\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3172 - acc: 0.8193 - val_loss: 1.0062 - val_acc: 0.7837\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3178 - acc: 0.8179 - val_loss: 1.0633 - val_acc: 0.7762\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3171 - acc: 0.8211 - val_loss: 0.9684 - val_acc: 0.7936\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3198 - acc: 0.8210 - val_loss: 1.0149 - val_acc: 0.7842\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.2811 - acc: 0.8314 - val_loss: 0.9770 - val_acc: 0.7911\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.2886 - acc: 0.8316 - val_loss: 0.9732 - val_acc: 0.8011\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2827 - acc: 0.8365 - val_loss: 0.9880 - val_acc: 0.7887\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2856 - acc: 0.8390 - val_loss: 0.9454 - val_acc: 0.8021\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2584 - acc: 0.8402 - val_loss: 1.0088 - val_acc: 0.7902\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2571 - acc: 0.8432 - val_loss: 1.0185 - val_acc: 0.7897\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2735 - acc: 0.8407 - val_loss: 0.9878 - val_acc: 0.7946\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2587 - acc: 0.8438 - val_loss: 1.0291 - val_acc: 0.7907\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2453 - acc: 0.8484 - val_loss: 0.9463 - val_acc: 0.8086\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2541 - acc: 0.8474 - val_loss: 1.0105 - val_acc: 0.8036\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2573 - acc: 0.8494 - val_loss: 0.9875 - val_acc: 0.8046\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2521 - acc: 0.8530 - val_loss: 0.9563 - val_acc: 0.8091\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2357 - acc: 0.8567 - val_loss: 0.9989 - val_acc: 0.7986\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2256 - acc: 0.8616 - val_loss: 0.9808 - val_acc: 0.8046\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2206 - acc: 0.8646 - val_loss: 0.9546 - val_acc: 0.8100\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2123 - acc: 0.8672 - val_loss: 0.9496 - val_acc: 0.8130\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2087 - acc: 0.8659 - val_loss: 0.9718 - val_acc: 0.8056\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2170 - acc: 0.8616 - val_loss: 0.9807 - val_acc: 0.8071\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2116 - acc: 0.8643 - val_loss: 0.9968 - val_acc: 0.8081\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2073 - acc: 0.8729 - val_loss: 0.9698 - val_acc: 0.8120\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2018 - acc: 0.8760 - val_loss: 0.9722 - val_acc: 0.8100\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2040 - acc: 0.8743 - val_loss: 0.9632 - val_acc: 0.8140\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2024 - acc: 0.8705 - val_loss: 0.9870 - val_acc: 0.8170\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2047 - acc: 0.8712 - val_loss: 0.9514 - val_acc: 0.8205\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2092 - acc: 0.8727 - val_loss: 0.9639 - val_acc: 0.8125\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.1981 - acc: 0.8782 - val_loss: 0.9602 - val_acc: 0.8160\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1879 - acc: 0.8795 - val_loss: 0.9783 - val_acc: 0.8200\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1877 - acc: 0.8787 - val_loss: 0.9619 - val_acc: 0.8145\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.1877 - acc: 0.8808 - val_loss: 0.9883 - val_acc: 0.8105\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1906 - acc: 0.8836 - val_loss: 0.9811 - val_acc: 0.8135\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1888 - acc: 0.8796 - val_loss: 0.9658 - val_acc: 0.8205\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1800 - acc: 0.8841 - val_loss: 1.0098 - val_acc: 0.8081\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1825 - acc: 0.8837 - val_loss: 1.0225 - val_acc: 0.8115\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1671 - acc: 0.8827 - val_loss: 0.9893 - val_acc: 0.8115\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1885 - acc: 0.8908 - val_loss: 0.9518 - val_acc: 0.8265\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1625 - acc: 0.8901 - val_loss: 0.9932 - val_acc: 0.8185\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1593 - acc: 0.8962 - val_loss: 0.9769 - val_acc: 0.8250\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1625 - acc: 0.8913 - val_loss: 0.9898 - val_acc: 0.8170\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1778 - acc: 0.8848 - val_loss: 1.0547 - val_acc: 0.8095\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1743 - acc: 0.8863 - val_loss: 0.9888 - val_acc: 0.8255\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1550 - acc: 0.8962 - val_loss: 0.9614 - val_acc: 0.8230\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1625 - acc: 0.8925 - val_loss: 0.9925 - val_acc: 0.8185\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1579 - acc: 0.8955 - val_loss: 1.0047 - val_acc: 0.8200\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1447 - acc: 0.8986 - val_loss: 0.9714 - val_acc: 0.8160\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1520 - acc: 0.9001 - val_loss: 0.9636 - val_acc: 0.8270\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1338 - acc: 0.9074 - val_loss: 1.0076 - val_acc: 0.8270\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1535 - acc: 0.9013 - val_loss: 0.9979 - val_acc: 0.8270\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1539 - acc: 0.8992 - val_loss: 0.9891 - val_acc: 0.8215\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1539 - acc: 0.8966 - val_loss: 1.0094 - val_acc: 0.8225\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1446 - acc: 0.9004 - val_loss: 1.0358 - val_acc: 0.8125\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1610 - acc: 0.8993 - val_loss: 0.9785 - val_acc: 0.8289\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1440 - acc: 0.8999 - val_loss: 1.0183 - val_acc: 0.8260\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1469 - acc: 0.9015 - val_loss: 0.9668 - val_acc: 0.8250\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1459 - acc: 0.8997 - val_loss: 0.9652 - val_acc: 0.8289\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1385 - acc: 0.9102 - val_loss: 0.9613 - val_acc: 0.8344\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1479 - acc: 0.9060 - val_loss: 0.9843 - val_acc: 0.8255\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1481 - acc: 0.9057 - val_loss: 0.9950 - val_acc: 0.8279\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1452 - acc: 0.9076 - val_loss: 1.0276 - val_acc: 0.8215\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1336 - acc: 0.9066 - val_loss: 1.0098 - val_acc: 0.8260\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1330 - acc: 0.9058 - val_loss: 1.0012 - val_acc: 0.8284\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1333 - acc: 0.9121 - val_loss: 0.9740 - val_acc: 0.8334\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1299 - acc: 0.9149 - val_loss: 0.9959 - val_acc: 0.8324\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1472 - acc: 0.9047 - val_loss: 0.9671 - val_acc: 0.8359\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1430 - acc: 0.9078 - val_loss: 0.9644 - val_acc: 0.8384\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1343 - acc: 0.9098 - val_loss: 0.9850 - val_acc: 0.8255\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1271 - acc: 0.9155 - val_loss: 0.9604 - val_acc: 0.8339\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1196 - acc: 0.9181 - val_loss: 1.0162 - val_acc: 0.8299\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1369 - acc: 0.9060 - val_loss: 1.0225 - val_acc: 0.8220\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1387 - acc: 0.9064 - val_loss: 1.0070 - val_acc: 0.8270\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1310 - acc: 0.9129 - val_loss: 0.9926 - val_acc: 0.8309\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1274 - acc: 0.9120 - val_loss: 0.9768 - val_acc: 0.8329\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1315 - acc: 0.9100 - val_loss: 1.0188 - val_acc: 0.8349\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1167 - acc: 0.9176 - val_loss: 1.0048 - val_acc: 0.8344\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1224 - acc: 0.9199 - val_loss: 0.9652 - val_acc: 0.8374\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1164 - acc: 0.9187 - val_loss: 0.9705 - val_acc: 0.8389\n",
            "Epoch 109/200\n",
            "566/566 - 6s - loss: 0.1165 - acc: 0.9205 - val_loss: 0.9896 - val_acc: 0.8329\n",
            "Epoch 110/200\n",
            "566/566 - 6s - loss: 0.1201 - acc: 0.9181 - val_loss: 0.9731 - val_acc: 0.8314\n",
            "Epoch 111/200\n",
            "566/566 - 6s - loss: 0.1200 - acc: 0.9158 - val_loss: 0.9914 - val_acc: 0.8260\n",
            "Epoch 112/200\n",
            "566/566 - 6s - loss: 0.1238 - acc: 0.9135 - val_loss: 1.0125 - val_acc: 0.8279\n",
            "Epoch 113/200\n",
            "566/566 - 6s - loss: 0.1154 - acc: 0.9192 - val_loss: 1.0032 - val_acc: 0.8309\n",
            "Epoch 114/200\n",
            "566/566 - 6s - loss: 0.1189 - acc: 0.9182 - val_loss: 1.0045 - val_acc: 0.8369\n",
            "Epoch 115/200\n",
            "566/566 - 6s - loss: 0.1136 - acc: 0.9172 - val_loss: 1.0004 - val_acc: 0.8304\n",
            "Epoch 116/200\n",
            "566/566 - 6s - loss: 0.1198 - acc: 0.9171 - val_loss: 0.9899 - val_acc: 0.8339\n",
            "Epoch 117/200\n",
            "566/566 - 6s - loss: 0.1073 - acc: 0.9230 - val_loss: 0.9727 - val_acc: 0.8319\n",
            "Epoch 118/200\n",
            "566/566 - 6s - loss: 0.1187 - acc: 0.9193 - val_loss: 0.9770 - val_acc: 0.8379\n",
            "Epoch 119/200\n",
            "566/566 - 6s - loss: 0.1046 - acc: 0.9233 - val_loss: 0.9932 - val_acc: 0.8404\n",
            "Epoch 120/200\n",
            "566/566 - 6s - loss: 0.1218 - acc: 0.9173 - val_loss: 1.0144 - val_acc: 0.8270\n",
            "Epoch 121/200\n",
            "566/566 - 6s - loss: 0.1186 - acc: 0.9202 - val_loss: 1.0438 - val_acc: 0.8235\n",
            "Epoch 122/200\n",
            "566/566 - 6s - loss: 0.1154 - acc: 0.9189 - val_loss: 1.0034 - val_acc: 0.8394\n",
            "Epoch 123/200\n",
            "566/566 - 6s - loss: 0.1104 - acc: 0.9210 - val_loss: 0.9960 - val_acc: 0.8419\n",
            "Epoch 124/200\n",
            "566/566 - 6s - loss: 0.1258 - acc: 0.9186 - val_loss: 0.9889 - val_acc: 0.8399\n",
            "Epoch 125/200\n",
            "566/566 - 6s - loss: 0.1307 - acc: 0.9187 - val_loss: 1.0226 - val_acc: 0.8414\n",
            "Epoch 126/200\n",
            "566/566 - 6s - loss: 0.1135 - acc: 0.9226 - val_loss: 1.0273 - val_acc: 0.8299\n",
            "Epoch 127/200\n",
            "566/566 - 6s - loss: 0.1111 - acc: 0.9246 - val_loss: 1.0097 - val_acc: 0.8339\n",
            "Epoch 128/200\n",
            "566/566 - 6s - loss: 0.1104 - acc: 0.9223 - val_loss: 0.9940 - val_acc: 0.8369\n",
            "Epoch 129/200\n",
            "566/566 - 6s - loss: 0.1098 - acc: 0.9271 - val_loss: 1.0003 - val_acc: 0.8414\n",
            "Epoch 130/200\n",
            "566/566 - 6s - loss: 0.1226 - acc: 0.9202 - val_loss: 1.0171 - val_acc: 0.8369\n",
            "Epoch 131/200\n",
            "566/566 - 6s - loss: 0.1143 - acc: 0.9240 - val_loss: 1.0042 - val_acc: 0.8374\n",
            "Epoch 132/200\n",
            "566/566 - 6s - loss: 0.0992 - acc: 0.9278 - val_loss: 0.9822 - val_acc: 0.8454\n",
            "Epoch 133/200\n",
            "566/566 - 6s - loss: 0.1011 - acc: 0.9280 - val_loss: 0.9947 - val_acc: 0.8374\n",
            "Epoch 134/200\n",
            "566/566 - 6s - loss: 0.0989 - acc: 0.9273 - val_loss: 1.0102 - val_acc: 0.8389\n",
            "Epoch 135/200\n",
            "566/566 - 6s - loss: 0.1053 - acc: 0.9248 - val_loss: 0.9891 - val_acc: 0.8493\n",
            "Epoch 136/200\n",
            "566/566 - 6s - loss: 0.1040 - acc: 0.9242 - val_loss: 1.0059 - val_acc: 0.8384\n",
            "Epoch 137/200\n",
            "566/566 - 6s - loss: 0.1012 - acc: 0.9260 - val_loss: 1.0362 - val_acc: 0.8404\n",
            "Epoch 138/200\n",
            "566/566 - 6s - loss: 0.1043 - acc: 0.9283 - val_loss: 1.0377 - val_acc: 0.8463\n",
            "Epoch 139/200\n",
            "566/566 - 6s - loss: 0.1067 - acc: 0.9266 - val_loss: 0.9969 - val_acc: 0.8434\n",
            "Epoch 140/200\n",
            "566/566 - 6s - loss: 0.1035 - acc: 0.9272 - val_loss: 1.0293 - val_acc: 0.8419\n",
            "Epoch 141/200\n",
            "566/566 - 6s - loss: 0.1078 - acc: 0.9224 - val_loss: 1.0221 - val_acc: 0.8424\n",
            "Epoch 142/200\n",
            "566/566 - 6s - loss: 0.1170 - acc: 0.9259 - val_loss: 1.0091 - val_acc: 0.8404\n",
            "Epoch 143/200\n",
            "566/566 - 6s - loss: 0.1176 - acc: 0.9251 - val_loss: 1.0224 - val_acc: 0.8379\n",
            "Epoch 144/200\n",
            "566/566 - 6s - loss: 0.1088 - acc: 0.9265 - val_loss: 1.0106 - val_acc: 0.8344\n",
            "Epoch 145/200\n",
            "566/566 - 6s - loss: 0.1042 - acc: 0.9280 - val_loss: 0.9844 - val_acc: 0.8409\n",
            "Epoch 146/200\n",
            "566/566 - 6s - loss: 0.0979 - acc: 0.9272 - val_loss: 0.9886 - val_acc: 0.8394\n",
            "Epoch 147/200\n",
            "566/566 - 6s - loss: 0.0992 - acc: 0.9282 - val_loss: 0.9989 - val_acc: 0.8439\n",
            "Epoch 148/200\n",
            "566/566 - 6s - loss: 0.0966 - acc: 0.9249 - val_loss: 1.0223 - val_acc: 0.8349\n",
            "Epoch 149/200\n",
            "566/566 - 6s - loss: 0.0988 - acc: 0.9311 - val_loss: 0.9979 - val_acc: 0.8478\n",
            "Epoch 150/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1056 - acc: 0.9293 - val_loss: 0.9880 - val_acc: 0.8404\n",
            "Epoch 00150: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.80121007 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 7/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.3005 - acc: 0.0597 - val_loss: 3.8874 - val_acc: 0.2377\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1423 - acc: 0.2739 - val_loss: 2.2289 - val_acc: 0.4267\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.0033 - acc: 0.4142 - val_loss: 1.7951 - val_acc: 0.5465\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.5053 - acc: 0.4952 - val_loss: 1.4985 - val_acc: 0.6141\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.2060 - acc: 0.5497 - val_loss: 1.3641 - val_acc: 0.6464\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0260 - acc: 0.5948 - val_loss: 1.2646 - val_acc: 0.6698\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.8999 - acc: 0.6359 - val_loss: 1.1804 - val_acc: 0.6892\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8223 - acc: 0.6485 - val_loss: 1.2755 - val_acc: 0.6907\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7858 - acc: 0.6611 - val_loss: 1.2271 - val_acc: 0.7071\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7156 - acc: 0.6781 - val_loss: 1.1272 - val_acc: 0.7121\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6609 - acc: 0.7037 - val_loss: 1.1620 - val_acc: 0.7141\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6481 - acc: 0.7041 - val_loss: 1.1491 - val_acc: 0.7210\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.5923 - acc: 0.7204 - val_loss: 1.0956 - val_acc: 0.7315\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5834 - acc: 0.7287 - val_loss: 1.1591 - val_acc: 0.7275\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5407 - acc: 0.7386 - val_loss: 1.0824 - val_acc: 0.7414\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.4950 - acc: 0.7547 - val_loss: 1.0378 - val_acc: 0.7514\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.4814 - acc: 0.7579 - val_loss: 1.0244 - val_acc: 0.7558\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4850 - acc: 0.7560 - val_loss: 0.9992 - val_acc: 0.7529\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4557 - acc: 0.7678 - val_loss: 1.0563 - val_acc: 0.7558\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4384 - acc: 0.7710 - val_loss: 1.0672 - val_acc: 0.7668\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4620 - acc: 0.7718 - val_loss: 1.0712 - val_acc: 0.7593\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4206 - acc: 0.7847 - val_loss: 1.0381 - val_acc: 0.7628\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4125 - acc: 0.7909 - val_loss: 1.0242 - val_acc: 0.7613\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3882 - acc: 0.7914 - val_loss: 1.0088 - val_acc: 0.7762\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3884 - acc: 0.7977 - val_loss: 1.0633 - val_acc: 0.7698\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3487 - acc: 0.8043 - val_loss: 1.0268 - val_acc: 0.7708\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3324 - acc: 0.8092 - val_loss: 0.9968 - val_acc: 0.7792\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3364 - acc: 0.8097 - val_loss: 1.0509 - val_acc: 0.7752\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3424 - acc: 0.8126 - val_loss: 1.1074 - val_acc: 0.7727\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3164 - acc: 0.8170 - val_loss: 1.0100 - val_acc: 0.7837\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3086 - acc: 0.8190 - val_loss: 1.0339 - val_acc: 0.7872\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3128 - acc: 0.8238 - val_loss: 0.9767 - val_acc: 0.7946\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3164 - acc: 0.8224 - val_loss: 1.0626 - val_acc: 0.7817\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.2996 - acc: 0.8220 - val_loss: 1.0459 - val_acc: 0.7807\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.2871 - acc: 0.8341 - val_loss: 1.0462 - val_acc: 0.7807\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2929 - acc: 0.8308 - val_loss: 0.9987 - val_acc: 0.7926\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2832 - acc: 0.8369 - val_loss: 1.0270 - val_acc: 0.7971\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2688 - acc: 0.8416 - val_loss: 1.0265 - val_acc: 0.7996\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2733 - acc: 0.8424 - val_loss: 1.0865 - val_acc: 0.7832\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2611 - acc: 0.8427 - val_loss: 1.0370 - val_acc: 0.7921\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2380 - acc: 0.8496 - val_loss: 0.9971 - val_acc: 0.8071\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2590 - acc: 0.8518 - val_loss: 0.9688 - val_acc: 0.8061\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2439 - acc: 0.8549 - val_loss: 1.0228 - val_acc: 0.7996\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2554 - acc: 0.8497 - val_loss: 1.0299 - val_acc: 0.7907\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2229 - acc: 0.8554 - val_loss: 1.0628 - val_acc: 0.7966\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2532 - acc: 0.8534 - val_loss: 1.0249 - val_acc: 0.7902\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2311 - acc: 0.8562 - val_loss: 1.0320 - val_acc: 0.8011\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2417 - acc: 0.8549 - val_loss: 1.0526 - val_acc: 0.7946\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2179 - acc: 0.8625 - val_loss: 1.0381 - val_acc: 0.7996\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2154 - acc: 0.8688 - val_loss: 1.0216 - val_acc: 0.8081\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2242 - acc: 0.8619 - val_loss: 0.9887 - val_acc: 0.8086\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2079 - acc: 0.8724 - val_loss: 0.9867 - val_acc: 0.8095\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2142 - acc: 0.8727 - val_loss: 0.9894 - val_acc: 0.8031\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2128 - acc: 0.8673 - val_loss: 1.0572 - val_acc: 0.7981\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2042 - acc: 0.8717 - val_loss: 0.9762 - val_acc: 0.8056\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.1922 - acc: 0.8696 - val_loss: 1.0168 - val_acc: 0.8076\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2079 - acc: 0.8742 - val_loss: 1.0185 - val_acc: 0.8051\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2239 - acc: 0.8728 - val_loss: 0.9522 - val_acc: 0.8081\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2040 - acc: 0.8721 - val_loss: 0.9604 - val_acc: 0.8150\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1947 - acc: 0.8753 - val_loss: 0.9618 - val_acc: 0.8135\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1972 - acc: 0.8774 - val_loss: 0.9783 - val_acc: 0.8125\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.1858 - acc: 0.8804 - val_loss: 0.9720 - val_acc: 0.8095\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1706 - acc: 0.8841 - val_loss: 0.9918 - val_acc: 0.8190\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1839 - acc: 0.8809 - val_loss: 0.9812 - val_acc: 0.8140\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1726 - acc: 0.8838 - val_loss: 0.9844 - val_acc: 0.8215\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1798 - acc: 0.8838 - val_loss: 1.0471 - val_acc: 0.7976\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1822 - acc: 0.8843 - val_loss: 0.9711 - val_acc: 0.8165\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1825 - acc: 0.8874 - val_loss: 1.0311 - val_acc: 0.8140\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1699 - acc: 0.8857 - val_loss: 0.9733 - val_acc: 0.8165\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1725 - acc: 0.8914 - val_loss: 0.9866 - val_acc: 0.8056\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1578 - acc: 0.8935 - val_loss: 0.9938 - val_acc: 0.8150\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1541 - acc: 0.8950 - val_loss: 0.9719 - val_acc: 0.8195\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1819 - acc: 0.8858 - val_loss: 0.9651 - val_acc: 0.8240\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1644 - acc: 0.8900 - val_loss: 0.9728 - val_acc: 0.8185\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1573 - acc: 0.8948 - val_loss: 0.9650 - val_acc: 0.8145\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1629 - acc: 0.8926 - val_loss: 1.0062 - val_acc: 0.8095\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1500 - acc: 0.8994 - val_loss: 1.0454 - val_acc: 0.7996\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1662 - acc: 0.8932 - val_loss: 1.0205 - val_acc: 0.8095\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1532 - acc: 0.8959 - val_loss: 0.9990 - val_acc: 0.8180\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1509 - acc: 0.8985 - val_loss: 1.0447 - val_acc: 0.8145\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1523 - acc: 0.8959 - val_loss: 1.0442 - val_acc: 0.8155\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1479 - acc: 0.9006 - val_loss: 1.0149 - val_acc: 0.8130\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1627 - acc: 0.8984 - val_loss: 1.1211 - val_acc: 0.7976\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1479 - acc: 0.8978 - val_loss: 1.0604 - val_acc: 0.8155\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1441 - acc: 0.9020 - val_loss: 1.0528 - val_acc: 0.8105\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1586 - acc: 0.9013 - val_loss: 1.0464 - val_acc: 0.8086\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1489 - acc: 0.8988 - val_loss: 0.9973 - val_acc: 0.8225\n",
            "Epoch 88/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1388 - acc: 0.9025 - val_loss: 1.0156 - val_acc: 0.8215\n",
            "Epoch 00088: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.79472350 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 8/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.2947 - acc: 0.0609 - val_loss: 3.8229 - val_acc: 0.2512\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1444 - acc: 0.2790 - val_loss: 2.0603 - val_acc: 0.4806\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 1.9913 - acc: 0.4158 - val_loss: 1.5765 - val_acc: 0.5915\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4930 - acc: 0.4948 - val_loss: 1.5310 - val_acc: 0.6050\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.1990 - acc: 0.5600 - val_loss: 1.2833 - val_acc: 0.6731\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0355 - acc: 0.5982 - val_loss: 1.3057 - val_acc: 0.6662\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.9299 - acc: 0.6272 - val_loss: 1.2465 - val_acc: 0.6965\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8308 - acc: 0.6476 - val_loss: 1.2085 - val_acc: 0.7035\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7804 - acc: 0.6689 - val_loss: 1.1602 - val_acc: 0.7075\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7261 - acc: 0.6825 - val_loss: 1.1599 - val_acc: 0.7154\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6695 - acc: 0.7032 - val_loss: 1.1921 - val_acc: 0.7154\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6387 - acc: 0.7014 - val_loss: 1.1478 - val_acc: 0.7234\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6235 - acc: 0.7113 - val_loss: 1.1229 - val_acc: 0.7313\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5578 - acc: 0.7309 - val_loss: 1.1185 - val_acc: 0.7318\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5414 - acc: 0.7361 - val_loss: 1.0746 - val_acc: 0.7453\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5221 - acc: 0.7443 - val_loss: 1.1261 - val_acc: 0.7323\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.4863 - acc: 0.7540 - val_loss: 1.0807 - val_acc: 0.7433\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.5124 - acc: 0.7503 - val_loss: 1.1319 - val_acc: 0.7403\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4594 - acc: 0.7677 - val_loss: 1.1129 - val_acc: 0.7478\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4497 - acc: 0.7705 - val_loss: 1.0934 - val_acc: 0.7552\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4246 - acc: 0.7790 - val_loss: 1.0537 - val_acc: 0.7587\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4109 - acc: 0.7814 - val_loss: 1.0359 - val_acc: 0.7682\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.4006 - acc: 0.7827 - val_loss: 1.0101 - val_acc: 0.7791\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3847 - acc: 0.7962 - val_loss: 1.0121 - val_acc: 0.7776\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3677 - acc: 0.8035 - val_loss: 1.0610 - val_acc: 0.7577\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3595 - acc: 0.8046 - val_loss: 1.0003 - val_acc: 0.7836\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3655 - acc: 0.8051 - val_loss: 1.0449 - val_acc: 0.7816\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3587 - acc: 0.8030 - val_loss: 1.0161 - val_acc: 0.7836\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3507 - acc: 0.8088 - val_loss: 0.9632 - val_acc: 0.7910\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3345 - acc: 0.8164 - val_loss: 1.0035 - val_acc: 0.7925\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3162 - acc: 0.8170 - val_loss: 1.0102 - val_acc: 0.7786\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3109 - acc: 0.8180 - val_loss: 0.9732 - val_acc: 0.7975\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.2869 - acc: 0.8281 - val_loss: 1.0160 - val_acc: 0.7920\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3071 - acc: 0.8199 - val_loss: 0.9794 - val_acc: 0.8050\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.2874 - acc: 0.8294 - val_loss: 1.0480 - val_acc: 0.7856\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2837 - acc: 0.8326 - val_loss: 0.9962 - val_acc: 0.8020\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2877 - acc: 0.8298 - val_loss: 1.0687 - val_acc: 0.7891\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2734 - acc: 0.8323 - val_loss: 1.0167 - val_acc: 0.8000\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2735 - acc: 0.8388 - val_loss: 0.9848 - val_acc: 0.7995\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2548 - acc: 0.8425 - val_loss: 0.9685 - val_acc: 0.8070\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2727 - acc: 0.8445 - val_loss: 0.9704 - val_acc: 0.8030\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2768 - acc: 0.8447 - val_loss: 1.0017 - val_acc: 0.8085\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2474 - acc: 0.8503 - val_loss: 1.0393 - val_acc: 0.7910\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2409 - acc: 0.8455 - val_loss: 0.9814 - val_acc: 0.8114\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2508 - acc: 0.8545 - val_loss: 1.0009 - val_acc: 0.8060\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2329 - acc: 0.8572 - val_loss: 1.0345 - val_acc: 0.7985\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2473 - acc: 0.8499 - val_loss: 0.9978 - val_acc: 0.8025\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2297 - acc: 0.8586 - val_loss: 0.9627 - val_acc: 0.8095\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2457 - acc: 0.8582 - val_loss: 0.9555 - val_acc: 0.8209\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2382 - acc: 0.8622 - val_loss: 1.0050 - val_acc: 0.8070\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2153 - acc: 0.8652 - val_loss: 0.9685 - val_acc: 0.8090\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2436 - acc: 0.8594 - val_loss: 0.9928 - val_acc: 0.8035\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2196 - acc: 0.8665 - val_loss: 0.9820 - val_acc: 0.8080\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.1968 - acc: 0.8711 - val_loss: 0.9603 - val_acc: 0.8194\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.2056 - acc: 0.8702 - val_loss: 0.9521 - val_acc: 0.8164\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.2100 - acc: 0.8676 - val_loss: 0.9885 - val_acc: 0.8109\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.2043 - acc: 0.8698 - val_loss: 0.9802 - val_acc: 0.8124\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2005 - acc: 0.8725 - val_loss: 0.9661 - val_acc: 0.8124\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.1898 - acc: 0.8769 - val_loss: 0.9883 - val_acc: 0.8179\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.1947 - acc: 0.8756 - val_loss: 1.0061 - val_acc: 0.8025\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1877 - acc: 0.8809 - val_loss: 1.0245 - val_acc: 0.8085\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.1832 - acc: 0.8784 - val_loss: 0.9603 - val_acc: 0.8244\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1721 - acc: 0.8840 - val_loss: 0.9781 - val_acc: 0.8224\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1882 - acc: 0.8797 - val_loss: 1.0500 - val_acc: 0.8104\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1973 - acc: 0.8760 - val_loss: 0.9386 - val_acc: 0.8269\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1849 - acc: 0.8806 - val_loss: 1.0119 - val_acc: 0.8219\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1859 - acc: 0.8853 - val_loss: 1.0439 - val_acc: 0.8100\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1744 - acc: 0.8847 - val_loss: 0.9810 - val_acc: 0.8169\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1767 - acc: 0.8882 - val_loss: 1.0349 - val_acc: 0.8139\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1758 - acc: 0.8894 - val_loss: 0.9860 - val_acc: 0.8318\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1670 - acc: 0.8917 - val_loss: 0.9804 - val_acc: 0.8259\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1688 - acc: 0.8916 - val_loss: 0.9681 - val_acc: 0.8294\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1701 - acc: 0.8910 - val_loss: 0.9794 - val_acc: 0.8284\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1593 - acc: 0.8955 - val_loss: 1.0132 - val_acc: 0.8308\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1625 - acc: 0.8913 - val_loss: 1.0103 - val_acc: 0.8139\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1683 - acc: 0.8905 - val_loss: 0.9709 - val_acc: 0.8318\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1498 - acc: 0.8952 - val_loss: 1.0497 - val_acc: 0.8204\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1672 - acc: 0.8899 - val_loss: 1.0538 - val_acc: 0.8159\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1706 - acc: 0.8903 - val_loss: 0.9835 - val_acc: 0.8229\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1665 - acc: 0.8926 - val_loss: 0.9768 - val_acc: 0.8264\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1565 - acc: 0.8977 - val_loss: 0.9659 - val_acc: 0.8333\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1709 - acc: 0.8932 - val_loss: 1.0270 - val_acc: 0.8189\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1451 - acc: 0.9000 - val_loss: 0.9569 - val_acc: 0.8328\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1467 - acc: 0.9039 - val_loss: 0.9463 - val_acc: 0.8358\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1456 - acc: 0.9014 - val_loss: 0.9240 - val_acc: 0.8433\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1468 - acc: 0.8993 - val_loss: 0.9718 - val_acc: 0.8343\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1375 - acc: 0.9020 - val_loss: 0.9695 - val_acc: 0.8338\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1569 - acc: 0.9043 - val_loss: 0.9561 - val_acc: 0.8403\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1434 - acc: 0.9056 - val_loss: 0.9692 - val_acc: 0.8418\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1455 - acc: 0.9026 - val_loss: 0.9983 - val_acc: 0.8274\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1472 - acc: 0.9005 - val_loss: 1.0092 - val_acc: 0.8219\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1481 - acc: 0.9011 - val_loss: 1.0102 - val_acc: 0.8303\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1341 - acc: 0.9075 - val_loss: 0.9778 - val_acc: 0.8353\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1534 - acc: 0.8997 - val_loss: 1.0223 - val_acc: 0.8333\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1368 - acc: 0.9049 - val_loss: 1.0226 - val_acc: 0.8284\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1361 - acc: 0.9107 - val_loss: 1.0127 - val_acc: 0.8333\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1398 - acc: 0.9084 - val_loss: 1.0065 - val_acc: 0.8239\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1387 - acc: 0.9074 - val_loss: 1.0239 - val_acc: 0.8274\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1457 - acc: 0.9060 - val_loss: 0.9878 - val_acc: 0.8274\n",
            "Epoch 100/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1379 - acc: 0.9078 - val_loss: 0.9652 - val_acc: 0.8303\n",
            "Epoch 00100: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.82071638 ##########\n",
            "\n",
            "ðŸš€ Starting kfold iteration: 9/9\n",
            "Epoch 1/200\n",
            "566/566 - 6s - loss: 5.3507 - acc: 0.0549 - val_loss: 3.8952 - val_acc: 0.2234\n",
            "Epoch 2/200\n",
            "566/566 - 6s - loss: 3.1947 - acc: 0.2704 - val_loss: 2.1134 - val_acc: 0.4607\n",
            "Epoch 3/200\n",
            "566/566 - 6s - loss: 2.0187 - acc: 0.4126 - val_loss: 1.7883 - val_acc: 0.5443\n",
            "Epoch 4/200\n",
            "566/566 - 6s - loss: 1.4880 - acc: 0.5030 - val_loss: 1.4607 - val_acc: 0.6219\n",
            "Epoch 5/200\n",
            "566/566 - 6s - loss: 1.1713 - acc: 0.5640 - val_loss: 1.3953 - val_acc: 0.6244\n",
            "Epoch 6/200\n",
            "566/566 - 6s - loss: 1.0198 - acc: 0.5953 - val_loss: 1.2620 - val_acc: 0.6667\n",
            "Epoch 7/200\n",
            "566/566 - 6s - loss: 0.8926 - acc: 0.6290 - val_loss: 1.2983 - val_acc: 0.6711\n",
            "Epoch 8/200\n",
            "566/566 - 6s - loss: 0.8276 - acc: 0.6484 - val_loss: 1.2353 - val_acc: 0.6900\n",
            "Epoch 9/200\n",
            "566/566 - 6s - loss: 0.7847 - acc: 0.6668 - val_loss: 1.1956 - val_acc: 0.6965\n",
            "Epoch 10/200\n",
            "566/566 - 6s - loss: 0.7148 - acc: 0.6842 - val_loss: 1.1261 - val_acc: 0.7189\n",
            "Epoch 11/200\n",
            "566/566 - 6s - loss: 0.6840 - acc: 0.6916 - val_loss: 1.1278 - val_acc: 0.7249\n",
            "Epoch 12/200\n",
            "566/566 - 6s - loss: 0.6244 - acc: 0.7155 - val_loss: 1.2451 - val_acc: 0.7000\n",
            "Epoch 13/200\n",
            "566/566 - 6s - loss: 0.6060 - acc: 0.7132 - val_loss: 1.0724 - val_acc: 0.7408\n",
            "Epoch 14/200\n",
            "566/566 - 6s - loss: 0.5623 - acc: 0.7238 - val_loss: 1.0703 - val_acc: 0.7433\n",
            "Epoch 15/200\n",
            "566/566 - 6s - loss: 0.5480 - acc: 0.7307 - val_loss: 1.0446 - val_acc: 0.7682\n",
            "Epoch 16/200\n",
            "566/566 - 6s - loss: 0.5141 - acc: 0.7495 - val_loss: 1.0804 - val_acc: 0.7567\n",
            "Epoch 17/200\n",
            "566/566 - 6s - loss: 0.5232 - acc: 0.7484 - val_loss: 1.0620 - val_acc: 0.7731\n",
            "Epoch 18/200\n",
            "566/566 - 6s - loss: 0.4836 - acc: 0.7552 - val_loss: 1.0282 - val_acc: 0.7697\n",
            "Epoch 19/200\n",
            "566/566 - 6s - loss: 0.4339 - acc: 0.7678 - val_loss: 1.0026 - val_acc: 0.7657\n",
            "Epoch 20/200\n",
            "566/566 - 6s - loss: 0.4454 - acc: 0.7717 - val_loss: 1.0158 - val_acc: 0.7682\n",
            "Epoch 21/200\n",
            "566/566 - 6s - loss: 0.4377 - acc: 0.7742 - val_loss: 1.0222 - val_acc: 0.7587\n",
            "Epoch 22/200\n",
            "566/566 - 6s - loss: 0.4036 - acc: 0.7860 - val_loss: 0.9597 - val_acc: 0.7816\n",
            "Epoch 23/200\n",
            "566/566 - 6s - loss: 0.3960 - acc: 0.7872 - val_loss: 1.0153 - val_acc: 0.7711\n",
            "Epoch 24/200\n",
            "566/566 - 6s - loss: 0.3829 - acc: 0.7868 - val_loss: 1.0267 - val_acc: 0.7716\n",
            "Epoch 25/200\n",
            "566/566 - 6s - loss: 0.3945 - acc: 0.7935 - val_loss: 1.0663 - val_acc: 0.7667\n",
            "Epoch 26/200\n",
            "566/566 - 6s - loss: 0.3813 - acc: 0.7929 - val_loss: 1.0267 - val_acc: 0.7751\n",
            "Epoch 27/200\n",
            "566/566 - 6s - loss: 0.3571 - acc: 0.8008 - val_loss: 0.9801 - val_acc: 0.7900\n",
            "Epoch 28/200\n",
            "566/566 - 6s - loss: 0.3868 - acc: 0.7998 - val_loss: 1.0010 - val_acc: 0.7846\n",
            "Epoch 29/200\n",
            "566/566 - 6s - loss: 0.3488 - acc: 0.8098 - val_loss: 0.9973 - val_acc: 0.7940\n",
            "Epoch 30/200\n",
            "566/566 - 6s - loss: 0.3345 - acc: 0.8131 - val_loss: 0.9548 - val_acc: 0.7965\n",
            "Epoch 31/200\n",
            "566/566 - 6s - loss: 0.3205 - acc: 0.8205 - val_loss: 0.9782 - val_acc: 0.7940\n",
            "Epoch 32/200\n",
            "566/566 - 6s - loss: 0.3185 - acc: 0.8204 - val_loss: 0.9490 - val_acc: 0.8050\n",
            "Epoch 33/200\n",
            "566/566 - 6s - loss: 0.3158 - acc: 0.8246 - val_loss: 1.0261 - val_acc: 0.7796\n",
            "Epoch 34/200\n",
            "566/566 - 6s - loss: 0.3049 - acc: 0.8200 - val_loss: 0.9779 - val_acc: 0.7935\n",
            "Epoch 35/200\n",
            "566/566 - 6s - loss: 0.2939 - acc: 0.8275 - val_loss: 1.0337 - val_acc: 0.7846\n",
            "Epoch 36/200\n",
            "566/566 - 6s - loss: 0.2821 - acc: 0.8262 - val_loss: 0.9464 - val_acc: 0.7940\n",
            "Epoch 37/200\n",
            "566/566 - 6s - loss: 0.2688 - acc: 0.8332 - val_loss: 0.9583 - val_acc: 0.8025\n",
            "Epoch 38/200\n",
            "566/566 - 6s - loss: 0.2922 - acc: 0.8364 - val_loss: 0.9783 - val_acc: 0.8070\n",
            "Epoch 39/200\n",
            "566/566 - 6s - loss: 0.2755 - acc: 0.8395 - val_loss: 0.9281 - val_acc: 0.8055\n",
            "Epoch 40/200\n",
            "566/566 - 6s - loss: 0.2555 - acc: 0.8472 - val_loss: 0.9341 - val_acc: 0.8109\n",
            "Epoch 41/200\n",
            "566/566 - 6s - loss: 0.2478 - acc: 0.8457 - val_loss: 0.9369 - val_acc: 0.8179\n",
            "Epoch 42/200\n",
            "566/566 - 6s - loss: 0.2525 - acc: 0.8466 - val_loss: 0.9904 - val_acc: 0.8010\n",
            "Epoch 43/200\n",
            "566/566 - 6s - loss: 0.2493 - acc: 0.8484 - val_loss: 0.9638 - val_acc: 0.8100\n",
            "Epoch 44/200\n",
            "566/566 - 6s - loss: 0.2506 - acc: 0.8480 - val_loss: 0.9183 - val_acc: 0.8134\n",
            "Epoch 45/200\n",
            "566/566 - 6s - loss: 0.2629 - acc: 0.8471 - val_loss: 0.9284 - val_acc: 0.8204\n",
            "Epoch 46/200\n",
            "566/566 - 6s - loss: 0.2507 - acc: 0.8530 - val_loss: 0.9071 - val_acc: 0.8134\n",
            "Epoch 47/200\n",
            "566/566 - 6s - loss: 0.2238 - acc: 0.8625 - val_loss: 0.8998 - val_acc: 0.8179\n",
            "Epoch 48/200\n",
            "566/566 - 6s - loss: 0.2364 - acc: 0.8569 - val_loss: 0.9306 - val_acc: 0.8169\n",
            "Epoch 49/200\n",
            "566/566 - 6s - loss: 0.2259 - acc: 0.8624 - val_loss: 0.9210 - val_acc: 0.8154\n",
            "Epoch 50/200\n",
            "566/566 - 6s - loss: 0.2197 - acc: 0.8615 - val_loss: 0.9637 - val_acc: 0.8129\n",
            "Epoch 51/200\n",
            "566/566 - 6s - loss: 0.2323 - acc: 0.8632 - val_loss: 0.9220 - val_acc: 0.8219\n",
            "Epoch 52/200\n",
            "566/566 - 6s - loss: 0.2075 - acc: 0.8636 - val_loss: 0.8961 - val_acc: 0.8239\n",
            "Epoch 53/200\n",
            "566/566 - 6s - loss: 0.2113 - acc: 0.8644 - val_loss: 0.9167 - val_acc: 0.8199\n",
            "Epoch 54/200\n",
            "566/566 - 6s - loss: 0.2253 - acc: 0.8686 - val_loss: 0.9260 - val_acc: 0.8219\n",
            "Epoch 55/200\n",
            "566/566 - 6s - loss: 0.1978 - acc: 0.8760 - val_loss: 0.9024 - val_acc: 0.8274\n",
            "Epoch 56/200\n",
            "566/566 - 6s - loss: 0.1920 - acc: 0.8723 - val_loss: 0.9379 - val_acc: 0.8199\n",
            "Epoch 57/200\n",
            "566/566 - 6s - loss: 0.1901 - acc: 0.8664 - val_loss: 1.0176 - val_acc: 0.8095\n",
            "Epoch 58/200\n",
            "566/566 - 6s - loss: 0.2097 - acc: 0.8722 - val_loss: 0.9437 - val_acc: 0.8249\n",
            "Epoch 59/200\n",
            "566/566 - 6s - loss: 0.2036 - acc: 0.8719 - val_loss: 0.9030 - val_acc: 0.8269\n",
            "Epoch 60/200\n",
            "566/566 - 6s - loss: 0.2054 - acc: 0.8734 - val_loss: 0.8853 - val_acc: 0.8234\n",
            "Epoch 61/200\n",
            "566/566 - 6s - loss: 0.1848 - acc: 0.8806 - val_loss: 0.8770 - val_acc: 0.8328\n",
            "Epoch 62/200\n",
            "566/566 - 6s - loss: 0.1960 - acc: 0.8756 - val_loss: 0.9146 - val_acc: 0.8264\n",
            "Epoch 63/200\n",
            "566/566 - 6s - loss: 0.1960 - acc: 0.8778 - val_loss: 0.9502 - val_acc: 0.8229\n",
            "Epoch 64/200\n",
            "566/566 - 6s - loss: 0.1817 - acc: 0.8814 - val_loss: 0.8614 - val_acc: 0.8353\n",
            "Epoch 65/200\n",
            "566/566 - 6s - loss: 0.1945 - acc: 0.8793 - val_loss: 0.9224 - val_acc: 0.8249\n",
            "Epoch 66/200\n",
            "566/566 - 6s - loss: 0.1644 - acc: 0.8851 - val_loss: 0.9016 - val_acc: 0.8259\n",
            "Epoch 67/200\n",
            "566/566 - 6s - loss: 0.1745 - acc: 0.8871 - val_loss: 0.9392 - val_acc: 0.8209\n",
            "Epoch 68/200\n",
            "566/566 - 6s - loss: 0.1819 - acc: 0.8853 - val_loss: 0.9579 - val_acc: 0.8209\n",
            "Epoch 69/200\n",
            "566/566 - 6s - loss: 0.1748 - acc: 0.8831 - val_loss: 0.9660 - val_acc: 0.8224\n",
            "Epoch 70/200\n",
            "566/566 - 6s - loss: 0.1757 - acc: 0.8832 - val_loss: 0.9526 - val_acc: 0.8119\n",
            "Epoch 71/200\n",
            "566/566 - 6s - loss: 0.1726 - acc: 0.8869 - val_loss: 0.9626 - val_acc: 0.8219\n",
            "Epoch 72/200\n",
            "566/566 - 6s - loss: 0.1721 - acc: 0.8869 - val_loss: 0.9540 - val_acc: 0.8124\n",
            "Epoch 73/200\n",
            "566/566 - 6s - loss: 0.1689 - acc: 0.8944 - val_loss: 1.0049 - val_acc: 0.8249\n",
            "Epoch 74/200\n",
            "566/566 - 6s - loss: 0.1760 - acc: 0.8892 - val_loss: 0.9221 - val_acc: 0.8308\n",
            "Epoch 75/200\n",
            "566/566 - 6s - loss: 0.1633 - acc: 0.8928 - val_loss: 0.9215 - val_acc: 0.8373\n",
            "Epoch 76/200\n",
            "566/566 - 6s - loss: 0.1668 - acc: 0.8910 - val_loss: 0.9670 - val_acc: 0.8229\n",
            "Epoch 77/200\n",
            "566/566 - 6s - loss: 0.1547 - acc: 0.8968 - val_loss: 0.9032 - val_acc: 0.8343\n",
            "Epoch 78/200\n",
            "566/566 - 6s - loss: 0.1604 - acc: 0.8979 - val_loss: 0.9105 - val_acc: 0.8259\n",
            "Epoch 79/200\n",
            "566/566 - 6s - loss: 0.1737 - acc: 0.8988 - val_loss: 0.9123 - val_acc: 0.8378\n",
            "Epoch 80/200\n",
            "566/566 - 6s - loss: 0.1697 - acc: 0.8932 - val_loss: 0.9070 - val_acc: 0.8279\n",
            "Epoch 81/200\n",
            "566/566 - 6s - loss: 0.1500 - acc: 0.8976 - val_loss: 0.9125 - val_acc: 0.8274\n",
            "Epoch 82/200\n",
            "566/566 - 6s - loss: 0.1537 - acc: 0.8974 - val_loss: 0.9182 - val_acc: 0.8323\n",
            "Epoch 83/200\n",
            "566/566 - 6s - loss: 0.1563 - acc: 0.8978 - val_loss: 0.9253 - val_acc: 0.8313\n",
            "Epoch 84/200\n",
            "566/566 - 6s - loss: 0.1557 - acc: 0.8990 - val_loss: 0.9273 - val_acc: 0.8308\n",
            "Epoch 85/200\n",
            "566/566 - 6s - loss: 0.1470 - acc: 0.8981 - val_loss: 0.8886 - val_acc: 0.8353\n",
            "Epoch 86/200\n",
            "566/566 - 6s - loss: 0.1450 - acc: 0.9031 - val_loss: 0.8889 - val_acc: 0.8368\n",
            "Epoch 87/200\n",
            "566/566 - 6s - loss: 0.1578 - acc: 0.8982 - val_loss: 0.8929 - val_acc: 0.8373\n",
            "Epoch 88/200\n",
            "566/566 - 6s - loss: 0.1461 - acc: 0.9029 - val_loss: 0.9056 - val_acc: 0.8348\n",
            "Epoch 89/200\n",
            "566/566 - 6s - loss: 0.1460 - acc: 0.9015 - val_loss: 0.9221 - val_acc: 0.8383\n",
            "Epoch 90/200\n",
            "566/566 - 6s - loss: 0.1396 - acc: 0.9028 - val_loss: 0.9280 - val_acc: 0.8299\n",
            "Epoch 91/200\n",
            "566/566 - 6s - loss: 0.1423 - acc: 0.9081 - val_loss: 0.9257 - val_acc: 0.8403\n",
            "Epoch 92/200\n",
            "566/566 - 6s - loss: 0.1333 - acc: 0.9081 - val_loss: 0.8971 - val_acc: 0.8393\n",
            "Epoch 93/200\n",
            "566/566 - 6s - loss: 0.1454 - acc: 0.9037 - val_loss: 0.9367 - val_acc: 0.8318\n",
            "Epoch 94/200\n",
            "566/566 - 6s - loss: 0.1343 - acc: 0.9083 - val_loss: 0.9346 - val_acc: 0.8423\n",
            "Epoch 95/200\n",
            "566/566 - 6s - loss: 0.1409 - acc: 0.9080 - val_loss: 0.9324 - val_acc: 0.8408\n",
            "Epoch 96/200\n",
            "566/566 - 6s - loss: 0.1302 - acc: 0.9095 - val_loss: 0.9528 - val_acc: 0.8393\n",
            "Epoch 97/200\n",
            "566/566 - 6s - loss: 0.1326 - acc: 0.9106 - val_loss: 0.9448 - val_acc: 0.8373\n",
            "Epoch 98/200\n",
            "566/566 - 6s - loss: 0.1432 - acc: 0.9080 - val_loss: 0.9503 - val_acc: 0.8338\n",
            "Epoch 99/200\n",
            "566/566 - 6s - loss: 0.1428 - acc: 0.9064 - val_loss: 0.9290 - val_acc: 0.8348\n",
            "Epoch 100/200\n",
            "566/566 - 6s - loss: 0.1344 - acc: 0.9107 - val_loss: 0.9138 - val_acc: 0.8393\n",
            "Epoch 101/200\n",
            "566/566 - 6s - loss: 0.1370 - acc: 0.9106 - val_loss: 0.9162 - val_acc: 0.8373\n",
            "Epoch 102/200\n",
            "566/566 - 6s - loss: 0.1289 - acc: 0.9102 - val_loss: 0.9235 - val_acc: 0.8378\n",
            "Epoch 103/200\n",
            "566/566 - 6s - loss: 0.1327 - acc: 0.9093 - val_loss: 0.9510 - val_acc: 0.8333\n",
            "Epoch 104/200\n",
            "566/566 - 6s - loss: 0.1256 - acc: 0.9126 - val_loss: 0.9176 - val_acc: 0.8373\n",
            "Epoch 105/200\n",
            "566/566 - 6s - loss: 0.1266 - acc: 0.9103 - val_loss: 0.9224 - val_acc: 0.8418\n",
            "Epoch 106/200\n",
            "566/566 - 6s - loss: 0.1263 - acc: 0.9119 - val_loss: 0.9752 - val_acc: 0.8323\n",
            "Epoch 107/200\n",
            "566/566 - 6s - loss: 0.1350 - acc: 0.9130 - val_loss: 0.9277 - val_acc: 0.8373\n",
            "Epoch 108/200\n",
            "566/566 - 6s - loss: 0.1235 - acc: 0.9139 - val_loss: 0.9313 - val_acc: 0.8383\n",
            "Epoch 109/200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "566/566 - 6s - loss: 0.1269 - acc: 0.9135 - val_loss: 0.9113 - val_acc: 0.8383\n",
            "Epoch 00109: early stopping\n",
            "\n",
            "########## Balanced Acc: 0.82721522 ##########\n",
            "\n",
            "\n",
            "########## Global Balanced Acc: 0.80406351 ##########\n",
            "\n",
            "\n",
            " Done training GRU model, starting LSTM Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0rdisSn1idZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "8ff91401-347c-4d59-9ea0-f4a644f42a37"
      },
      "source": [
        "# Download predictions, test ids and labels\n",
        "\n",
        "from google.colab import files\n",
        "files.download('gru.npy')  # GRU Predictions\n",
        "files.download('lstm.npy')  # LSTM Predictions"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c56e0ef3-2f6c-47ae-9254-d50444e67308\", \"gru.npy\", 9436544)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_422e6544-699d-4136-98d3-6bc1f5c291d1\", \"lstm.npy\", 9436544)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}