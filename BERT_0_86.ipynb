{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "BERT-0.86.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7oXA7S8O5tf",
        "colab_type": "text"
      },
      "source": [
        "# Santander Questions Classification Using:\n",
        "### A Bidirectional Encoder Representations from Transformers (BERT) Model\n",
        "> Author: Jefferson Licet\n",
        "\n",
        "> Email: jeffersonlicet@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJpwnYmwPYi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "48e17388-ddeb-49a0-fefc-664d9e8d567e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "-kGaguqTO5ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import random as rn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Define constants\n",
        "\n",
        "SEED_NUMBER = 44 # Magic number\n",
        "CACHE_PATH = '/cache' # Cache folder\n",
        "BERT_MODEL = 'dccuchile/bert-base-spanish-wwm-cased' # Beto - Spanish Bert model\n",
        "\n",
        "# Seed random numbers, only words with CPU/GPU\n",
        "rn.seed(SEED_NUMBER)\n",
        "np.random.seed(SEED_NUMBER)\n",
        "tf.random.set_seed(SEED_NUMBER)\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "# When using a pool of TPUS random functions can't use SEED"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hamMESdSPzHU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "9f2ccfbc-deda-4aed-f68f-28cde7131199"
      },
      "source": [
        "# Enable TPUStrategy\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "# Register pandas progress bar using tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0uL0EUBBO5tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "def generateBertPath(bert_model):\n",
        "  return os.path.join(CACHE_PATH, bert_model + '-cache')\n",
        "\n",
        "save_vocab_path = generateBertPath(BERT_MODEL)\n",
        "vocab_file_path = os.path.join(save_vocab_path, 'vocab.txt')\n",
        "\n",
        "if not os.path.exists(save_vocab_path):\n",
        "    os.makedirs(save_vocab_path)\n",
        "\n",
        "tokenizer.save_pretrained(save_vocab_path)\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "fast_tokenizer = BertWordPieceTokenizer(\n",
        "    vocab_file_path,\n",
        "    lowercase=True,\n",
        "    strip_accents=True\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "TIlGZYgUO5tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Tokenizes an array of texts using BERT tokenizer\n",
        "  returns an array of arrays containing ids of the vocab\n",
        "\"\"\"\n",
        "def tokenizeAndEncode(texts, tokenizer, chunk_size=256, maxlen=512):\n",
        "    tokenizer.enable_truncation(max_length=maxlen)\n",
        "    tokenizer.enable_padding()\n",
        "\n",
        "    bert_ids = []\n",
        "    \n",
        "    encs = tokenizer.encode_batch(texts)\n",
        "    bert_ids.extend([enc.ids for enc in encs])\n",
        "        \n",
        "    return np.array(bert_ids)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJK_H-hDhTP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Descargarmos el dataset desde el drive de la competencia\n",
        "!wget -q -O train.csv https://drive.google.com/u/0/uc?id=1SvVbsYUpKphC3NuU4y7JDYsDJxYT61Yl&export=download\n",
        "!wget -q -O test_santander.csv https://drive.google.com/u/0/uc?id=1bsV_URfRHy8LNLA1SKJ24hv0lRNVXMV4&export=download"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HNWFjRFgO5t5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "c6c00d5f-3e41-487d-f468-6b318647b55e"
      },
      "source": [
        "# Load train and test data\n",
        "\n",
        "DATA_PATH = ''\n",
        "TRAIN_CSV_DIR = os.path.join(DATA_PATH, 'train.csv')\n",
        "TEST_CSV_DIR = os.path.join(DATA_PATH, 'test_santander.csv')\n",
        "\n",
        "train_data = pd.read_csv(TRAIN_CSV_DIR, sep='|')\n",
        "\n",
        "# Append samples for less populated category\n",
        "appendQuestions = [\n",
        " \"correo electr贸nico inv谩lido\",\n",
        " \"correo electr贸nico incorrecto\",\n",
        " \"el correo electronico es incorrecto\",\n",
        " \"el correo electronico no es correcto\",\n",
        "]\n",
        "\n",
        "appendCategories = [\"Cat_104\", \"Cat_104\", \"Cat_104\", \"Cat_104\"]\n",
        "\n",
        "df_concat = pd.DataFrame({'Pregunta': appendQuestions, 'Intencion': appendCategories })\n",
        "train_data = pd.concat([train_data, df_concat], ignore_index=True)\n",
        "\n",
        "print(train_data.tail(10))\n",
        "\n",
        "test_data = pd.read_csv(TEST_CSV_DIR)\n",
        "\n",
        "train_data['labels'], labels = pd.factorize(train_data.Intencion)\n",
        "np.save('labels.npy', labels)\n",
        "\n",
        "# Assert prints train data\n",
        "print(train_data.head())\n",
        "\n",
        "# Assert prints test data\n",
        "print(test_data.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Pregunta Intencion\n",
            "20098            estoy necesitando una tarjeta de debito    Cat_39\n",
            "20099   el monto del prestamo depende de los ingresos???   Cat_251\n",
            "20100       quiero cancelar una compra puntual el cuotas   Cat_339\n",
            "20101                               necesito pagar deuda   Cat_192\n",
            "20102  teniendo otro hipotecario es posible aplicar p...   Cat_218\n",
            "20103                               comisi贸n descubierto    Cat_56\n",
            "20104                        correo electr贸nico inv谩lido   Cat_104\n",
            "20105                      correo electr贸nico incorrecto   Cat_104\n",
            "20106                el correo electronico es incorrecto   Cat_104\n",
            "20107               el correo electronico no es correcto   Cat_104\n",
            "                                            Pregunta Intencion  labels\n",
            "0               como puedo trabajar en santander rio   Cat_102       0\n",
            "1                pagar tarjeta visa querer reintegro   Cat_350       1\n",
            "2                      pagar tarjeta naranja sistema   Cat_132       2\n",
            "3  no se debit贸 la primera cuota del plan de bien...   Cat_129       3\n",
            "4                             abonar tarjeta credito   Cat_342       4\n",
            "   id                                           Pregunta\n",
            "0   0                    querer saber tarjeta sin limite\n",
            "1   1        驴cu谩l es el l铆mite de mi tarjeta santander?\n",
            "2   2  hay beneficios en restaurantes de la costa atl...\n",
            "3   3  semana realizar pagar afip monotributo volver ...\n",
            "4   4      por un prestamo de mil. cuanto es el interes?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68tMURq460EK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2597515c-2015-4768-d43c-cfab2d57a46b"
      },
      "source": [
        "# Test the tokenizer\n",
        "tokenizeAndEncode([train_data.Pregunta.values[0]], fast_tokenizer, maxlen=15)[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    4,  1184,  1769,  3460,  1036, 18244, 30935,  1295, 25355,\n",
              "           5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhiDxjxII2ZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 30"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i9SAVwWGO5uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode test dataset\n",
        "test_data_encoded = tokenizeAndEncode(test_data.Pregunta.values, fast_tokenizer, maxlen=MAX_LEN) \n",
        "processed_test_ids = test_data.id\n",
        "\n",
        "np.save('test_ids.npy', processed_test_ids)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_data_encoded).batch(64)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DqZRk3WdO5t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\"\"\"\n",
        "  Creates a keras model using BERT as a Input layer\n",
        "\"\"\"\n",
        "def createModel(transformer,\n",
        "                op=None,\n",
        "                max_len=512,\n",
        "                categories=[],\n",
        "                loss='sparse_categorical_crossentropy'):\n",
        "  \n",
        "    input = Input(shape=(max_len,), dtype=tf.int32)\n",
        "    bert_output = transformer(input)[0]\n",
        "    hidden_state = bert_output[:, 0, :]\n",
        "    dropped_state = Dropout(0.35)(hidden_state)\n",
        "    output = Dense(len(categories), activation='softmax')(dropped_state)\n",
        "    \n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    model.compile(op, loss=loss, metrics=['acc'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J-kPKjSxO5uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from transformers import TFBertModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\"\n",
        "  Training the model using encoded data, early stops\n",
        "  when val_acc stops increasing\n",
        "\"\"\"\n",
        "def trainModel(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    x_validate,\n",
        "    y_validate,\n",
        "    class_w,\n",
        "    iteration,\n",
        "    maxLen=30,\n",
        "    epochs=75):\n",
        "    MAX_LEN = maxLen\n",
        "    categories = np.unique(train_data.labels.values)\n",
        "    optimizer = Adam(lr=3e-5)\n",
        "    loss = 'sparse_categorical_crossentropy'\n",
        "\n",
        "    with strategy.scope():\n",
        "        bert_layer = TFBertModel.from_pretrained(BERT_MODEL,from_pt=True)\n",
        "        model = createModel(bert_layer,\n",
        "                            max_len=MAX_LEN,\n",
        "                            categories=categories,\n",
        "                            op=optimizer,\n",
        "                            loss=loss)\n",
        "        model.summary()\n",
        "\n",
        "    x_encoded = tokenizeAndEncode(x_train, fast_tokenizer, maxlen=MAX_LEN)\n",
        "    x_test_encoded = tokenizeAndEncode(x_validate, fast_tokenizer, maxlen=MAX_LEN)\n",
        "    \n",
        "    batch_size = 64\n",
        "\n",
        "    train_dataset = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices((x_encoded, y_train))\n",
        "        .batch(batch_size)\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "\n",
        "    valid_dataset = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices((x_test_encoded, y_validate))\n",
        "        .batch(batch_size)\n",
        "        .shuffle(2008)\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "\n",
        "    nb_epochs=epochs\n",
        "\n",
        "    es = EarlyStopping(\n",
        "        monitor='val_acc',\n",
        "        mode='max',\n",
        "        verbose=1,\n",
        "        patience=8,\n",
        "        restore_best_weights=True)\n",
        "  \n",
        "    callbacks_list=[es]\n",
        "\n",
        "    history = model.fit_generator(\n",
        "        train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=nb_epochs,\n",
        "        callbacks=callbacks_list,\n",
        "        class_weight=dict(enumerate(class_w))\n",
        "    )\n",
        "\n",
        "    prefix = 'bert'\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.savefig(str(iteration)+'_acc_'+prefix+'.png')\n",
        "    plt.clf()\n",
        "    plt.figure(1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.savefig(str(iteration)+'_loss_'+prefix+'.png')\n",
        "    plt.clf()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oCR0-NCWO5uE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4aeb6da9-80f8-40b7-9b76-866aa7a872ef"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "N_FOLDS = 10\n",
        "EPOCHS = 150\n",
        "\n",
        "x = train_data.Pregunta.values.astype(str)\n",
        "y = train_data.labels.values.astype(int)\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(y),\n",
        "    y=y)\n",
        "\n",
        "kfold = StratifiedKFold(N_FOLDS, True, 1)\n",
        "iteration = 0\n",
        "\n",
        "scores = []\n",
        "predictions = []\n",
        "\n",
        "for train_ix, test_ix in kfold.split(x, y):\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    print(' Starting kfold iteration: ' + str(iteration) + '/' + str(N_FOLDS-1))\n",
        "    trainX, trainy = x[train_ix], y[train_ix]\n",
        "    testX, testy = x[test_ix], y[test_ix]\n",
        "    \n",
        "    model = trainModel(\n",
        "        trainX,\n",
        "        trainy,\n",
        "        testX,\n",
        "        testy,\n",
        "        class_weights,\n",
        "        iteration,\n",
        "        MAX_LEN,\n",
        "        EPOCHS)\n",
        "    \n",
        "    encoded_for_test = tokenizeAndEncode(testX, fast_tokenizer, maxlen=MAX_LEN)\n",
        "\n",
        "    y_pred = model.predict(encoded_for_test, verbose=0)\n",
        "    y_pred_max = np.argmax(y_pred, axis=1).tolist()\n",
        "    iteration = iteration + 1\n",
        "\n",
        "    print(\"Balanced Acc for: \")\n",
        "    bacc = balanced_accuracy_score(testy, y_pred_max)\n",
        "    print (\"\\n########## Balanced Acc: %0.8f ##########\\n\" % bacc )\n",
        "    scores.append(bacc)\n",
        "    predictions.append(model.predict(test_dataset))\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 0/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_17 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_17 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_683 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 54s 191ms/step - acc: 0.0029 - loss: 6.0945 - val_acc: 0.0129 - val_loss: 5.6666\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.0776 - loss: 4.7194 - val_acc: 0.2815 - val_loss: 3.4208\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.3651 - loss: 2.3088 - val_acc: 0.5201 - val_loss: 2.0916\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.5880 - loss: 1.1858 - val_acc: 0.6638 - val_loss: 1.3873\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.7235 - loss: 0.6886 - val_acc: 0.7399 - val_loss: 1.0445\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.8096 - loss: 0.4191 - val_acc: 0.7772 - val_loss: 0.8982\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.8644 - loss: 0.2615 - val_acc: 0.8130 - val_loss: 0.7417\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.8999 - loss: 0.1834 - val_acc: 0.8195 - val_loss: 0.6894\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9258 - loss: 0.1321 - val_acc: 0.8483 - val_loss: 0.5999\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 23s 82ms/step - acc: 0.9474 - loss: 0.0942 - val_acc: 0.8473 - val_loss: 0.6194\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9582 - loss: 0.0718 - val_acc: 0.8513 - val_loss: 0.5821\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9670 - loss: 0.0579 - val_acc: 0.8573 - val_loss: 0.5783\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9769 - loss: 0.0440 - val_acc: 0.8727 - val_loss: 0.5473\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9804 - loss: 0.0371 - val_acc: 0.8772 - val_loss: 0.5230\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9836 - loss: 0.0321 - val_acc: 0.8697 - val_loss: 0.5525\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9814 - loss: 0.0410 - val_acc: 0.8647 - val_loss: 0.5648\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9745 - loss: 0.0612 - val_acc: 0.8429 - val_loss: 0.6617\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9714 - loss: 0.0634 - val_acc: 0.8623 - val_loss: 0.5748\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9844 - loss: 0.0388 - val_acc: 0.8637 - val_loss: 0.5795\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9832 - loss: 0.0473 - val_acc: 0.8797 - val_loss: 0.5483\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9841 - loss: 0.0349 - val_acc: 0.8767 - val_loss: 0.5693\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9866 - loss: 0.0286 - val_acc: 0.8767 - val_loss: 0.5467\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9895 - loss: 0.0272 - val_acc: 0.8846 - val_loss: 0.5500\n",
            "Epoch 24/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9875 - loss: 0.0381 - val_acc: 0.8722 - val_loss: 0.5831\n",
            "Epoch 25/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9848 - loss: 0.0448 - val_acc: 0.8672 - val_loss: 0.6146\n",
            "Epoch 26/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9876 - loss: 0.0464 - val_acc: 0.8613 - val_loss: 0.6176\n",
            "Epoch 27/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9836 - loss: 0.0412 - val_acc: 0.8623 - val_loss: 0.6215\n",
            "Epoch 28/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9876 - loss: 0.0342 - val_acc: 0.8782 - val_loss: 0.5865\n",
            "Epoch 29/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9907 - loss: 0.0282 - val_acc: 0.8782 - val_loss: 0.5821\n",
            "Epoch 30/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9919 - loss: 0.0205 - val_acc: 0.8792 - val_loss: 0.5961\n",
            "Epoch 31/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9960 - loss: 0.0132Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 27s 95ms/step - acc: 0.9960 - loss: 0.0132 - val_acc: 0.8846 - val_loss: 0.5754\n",
            "Epoch 00031: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.83244222 ##########\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 1/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_18 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_18 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_721 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 54s 191ms/step - acc: 0.0041 - loss: 6.0426 - val_acc: 0.0209 - val_loss: 5.4268\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.1126 - loss: 4.2658 - val_acc: 0.3277 - val_loss: 3.1872\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.3979 - loss: 2.1027 - val_acc: 0.5390 - val_loss: 2.0367\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.6112 - loss: 1.1261 - val_acc: 0.6668 - val_loss: 1.3846\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.7306 - loss: 0.6595 - val_acc: 0.7350 - val_loss: 1.0747\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.8094 - loss: 0.4094 - val_acc: 0.7737 - val_loss: 0.9015\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.8631 - loss: 0.2816 - val_acc: 0.8011 - val_loss: 0.7846\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.8987 - loss: 0.2034 - val_acc: 0.8135 - val_loss: 0.7235\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9271 - loss: 0.1347 - val_acc: 0.8339 - val_loss: 0.6754\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9431 - loss: 0.1008 - val_acc: 0.8414 - val_loss: 0.6385\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9513 - loss: 0.0783 - val_acc: 0.8578 - val_loss: 0.6018\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9673 - loss: 0.0577 - val_acc: 0.8637 - val_loss: 0.5916\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9709 - loss: 0.0546 - val_acc: 0.8533 - val_loss: 0.6290\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9784 - loss: 0.0449 - val_acc: 0.8598 - val_loss: 0.6348\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9818 - loss: 0.0407 - val_acc: 0.8598 - val_loss: 0.6059\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9781 - loss: 0.0478 - val_acc: 0.8498 - val_loss: 0.6772\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9819 - loss: 0.0419 - val_acc: 0.8583 - val_loss: 0.6427\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9869 - loss: 0.0296 - val_acc: 0.8598 - val_loss: 0.6474\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9859 - loss: 0.0346 - val_acc: 0.8603 - val_loss: 0.6487\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9814 - loss: 0.0532Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 28s 98ms/step - acc: 0.9814 - loss: 0.0532 - val_acc: 0.8488 - val_loss: 0.6573\n",
            "Epoch 00020: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.81084146 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 2/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_19 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_19 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_759 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 55s 194ms/step - acc: 0.0035 - loss: 6.0991 - val_acc: 0.0109 - val_loss: 5.5908\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.1152 - loss: 4.3631 - val_acc: 0.3362 - val_loss: 3.1077\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.4012 - loss: 2.0943 - val_acc: 0.5520 - val_loss: 1.9171\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.6032 - loss: 1.1109 - val_acc: 0.6808 - val_loss: 1.3204\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.7360 - loss: 0.6412 - val_acc: 0.7404 - val_loss: 1.0208\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.8155 - loss: 0.3927 - val_acc: 0.7862 - val_loss: 0.8101\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.8650 - loss: 0.2622 - val_acc: 0.8061 - val_loss: 0.7191\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.9022 - loss: 0.1916 - val_acc: 0.8279 - val_loss: 0.6552\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9284 - loss: 0.1359 - val_acc: 0.8553 - val_loss: 0.5659\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9492 - loss: 0.0863 - val_acc: 0.8603 - val_loss: 0.5497\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9547 - loss: 0.0812 - val_acc: 0.8548 - val_loss: 0.5730\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9579 - loss: 0.0901 - val_acc: 0.8637 - val_loss: 0.5618\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9660 - loss: 0.0662 - val_acc: 0.8747 - val_loss: 0.5434\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9743 - loss: 0.0488 - val_acc: 0.8762 - val_loss: 0.5426\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9818 - loss: 0.0396 - val_acc: 0.8826 - val_loss: 0.5319\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9828 - loss: 0.0375 - val_acc: 0.8772 - val_loss: 0.5604\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9831 - loss: 0.0376 - val_acc: 0.8682 - val_loss: 0.5775\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9787 - loss: 0.0401 - val_acc: 0.8702 - val_loss: 0.5685\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9720 - loss: 0.0703 - val_acc: 0.8732 - val_loss: 0.5672\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9738 - loss: 0.0668 - val_acc: 0.8742 - val_loss: 0.5804\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9771 - loss: 0.0610 - val_acc: 0.8598 - val_loss: 0.6178\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9833 - loss: 0.0438 - val_acc: 0.8787 - val_loss: 0.5662\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9875 - loss: 0.0297Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 27s 95ms/step - acc: 0.9875 - loss: 0.0297 - val_acc: 0.8747 - val_loss: 0.5752\n",
            "Epoch 00023: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.83898266 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 3/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_20 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_20 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_797 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 55s 195ms/step - acc: 0.0024 - loss: 6.2465 - val_acc: 9.9453e-04 - val_loss: 5.8884\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.0033 - loss: 6.0805 - val_acc: 0.0104 - val_loss: 5.7356\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.1054 - loss: 4.4204 - val_acc: 0.3178 - val_loss: 3.1807\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.3902 - loss: 2.1256 - val_acc: 0.5624 - val_loss: 1.9152\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.6055 - loss: 1.1122 - val_acc: 0.6862 - val_loss: 1.3332\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.7252 - loss: 0.6541 - val_acc: 0.7434 - val_loss: 1.0391\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.8102 - loss: 0.4106 - val_acc: 0.7807 - val_loss: 0.8654\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.8602 - loss: 0.2699 - val_acc: 0.8081 - val_loss: 0.7311\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.8993 - loss: 0.1866 - val_acc: 0.8289 - val_loss: 0.6724\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9240 - loss: 0.1421 - val_acc: 0.8429 - val_loss: 0.6236\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9414 - loss: 0.1015 - val_acc: 0.8458 - val_loss: 0.6273\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.9556 - loss: 0.0763 - val_acc: 0.8608 - val_loss: 0.5865\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.9651 - loss: 0.0626 - val_acc: 0.8677 - val_loss: 0.5553\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9742 - loss: 0.0473 - val_acc: 0.8782 - val_loss: 0.5349\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9785 - loss: 0.0373 - val_acc: 0.8767 - val_loss: 0.5397\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9818 - loss: 0.0348 - val_acc: 0.8767 - val_loss: 0.5448\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9839 - loss: 0.0330 - val_acc: 0.8787 - val_loss: 0.5808\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9717 - loss: 0.0577 - val_acc: 0.8722 - val_loss: 0.6024\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9788 - loss: 0.0500 - val_acc: 0.8628 - val_loss: 0.6102\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9817 - loss: 0.0405 - val_acc: 0.8692 - val_loss: 0.5985\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9689 - loss: 0.0810 - val_acc: 0.8812 - val_loss: 0.5794\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9699 - loss: 0.0811 - val_acc: 0.8573 - val_loss: 0.6110\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9765 - loss: 0.0559 - val_acc: 0.8543 - val_loss: 0.7084\n",
            "Epoch 24/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9870 - loss: 0.0269 - val_acc: 0.8826 - val_loss: 0.5425\n",
            "Epoch 25/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9925 - loss: 0.0187 - val_acc: 0.8931 - val_loss: 0.5324\n",
            "Epoch 26/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9952 - loss: 0.0126 - val_acc: 0.8921 - val_loss: 0.5282\n",
            "Epoch 27/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9931 - loss: 0.0173 - val_acc: 0.8906 - val_loss: 0.5543\n",
            "Epoch 28/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9847 - loss: 0.0405 - val_acc: 0.8742 - val_loss: 0.5911\n",
            "Epoch 29/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9875 - loss: 0.0309 - val_acc: 0.8836 - val_loss: 0.5867\n",
            "Epoch 30/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9872 - loss: 0.0388 - val_acc: 0.8628 - val_loss: 0.6142\n",
            "Epoch 31/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9823 - loss: 0.0422 - val_acc: 0.8787 - val_loss: 0.5920\n",
            "Epoch 32/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9914 - loss: 0.0215 - val_acc: 0.8836 - val_loss: 0.5806\n",
            "Epoch 33/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9963 - loss: 0.0103 - val_acc: 0.8951 - val_loss: 0.5468\n",
            "Epoch 34/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9930 - loss: 0.0190 - val_acc: 0.8787 - val_loss: 0.6014\n",
            "Epoch 35/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9925 - loss: 0.0170 - val_acc: 0.8936 - val_loss: 0.5563\n",
            "Epoch 36/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9946 - loss: 0.0122 - val_acc: 0.8921 - val_loss: 0.5738\n",
            "Epoch 37/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9957 - loss: 0.0107 - val_acc: 0.8906 - val_loss: 0.5897\n",
            "Epoch 38/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9859 - loss: 0.0338 - val_acc: 0.8682 - val_loss: 0.6854\n",
            "Epoch 39/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9821 - loss: 0.0394 - val_acc: 0.8826 - val_loss: 0.5817\n",
            "Epoch 40/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9871 - loss: 0.0367 - val_acc: 0.8757 - val_loss: 0.6278\n",
            "Epoch 41/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9897 - loss: 0.0285Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 27s 95ms/step - acc: 0.9897 - loss: 0.0285 - val_acc: 0.8826 - val_loss: 0.6368\n",
            "Epoch 00041: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.85161745 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 4/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_21 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_21 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_835 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 55s 194ms/step - acc: 0.0052 - loss: 6.0044 - val_acc: 0.0159 - val_loss: 5.4674\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.1200 - loss: 4.1965 - val_acc: 0.3590 - val_loss: 3.0675\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.4345 - loss: 1.9408 - val_acc: 0.5888 - val_loss: 1.8252\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.6389 - loss: 1.0144 - val_acc: 0.7126 - val_loss: 1.2361\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.7597 - loss: 0.5969 - val_acc: 0.7558 - val_loss: 0.9760\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.8248 - loss: 0.3714 - val_acc: 0.7916 - val_loss: 0.8076\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.8792 - loss: 0.2448 - val_acc: 0.8175 - val_loss: 0.6923\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9083 - loss: 0.1698 - val_acc: 0.8374 - val_loss: 0.6316\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9325 - loss: 0.1257 - val_acc: 0.8493 - val_loss: 0.5891\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9483 - loss: 0.0875 - val_acc: 0.8563 - val_loss: 0.5465\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9628 - loss: 0.0660 - val_acc: 0.8662 - val_loss: 0.5338\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9729 - loss: 0.0547 - val_acc: 0.8682 - val_loss: 0.5195\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9714 - loss: 0.0587 - val_acc: 0.8707 - val_loss: 0.5400\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 24s 83ms/step - acc: 0.9762 - loss: 0.0523 - val_acc: 0.8647 - val_loss: 0.5505\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9806 - loss: 0.0434 - val_acc: 0.8772 - val_loss: 0.5233\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9814 - loss: 0.0475 - val_acc: 0.8712 - val_loss: 0.5096\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9863 - loss: 0.0324 - val_acc: 0.8782 - val_loss: 0.5005\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 24s 83ms/step - acc: 0.9875 - loss: 0.0293 - val_acc: 0.8762 - val_loss: 0.5136\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9888 - loss: 0.0221 - val_acc: 0.8826 - val_loss: 0.5162\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9893 - loss: 0.0228 - val_acc: 0.8777 - val_loss: 0.5326\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9894 - loss: 0.0200 - val_acc: 0.8797 - val_loss: 0.5142\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9927 - loss: 0.0172 - val_acc: 0.8782 - val_loss: 0.5292\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9849 - loss: 0.0428 - val_acc: 0.8598 - val_loss: 0.6527\n",
            "Epoch 24/150\n",
            "283/283 [==============================] - 24s 87ms/step - acc: 0.9760 - loss: 0.0669 - val_acc: 0.8677 - val_loss: 0.5921\n",
            "Epoch 25/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9844 - loss: 0.0469 - val_acc: 0.8712 - val_loss: 0.5939\n",
            "Epoch 26/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9919 - loss: 0.0246 - val_acc: 0.8831 - val_loss: 0.5395\n",
            "Epoch 27/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9943 - loss: 0.0133 - val_acc: 0.8871 - val_loss: 0.5663\n",
            "Epoch 28/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9934 - loss: 0.0187 - val_acc: 0.8747 - val_loss: 0.5504\n",
            "Epoch 29/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9889 - loss: 0.0300 - val_acc: 0.8817 - val_loss: 0.5531\n",
            "Epoch 30/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9915 - loss: 0.0300 - val_acc: 0.8742 - val_loss: 0.5880\n",
            "Epoch 31/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9898 - loss: 0.0308 - val_acc: 0.8762 - val_loss: 0.5566\n",
            "Epoch 32/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9944 - loss: 0.0134 - val_acc: 0.8861 - val_loss: 0.5468\n",
            "Epoch 33/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9966 - loss: 0.0094 - val_acc: 0.8821 - val_loss: 0.5624\n",
            "Epoch 34/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9957 - loss: 0.0116 - val_acc: 0.8861 - val_loss: 0.5709\n",
            "Epoch 35/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9944 - loss: 0.0146Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 28s 98ms/step - acc: 0.9944 - loss: 0.0146 - val_acc: 0.8752 - val_loss: 0.6188\n",
            "Epoch 00035: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.83977804 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 5/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_22 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_22 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_873 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 55s 195ms/step - acc: 0.0089 - loss: 5.9799 - val_acc: 0.0487 - val_loss: 5.0482\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.1706 - loss: 3.8610 - val_acc: 0.3759 - val_loss: 2.8797\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.4525 - loss: 1.8678 - val_acc: 0.5699 - val_loss: 1.8585\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.6415 - loss: 0.9877 - val_acc: 0.6987 - val_loss: 1.2655\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.7585 - loss: 0.5811 - val_acc: 0.7613 - val_loss: 0.9891\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.8314 - loss: 0.3586 - val_acc: 0.7877 - val_loss: 0.8580\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.8785 - loss: 0.2322 - val_acc: 0.8110 - val_loss: 0.7382\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9110 - loss: 0.1638 - val_acc: 0.8389 - val_loss: 0.6554\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9357 - loss: 0.1115 - val_acc: 0.8548 - val_loss: 0.6160\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 23s 82ms/step - acc: 0.9498 - loss: 0.0842 - val_acc: 0.8493 - val_loss: 0.6126\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9613 - loss: 0.0640 - val_acc: 0.8608 - val_loss: 0.5982\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9695 - loss: 0.0531 - val_acc: 0.8742 - val_loss: 0.5556\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9732 - loss: 0.0471 - val_acc: 0.8732 - val_loss: 0.5633\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9819 - loss: 0.0372 - val_acc: 0.8797 - val_loss: 0.5697\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9793 - loss: 0.0416 - val_acc: 0.8747 - val_loss: 0.5899\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9791 - loss: 0.0500 - val_acc: 0.8628 - val_loss: 0.6128\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9781 - loss: 0.0517 - val_acc: 0.8603 - val_loss: 0.6466\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9793 - loss: 0.0541 - val_acc: 0.8518 - val_loss: 0.6936\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9717 - loss: 0.0758 - val_acc: 0.8359 - val_loss: 0.8242\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9673 - loss: 0.0773 - val_acc: 0.8772 - val_loss: 0.6072\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9824 - loss: 0.0438 - val_acc: 0.8742 - val_loss: 0.6220\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9898 - loss: 0.0246 - val_acc: 0.8846 - val_loss: 0.6077\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9909 - loss: 0.0175 - val_acc: 0.8826 - val_loss: 0.6057\n",
            "Epoch 24/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9918 - loss: 0.0163 - val_acc: 0.8851 - val_loss: 0.5947\n",
            "Epoch 25/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9907 - loss: 0.0206 - val_acc: 0.8752 - val_loss: 0.6545\n",
            "Epoch 26/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9736 - loss: 0.0744 - val_acc: 0.8444 - val_loss: 0.7448\n",
            "Epoch 27/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9650 - loss: 0.1369 - val_acc: 0.8439 - val_loss: 0.7517\n",
            "Epoch 28/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9845 - loss: 0.0450 - val_acc: 0.8618 - val_loss: 0.6890\n",
            "Epoch 29/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9878 - loss: 0.0316 - val_acc: 0.8697 - val_loss: 0.6456\n",
            "Epoch 30/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9949 - loss: 0.0091 - val_acc: 0.8737 - val_loss: 0.6393\n",
            "Epoch 31/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9966 - loss: 0.0075 - val_acc: 0.8767 - val_loss: 0.6489\n",
            "Epoch 32/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9967 - loss: 0.0057Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 28s 97ms/step - acc: 0.9967 - loss: 0.0057 - val_acc: 0.8817 - val_loss: 0.6572\n",
            "Epoch 00032: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.84038546 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 6/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_23 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_23 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_911 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 54s 192ms/step - acc: 0.0046 - loss: 6.0978 - val_acc: 0.0219 - val_loss: 5.5120\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.1325 - loss: 4.1824 - val_acc: 0.3899 - val_loss: 3.0138\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.4284 - loss: 1.9850 - val_acc: 0.5927 - val_loss: 1.8543\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.6245 - loss: 1.0487 - val_acc: 0.6962 - val_loss: 1.2433\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.7458 - loss: 0.6148 - val_acc: 0.7598 - val_loss: 0.9577\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.8158 - loss: 0.3996 - val_acc: 0.7966 - val_loss: 0.7973\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.8740 - loss: 0.2525 - val_acc: 0.8160 - val_loss: 0.7028\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9059 - loss: 0.1782 - val_acc: 0.8354 - val_loss: 0.6418\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9320 - loss: 0.1217 - val_acc: 0.8434 - val_loss: 0.6362\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9498 - loss: 0.0882 - val_acc: 0.8563 - val_loss: 0.5892\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9608 - loss: 0.0725 - val_acc: 0.8533 - val_loss: 0.5982\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9682 - loss: 0.0569 - val_acc: 0.8598 - val_loss: 0.5845\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9791 - loss: 0.0403 - val_acc: 0.8667 - val_loss: 0.5678\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9786 - loss: 0.0426 - val_acc: 0.8652 - val_loss: 0.5678\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 26s 94ms/step - acc: 0.9835 - loss: 0.0333 - val_acc: 0.8707 - val_loss: 0.5633\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9831 - loss: 0.0417 - val_acc: 0.8583 - val_loss: 0.6245\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9788 - loss: 0.0436 - val_acc: 0.8613 - val_loss: 0.6364\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9831 - loss: 0.0393 - val_acc: 0.8682 - val_loss: 0.6070\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9867 - loss: 0.0353 - val_acc: 0.8687 - val_loss: 0.6356\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9787 - loss: 0.0512 - val_acc: 0.8647 - val_loss: 0.6155\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9827 - loss: 0.0439 - val_acc: 0.8732 - val_loss: 0.6016\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9891 - loss: 0.0305 - val_acc: 0.8802 - val_loss: 0.5796\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9912 - loss: 0.0239 - val_acc: 0.8712 - val_loss: 0.6240\n",
            "Epoch 24/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9906 - loss: 0.0229 - val_acc: 0.8747 - val_loss: 0.5885\n",
            "Epoch 25/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9926 - loss: 0.0188 - val_acc: 0.8772 - val_loss: 0.5870\n",
            "Epoch 26/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9938 - loss: 0.0152 - val_acc: 0.8807 - val_loss: 0.5726\n",
            "Epoch 27/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9915 - loss: 0.0174 - val_acc: 0.8817 - val_loss: 0.5877\n",
            "Epoch 28/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9788 - loss: 0.0563 - val_acc: 0.8657 - val_loss: 0.6951\n",
            "Epoch 29/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9820 - loss: 0.0531 - val_acc: 0.8777 - val_loss: 0.6260\n",
            "Epoch 30/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9867 - loss: 0.0429 - val_acc: 0.8767 - val_loss: 0.6133\n",
            "Epoch 31/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9860 - loss: 0.0444 - val_acc: 0.8548 - val_loss: 0.6824\n",
            "Epoch 32/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9901 - loss: 0.0214 - val_acc: 0.8752 - val_loss: 0.6331\n",
            "Epoch 33/150\n",
            "283/283 [==============================] - 23s 83ms/step - acc: 0.9946 - loss: 0.0162 - val_acc: 0.8807 - val_loss: 0.6088\n",
            "Epoch 34/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9946 - loss: 0.0310 - val_acc: 0.8846 - val_loss: 0.6009\n",
            "Epoch 35/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9951 - loss: 0.0129 - val_acc: 0.8821 - val_loss: 0.5984\n",
            "Epoch 36/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9960 - loss: 0.0101 - val_acc: 0.8921 - val_loss: 0.5948\n",
            "Epoch 37/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9974 - loss: 0.0064 - val_acc: 0.8916 - val_loss: 0.5846\n",
            "Epoch 38/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9984 - loss: 0.0039 - val_acc: 0.8911 - val_loss: 0.6050\n",
            "Epoch 39/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9964 - loss: 0.0083 - val_acc: 0.8856 - val_loss: 0.6329\n",
            "Epoch 40/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9936 - loss: 0.0147 - val_acc: 0.8841 - val_loss: 0.6351\n",
            "Epoch 41/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9925 - loss: 0.0178 - val_acc: 0.8722 - val_loss: 0.6823\n",
            "Epoch 42/150\n",
            "283/283 [==============================] - 24s 87ms/step - acc: 0.9939 - loss: 0.0117 - val_acc: 0.8782 - val_loss: 0.6478\n",
            "Epoch 43/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9937 - loss: 0.0121 - val_acc: 0.8797 - val_loss: 0.6787\n",
            "Epoch 44/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9862 - loss: 0.0338Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 27s 97ms/step - acc: 0.9862 - loss: 0.0338 - val_acc: 0.8682 - val_loss: 0.6874\n",
            "Epoch 00044: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.84562335 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 7/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_24 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_24 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_949 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 55s 193ms/step - acc: 0.0031 - loss: 6.0461 - val_acc: 0.0065 - val_loss: 5.6568\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.0505 - loss: 4.9252 - val_acc: 0.1845 - val_loss: 3.9068\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.2862 - loss: 2.6537 - val_acc: 0.4590 - val_loss: 2.3600\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.5263 - loss: 1.3615 - val_acc: 0.6091 - val_loss: 1.6130\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.6777 - loss: 0.7774 - val_acc: 0.6748 - val_loss: 1.2408\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.7744 - loss: 0.4800 - val_acc: 0.7220 - val_loss: 1.0502\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.8379 - loss: 0.3044 - val_acc: 0.7678 - val_loss: 0.8832\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.8803 - loss: 0.2030 - val_acc: 0.8006 - val_loss: 0.7687\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9128 - loss: 0.1448 - val_acc: 0.8091 - val_loss: 0.7548\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9305 - loss: 0.1116 - val_acc: 0.8299 - val_loss: 0.6902\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9495 - loss: 0.0801 - val_acc: 0.8314 - val_loss: 0.6659\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9608 - loss: 0.0726 - val_acc: 0.8384 - val_loss: 0.6603\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.9656 - loss: 0.0587 - val_acc: 0.8454 - val_loss: 0.6504\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9672 - loss: 0.0568 - val_acc: 0.8473 - val_loss: 0.6557\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9773 - loss: 0.0413 - val_acc: 0.8588 - val_loss: 0.6108\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9776 - loss: 0.0490 - val_acc: 0.8498 - val_loss: 0.6452\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9750 - loss: 0.0639 - val_acc: 0.8349 - val_loss: 0.6973\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9700 - loss: 0.0731 - val_acc: 0.8468 - val_loss: 0.6777\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.9791 - loss: 0.0481 - val_acc: 0.8692 - val_loss: 0.6245\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9855 - loss: 0.0317 - val_acc: 0.8647 - val_loss: 0.6310\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9807 - loss: 0.0401 - val_acc: 0.8583 - val_loss: 0.6632\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9770 - loss: 0.0559 - val_acc: 0.8449 - val_loss: 0.7111\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9759 - loss: 0.0852 - val_acc: 0.8488 - val_loss: 0.7002\n",
            "Epoch 24/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9801 - loss: 0.0519 - val_acc: 0.8523 - val_loss: 0.7293\n",
            "Epoch 25/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9717 - loss: 0.0930 - val_acc: 0.8523 - val_loss: 0.7156\n",
            "Epoch 26/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9775 - loss: 0.0655 - val_acc: 0.8637 - val_loss: 0.6500\n",
            "Epoch 27/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9882 - loss: 0.0256 - val_acc: 0.8702 - val_loss: 0.6364\n",
            "Epoch 28/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9908 - loss: 0.0195 - val_acc: 0.8712 - val_loss: 0.6640\n",
            "Epoch 29/150\n",
            "283/283 [==============================] - 26s 90ms/step - acc: 0.9931 - loss: 0.0137 - val_acc: 0.8717 - val_loss: 0.6777\n",
            "Epoch 30/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9917 - loss: 0.0288 - val_acc: 0.8608 - val_loss: 0.6949\n",
            "Epoch 31/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9918 - loss: 0.0220 - val_acc: 0.8697 - val_loss: 0.7019\n",
            "Epoch 32/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9940 - loss: 0.0125 - val_acc: 0.8717 - val_loss: 0.7106\n",
            "Epoch 33/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9927 - loss: 0.0214 - val_acc: 0.8588 - val_loss: 0.7369\n",
            "Epoch 34/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9695 - loss: 0.0837 - val_acc: 0.8444 - val_loss: 0.8020\n",
            "Epoch 35/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9847 - loss: 0.0319 - val_acc: 0.8647 - val_loss: 0.7384\n",
            "Epoch 36/150\n",
            "283/283 [==============================] - 24s 84ms/step - acc: 0.9822 - loss: 0.0561 - val_acc: 0.8548 - val_loss: 0.7315\n",
            "Epoch 37/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9820 - loss: 0.0445Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 27s 95ms/step - acc: 0.9820 - loss: 0.0445 - val_acc: 0.8628 - val_loss: 0.6905\n",
            "Epoch 00037: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.82966169 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 8/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_25 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_25 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_987 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 55s 194ms/step - acc: 0.0115 - loss: 5.8782 - val_acc: 0.0746 - val_loss: 4.8460\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.1908 - loss: 3.6040 - val_acc: 0.4139 - val_loss: 2.7154\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.4531 - loss: 1.8153 - val_acc: 0.5871 - val_loss: 1.8222\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 27s 94ms/step - acc: 0.6342 - loss: 1.0008 - val_acc: 0.6910 - val_loss: 1.2899\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.7362 - loss: 0.6170 - val_acc: 0.7303 - val_loss: 1.0724\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.8121 - loss: 0.4009 - val_acc: 0.7905 - val_loss: 0.8884\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.8629 - loss: 0.2663 - val_acc: 0.8050 - val_loss: 0.8045\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.8956 - loss: 0.1844 - val_acc: 0.8299 - val_loss: 0.7003\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9267 - loss: 0.1266 - val_acc: 0.8502 - val_loss: 0.6526\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9456 - loss: 0.0970 - val_acc: 0.8498 - val_loss: 0.6412\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9566 - loss: 0.0748 - val_acc: 0.8562 - val_loss: 0.6183\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9628 - loss: 0.0625 - val_acc: 0.8587 - val_loss: 0.6104\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9703 - loss: 0.0533 - val_acc: 0.8662 - val_loss: 0.5981\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9753 - loss: 0.0519 - val_acc: 0.8642 - val_loss: 0.6122\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9806 - loss: 0.0363 - val_acc: 0.8766 - val_loss: 0.5848\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9803 - loss: 0.0416 - val_acc: 0.8617 - val_loss: 0.6344\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9786 - loss: 0.0483 - val_acc: 0.8706 - val_loss: 0.6193\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9730 - loss: 0.0554 - val_acc: 0.8627 - val_loss: 0.6671\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9733 - loss: 0.0695 - val_acc: 0.8552 - val_loss: 0.7068\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9747 - loss: 0.0605 - val_acc: 0.8607 - val_loss: 0.6488\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9833 - loss: 0.0418 - val_acc: 0.8736 - val_loss: 0.6300\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9886 - loss: 0.0263 - val_acc: 0.8642 - val_loss: 0.6730\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9870 - loss: 0.0328Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 28s 98ms/step - acc: 0.9870 - loss: 0.0328 - val_acc: 0.8672 - val_loss: 0.6759\n",
            "Epoch 00023: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.84444292 ##########\n",
            "\n",
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.5.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.5.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Starting kfold iteration: 9/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_pytorch_utils:All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "WARNING:transformers.modeling_tf_pytorch_utils:Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model_26 (TFBertMode ((None, 30, 768), (None,  109850880 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_26 [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_1025 (Dropout)       (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 352)               270688    \n",
            "=================================================================\n",
            "Total params: 110,121,568\n",
            "Trainable params: 110,121,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "283/283 [==============================] - 56s 197ms/step - acc: 0.0040 - loss: 6.0703 - val_acc: 0.0109 - val_loss: 5.5487\n",
            "Epoch 2/150\n",
            "283/283 [==============================] - 26s 91ms/step - acc: 0.0959 - loss: 4.5210 - val_acc: 0.3025 - val_loss: 3.3269\n",
            "Epoch 3/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.3809 - loss: 2.2387 - val_acc: 0.5418 - val_loss: 2.0501\n",
            "Epoch 4/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.5954 - loss: 1.1910 - val_acc: 0.6577 - val_loss: 1.4069\n",
            "Epoch 5/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.7170 - loss: 0.6947 - val_acc: 0.7249 - val_loss: 1.0852\n",
            "Epoch 6/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.8101 - loss: 0.4166 - val_acc: 0.7786 - val_loss: 0.8957\n",
            "Epoch 7/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.8613 - loss: 0.2762 - val_acc: 0.8100 - val_loss: 0.7670\n",
            "Epoch 8/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9012 - loss: 0.1907 - val_acc: 0.8323 - val_loss: 0.7005\n",
            "Epoch 9/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9259 - loss: 0.1356 - val_acc: 0.8368 - val_loss: 0.6315\n",
            "Epoch 10/150\n",
            "283/283 [==============================] - 26s 92ms/step - acc: 0.9471 - loss: 0.0949 - val_acc: 0.8468 - val_loss: 0.6236\n",
            "Epoch 11/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9598 - loss: 0.0730 - val_acc: 0.8468 - val_loss: 0.6106\n",
            "Epoch 12/150\n",
            "283/283 [==============================] - 25s 90ms/step - acc: 0.9638 - loss: 0.0679 - val_acc: 0.8498 - val_loss: 0.6095\n",
            "Epoch 13/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9743 - loss: 0.0497 - val_acc: 0.8597 - val_loss: 0.6088\n",
            "Epoch 14/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9670 - loss: 0.0648 - val_acc: 0.8478 - val_loss: 0.6534\n",
            "Epoch 15/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9744 - loss: 0.0448 - val_acc: 0.8622 - val_loss: 0.6047\n",
            "Epoch 16/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9835 - loss: 0.0331 - val_acc: 0.8682 - val_loss: 0.5865\n",
            "Epoch 17/150\n",
            "283/283 [==============================] - 25s 88ms/step - acc: 0.9809 - loss: 0.0404 - val_acc: 0.8706 - val_loss: 0.5872\n",
            "Epoch 18/150\n",
            "283/283 [==============================] - 25s 89ms/step - acc: 0.9824 - loss: 0.0309 - val_acc: 0.8721 - val_loss: 0.5888\n",
            "Epoch 19/150\n",
            "283/283 [==============================] - 26s 93ms/step - acc: 0.9868 - loss: 0.0255 - val_acc: 0.8806 - val_loss: 0.5664\n",
            "Epoch 20/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9868 - loss: 0.0354 - val_acc: 0.8602 - val_loss: 0.6380\n",
            "Epoch 21/150\n",
            "283/283 [==============================] - 25s 87ms/step - acc: 0.9707 - loss: 0.0815 - val_acc: 0.8577 - val_loss: 0.6386\n",
            "Epoch 22/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9726 - loss: 0.0734 - val_acc: 0.8478 - val_loss: 0.6615\n",
            "Epoch 23/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9831 - loss: 0.0426 - val_acc: 0.8622 - val_loss: 0.6260\n",
            "Epoch 24/150\n",
            "283/283 [==============================] - 24s 85ms/step - acc: 0.9912 - loss: 0.0192 - val_acc: 0.8726 - val_loss: 0.5983\n",
            "Epoch 25/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9902 - loss: 0.0274 - val_acc: 0.8726 - val_loss: 0.6014\n",
            "Epoch 26/150\n",
            "283/283 [==============================] - 24s 86ms/step - acc: 0.9931 - loss: 0.0180 - val_acc: 0.8716 - val_loss: 0.5985\n",
            "Epoch 27/150\n",
            "283/283 [==============================] - ETA: 0s - acc: 0.9901 - loss: 0.0256Restoring model weights from the end of the best epoch.\n",
            "283/283 [==============================] - 27s 96ms/step - acc: 0.9901 - loss: 0.0256 - val_acc: 0.8726 - val_loss: 0.6095\n",
            "Epoch 00027: early stopping\n",
            "Balanced Acc for: \n",
            "\n",
            "########## Balanced Acc: 0.83930396 ##########\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-zSPGqWKoli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3eeee993-93f3-4f1f-91ef-86ecebcd4eb1"
      },
      "source": [
        "summed = np.sum(scores, axis=0)\n",
        "print (\"\\n########## Global Balanced Acc: %0.8f ##########\\n\" % (summed/len(scores)) )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Global Balanced Acc: 0.83730792 ##########\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R2zhveWIO5uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summed = np.sum(predictions, axis=0)\n",
        "np.save('bert.npy', summed)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry5MuwMFhHhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48c247ba-e379-40ef-caa6-0aa3121b25dc"
      },
      "source": [
        "pred_summed = np.load('bert.npy', allow_pickle=True)\n",
        "labels[np.argmax(pred_summed[0])]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Cat_303'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxQio-XogdIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "fe42609f-4f7e-4b32-8c5d-6ace6fc7271b"
      },
      "source": [
        "# Download predictions, test ids and labels\n",
        "\n",
        "from google.colab import files\n",
        "files.download('bert.npy')  # Predictions\n",
        "files.download('labels.npy') # Mapping indexes to Cat_[Index]\n",
        "files.download('test_ids.npy') # Mapping test id to test index"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_899425bc-44ec-4dc7-9e46-129ae0701fc9\", \"bert.npy\", 9436544)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c732ff63-d0ae-4ece-aacb-8cff2a00b4ca\", \"labels.npy\", 5438)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_70b02311-c41c-4e01-8677-e8825a94d0a2\", \"test_ids.npy\", 53744)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}